2018-08-22 20:42:29.233570: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-08-22 20:42:29.842550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-22 20:42:29.842930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:02:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2018-08-22 20:42:29.842943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
Found 79399 images belonging to 103 classes.
Found 8844 images belonging to 103 classes.
****************
Class #4 = 101
Class #61 = 61
Class #37 = 4
Class #40 = 42
Class #0 = 0
Class #56 = 57
Class #86 = 84
Class #21 = 25
Class #18 = 22
Class #80 = 79
Class #87 = 85
Class #51 = 52
Class #25 = 29
Class #59 = 6
Class #32 = 35
Class #31 = 34
Class #47 = 49
Class #44 = 46
Class #66 = 66
Class #101 = 98
Class #5 = 102
Class #76 = 75
Class #95 = 92
Class #97 = 94
Class #100 = 97
Class #38 = 40
Class #49 = 50
Class #62 = 62
Class #55 = 56
Class #23 = 27
Class #71 = 70
Class #81 = 8
Class #17 = 21
Class #13 = 18
Class #98 = 95
Class #50 = 51
Class #53 = 54
Class #85 = 83
Class #72 = 71
Class #48 = 5
Class #68 = 68
Class #102 = 99
Class #67 = 67
Class #30 = 33
Class #52 = 53
Class #99 = 96
Class #69 = 69
Class #70 = 7
Class #33 = 36
Class #27 = 30
Class #20 = 24
Class #1 = 1
Class #22 = 26
Class #35 = 38
Class #83 = 81
Class #54 = 55
Class #82 = 80
Class #36 = 39
Class #41 = 43
Class #28 = 31
Class #64 = 64
Class #90 = 88
Class #57 = 58
Class #2 = 10
Class #46 = 48
Class #93 = 90
Class #75 = 74
Class #24 = 28
Class #29 = 32
Class #45 = 47
Class #8 = 13
Class #16 = 20
Class #96 = 93
Class #84 = 82
Class #94 = 91
Class #10 = 15
Class #9 = 14
Class #74 = 73
Class #65 = 65
Class #39 = 41
Class #42 = 44
Class #60 = 60
Class #91 = 89
Class #77 = 76
Class #19 = 23
Class #14 = 19
Class #43 = 45
Class #88 = 86
Class #12 = 17
Class #3 = 100
Class #92 = 9
Class #11 = 16
Class #78 = 77
Class #79 = 78
Class #15 = 2
Class #7 = 12
Class #89 = 87
Class #58 = 59
Class #73 = 72
Class #6 = 11
Class #26 = 3
Class #63 = 63
Class #34 = 37
['0', '1', '10', '100', '101', '102', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']
****************
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 480, 480, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 239, 239, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 239, 239, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 239, 239, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 237, 237, 32) 9216        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 237, 237, 32) 96          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 237, 237, 32) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 237, 237, 64) 18432       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 237, 237, 64) 192         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 237, 237, 64) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 118, 118, 64) 0           activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 118, 118, 80) 5120        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 118, 118, 80) 240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 118, 118, 80) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 116, 116, 192 138240      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 116, 116, 192 576         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 116, 116, 192 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 57, 57, 192)  0           activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 57, 57, 64)   12288       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 57, 57, 64)   192         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 57, 57, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 57, 57, 48)   9216        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 57, 57, 96)   55296       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 57, 57, 48)   144         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 57, 57, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 57, 57, 48)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 57, 57, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 57, 57, 192)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 57, 57, 96)   18432       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 57, 57, 64)   76800       activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 57, 57, 96)   82944       activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 57, 57, 64)   12288       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 57, 57, 96)   288         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 57, 57, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 57, 57, 96)   288         conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 57, 57, 64)   192         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 57, 57, 96)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 57, 57, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 57, 57, 96)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 57, 57, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
mixed_5b (Concatenate)          (None, 57, 57, 320)  0           activation_6[0][0]               
                                                                 activation_8[0][0]               
                                                                 activation_11[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 320)          0           mixed_5b[0][0]                   
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1, 1, 20)     6400        reshape_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1, 1, 320)    6400        dense_1[0][0]                    
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 57, 57, 320)  0           mixed_5b[0][0]                   
                                                                 dense_2[0][0]                    
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 57, 57, 32)   10240       multiply_1[0][0]                 
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 57, 57, 32)   96          conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 57, 57, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 57, 57, 32)   10240       multiply_1[0][0]                 
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 57, 57, 48)   13824       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 57, 57, 32)   96          conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 57, 57, 48)   144         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 57, 57, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 57, 57, 48)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 57, 57, 32)   10240       multiply_1[0][0]                 
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 57, 57, 32)   9216        activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 57, 57, 64)   27648       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 57, 57, 32)   96          conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 57, 57, 32)   96          conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 57, 57, 64)   192         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 57, 57, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 57, 57, 32)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 57, 57, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
block35_1_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_13[0][0]              
                                                                 activation_15[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
block35_1_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_1_mixed[0][0]            
__________________________________________________________________________________________________
block35_1 (Lambda)              (None, 57, 57, 320)  0           multiply_1[0][0]                 
                                                                 block35_1_conv[0][0]             
__________________________________________________________________________________________________
block35_1_ac (Activation)       (None, 57, 57, 320)  0           block35_1[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 320)          0           block35_1_ac[0][0]               
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_2[0][0] 
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1, 1, 20)     6400        reshape_2[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1, 1, 320)    6400        dense_3[0][0]                    
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 57, 57, 320)  0           block35_1_ac[0][0]               
                                                                 dense_4[0][0]                    
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 57, 57, 32)   10240       multiply_2[0][0]                 
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 57, 57, 32)   96          conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 57, 57, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 57, 57, 32)   10240       multiply_2[0][0]                 
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 57, 57, 48)   13824       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 57, 57, 32)   96          conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 57, 57, 48)   144         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 57, 57, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 57, 57, 48)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 57, 57, 32)   10240       multiply_2[0][0]                 
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 57, 57, 32)   9216        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 57, 57, 64)   27648       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 57, 57, 32)   96          conv2d_19[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 57, 57, 32)   96          conv2d_21[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 57, 57, 64)   192         conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 57, 57, 32)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 57, 57, 32)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 57, 57, 64)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
block35_2_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_24[0][0]              
__________________________________________________________________________________________________
block35_2_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_2_mixed[0][0]            
__________________________________________________________________________________________________
block35_2 (Lambda)              (None, 57, 57, 320)  0           multiply_2[0][0]                 
                                                                 block35_2_conv[0][0]             
__________________________________________________________________________________________________
block35_2_ac (Activation)       (None, 57, 57, 320)  0           block35_2[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 320)          0           block35_2_ac[0][0]               
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_3[0][0] 
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1, 1, 20)     6400        reshape_3[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1, 1, 320)    6400        dense_5[0][0]                    
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 57, 57, 320)  0           block35_2_ac[0][0]               
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 57, 57, 32)   10240       multiply_3[0][0]                 
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 57, 57, 32)   96          conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 57, 57, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 57, 57, 32)   10240       multiply_3[0][0]                 
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 57, 57, 48)   13824       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 57, 57, 32)   96          conv2d_26[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 57, 57, 48)   144         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 57, 57, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 57, 57, 48)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 57, 57, 32)   10240       multiply_3[0][0]                 
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 57, 57, 32)   9216        activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 57, 57, 64)   27648       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 57, 57, 32)   96          conv2d_25[0][0]                  
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 57, 57, 32)   96          conv2d_27[0][0]                  
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 57, 57, 64)   192         conv2d_30[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 57, 57, 32)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 57, 57, 32)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 57, 57, 64)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
block35_3_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_25[0][0]              
                                                                 activation_27[0][0]              
                                                                 activation_30[0][0]              
__________________________________________________________________________________________________
block35_3_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_3_mixed[0][0]            
__________________________________________________________________________________________________
block35_3 (Lambda)              (None, 57, 57, 320)  0           multiply_3[0][0]                 
                                                                 block35_3_conv[0][0]             
__________________________________________________________________________________________________
block35_3_ac (Activation)       (None, 57, 57, 320)  0           block35_3[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 320)          0           block35_3_ac[0][0]               
__________________________________________________________________________________________________
reshape_4 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_4[0][0] 
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1, 1, 20)     6400        reshape_4[0][0]                  
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1, 1, 320)    6400        dense_7[0][0]                    
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 57, 57, 320)  0           block35_3_ac[0][0]               
                                                                 dense_8[0][0]                    
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 57, 57, 32)   10240       multiply_4[0][0]                 
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 57, 57, 32)   96          conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 57, 57, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 57, 57, 32)   10240       multiply_4[0][0]                 
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 57, 57, 48)   13824       activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 57, 57, 32)   96          conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 57, 57, 48)   144         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 57, 57, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 57, 57, 48)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 57, 57, 32)   10240       multiply_4[0][0]                 
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 57, 57, 32)   9216        activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 57, 57, 64)   27648       activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 57, 57, 32)   96          conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 57, 57, 32)   96          conv2d_33[0][0]                  
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 57, 57, 64)   192         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 57, 57, 32)   0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 57, 57, 32)   0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 57, 57, 64)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
block35_4_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_31[0][0]              
                                                                 activation_33[0][0]              
                                                                 activation_36[0][0]              
__________________________________________________________________________________________________
block35_4_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_4_mixed[0][0]            
__________________________________________________________________________________________________
block35_4 (Lambda)              (None, 57, 57, 320)  0           multiply_4[0][0]                 
                                                                 block35_4_conv[0][0]             
__________________________________________________________________________________________________
block35_4_ac (Activation)       (None, 57, 57, 320)  0           block35_4[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 320)          0           block35_4_ac[0][0]               
__________________________________________________________________________________________________
reshape_5 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1, 1, 20)     6400        reshape_5[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1, 1, 320)    6400        dense_9[0][0]                    
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 57, 57, 320)  0           block35_4_ac[0][0]               
                                                                 dense_10[0][0]                   
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 57, 57, 32)   10240       multiply_5[0][0]                 
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 57, 57, 32)   96          conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 57, 57, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 57, 57, 32)   10240       multiply_5[0][0]                 
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 57, 57, 48)   13824       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 57, 57, 32)   96          conv2d_38[0][0]                  
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 57, 57, 48)   144         conv2d_41[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 57, 57, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 57, 57, 48)   0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 57, 57, 32)   10240       multiply_5[0][0]                 
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 57, 57, 32)   9216        activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 57, 57, 64)   27648       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 57, 57, 32)   96          conv2d_37[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 57, 57, 32)   96          conv2d_39[0][0]                  
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 57, 57, 64)   192         conv2d_42[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 57, 57, 32)   0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 57, 57, 32)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 57, 57, 64)   0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
block35_5_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_37[0][0]              
                                                                 activation_39[0][0]              
                                                                 activation_42[0][0]              
__________________________________________________________________________________________________
block35_5_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_5_mixed[0][0]            
__________________________________________________________________________________________________
block35_5 (Lambda)              (None, 57, 57, 320)  0           multiply_5[0][0]                 
                                                                 block35_5_conv[0][0]             
__________________________________________________________________________________________________
block35_5_ac (Activation)       (None, 57, 57, 320)  0           block35_5[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 320)          0           block35_5_ac[0][0]               
__________________________________________________________________________________________________
reshape_6 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_6[0][0] 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1, 1, 20)     6400        reshape_6[0][0]                  
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1, 1, 320)    6400        dense_11[0][0]                   
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 57, 57, 320)  0           block35_5_ac[0][0]               
                                                                 dense_12[0][0]                   
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 57, 57, 32)   10240       multiply_6[0][0]                 
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 57, 57, 32)   96          conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 57, 57, 32)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 57, 57, 32)   10240       multiply_6[0][0]                 
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 57, 57, 48)   13824       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 57, 57, 32)   96          conv2d_44[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 57, 57, 48)   144         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 57, 57, 32)   0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 57, 57, 48)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 57, 57, 32)   10240       multiply_6[0][0]                 
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 57, 57, 32)   9216        activation_44[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 57, 57, 64)   27648       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 57, 57, 32)   96          conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 57, 57, 32)   96          conv2d_45[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 57, 57, 64)   192         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 57, 57, 32)   0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 57, 57, 32)   0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 57, 57, 64)   0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
block35_6_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_43[0][0]              
                                                                 activation_45[0][0]              
                                                                 activation_48[0][0]              
__________________________________________________________________________________________________
block35_6_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_6_mixed[0][0]            
__________________________________________________________________________________________________
block35_6 (Lambda)              (None, 57, 57, 320)  0           multiply_6[0][0]                 
                                                                 block35_6_conv[0][0]             
__________________________________________________________________________________________________
block35_6_ac (Activation)       (None, 57, 57, 320)  0           block35_6[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 320)          0           block35_6_ac[0][0]               
__________________________________________________________________________________________________
reshape_7 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_7[0][0] 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1, 1, 20)     6400        reshape_7[0][0]                  
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1, 1, 320)    6400        dense_13[0][0]                   
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 57, 57, 320)  0           block35_6_ac[0][0]               
                                                                 dense_14[0][0]                   
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 57, 57, 32)   10240       multiply_7[0][0]                 
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 57, 57, 32)   96          conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 57, 57, 32)   0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 57, 57, 32)   10240       multiply_7[0][0]                 
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 57, 57, 48)   13824       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 57, 57, 32)   96          conv2d_50[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 57, 57, 48)   144         conv2d_53[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 57, 57, 32)   0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 57, 57, 48)   0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 57, 57, 32)   10240       multiply_7[0][0]                 
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 57, 57, 32)   9216        activation_50[0][0]              
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 57, 57, 64)   27648       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 57, 57, 32)   96          conv2d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 57, 57, 32)   96          conv2d_51[0][0]                  
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 57, 57, 64)   192         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 57, 57, 32)   0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 57, 57, 32)   0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 57, 57, 64)   0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
block35_7_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_49[0][0]              
                                                                 activation_51[0][0]              
                                                                 activation_54[0][0]              
__________________________________________________________________________________________________
block35_7_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_7_mixed[0][0]            
__________________________________________________________________________________________________
block35_7 (Lambda)              (None, 57, 57, 320)  0           multiply_7[0][0]                 
                                                                 block35_7_conv[0][0]             
__________________________________________________________________________________________________
block35_7_ac (Activation)       (None, 57, 57, 320)  0           block35_7[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 320)          0           block35_7_ac[0][0]               
__________________________________________________________________________________________________
reshape_8 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_8[0][0] 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1, 1, 20)     6400        reshape_8[0][0]                  
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1, 1, 320)    6400        dense_15[0][0]                   
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 57, 57, 320)  0           block35_7_ac[0][0]               
                                                                 dense_16[0][0]                   
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 57, 57, 32)   10240       multiply_8[0][0]                 
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 57, 57, 32)   96          conv2d_58[0][0]                  
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 57, 57, 32)   0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 57, 57, 32)   10240       multiply_8[0][0]                 
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 57, 57, 48)   13824       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 57, 57, 32)   96          conv2d_56[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 57, 57, 48)   144         conv2d_59[0][0]                  
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 57, 57, 32)   0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 57, 57, 48)   0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 57, 57, 32)   10240       multiply_8[0][0]                 
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 57, 57, 32)   9216        activation_56[0][0]              
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 57, 57, 64)   27648       activation_59[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 57, 57, 32)   96          conv2d_55[0][0]                  
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 57, 57, 32)   96          conv2d_57[0][0]                  
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 57, 57, 64)   192         conv2d_60[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 57, 57, 32)   0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 57, 57, 32)   0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 57, 57, 64)   0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
block35_8_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_55[0][0]              
                                                                 activation_57[0][0]              
                                                                 activation_60[0][0]              
__________________________________________________________________________________________________
block35_8_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_8_mixed[0][0]            
__________________________________________________________________________________________________
block35_8 (Lambda)              (None, 57, 57, 320)  0           multiply_8[0][0]                 
                                                                 block35_8_conv[0][0]             
__________________________________________________________________________________________________
block35_8_ac (Activation)       (None, 57, 57, 320)  0           block35_8[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 320)          0           block35_8_ac[0][0]               
__________________________________________________________________________________________________
reshape_9 (Reshape)             (None, 1, 1, 320)    0           global_average_pooling2d_9[0][0] 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 1, 1, 20)     6400        reshape_9[0][0]                  
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 1, 1, 320)    6400        dense_17[0][0]                   
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 57, 57, 320)  0           block35_8_ac[0][0]               
                                                                 dense_18[0][0]                   
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 57, 57, 32)   10240       multiply_9[0][0]                 
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 57, 57, 32)   96          conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 57, 57, 32)   0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 57, 57, 32)   10240       multiply_9[0][0]                 
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 57, 57, 48)   13824       activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 57, 57, 32)   96          conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 57, 57, 48)   144         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 57, 57, 32)   0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 57, 57, 48)   0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 57, 57, 32)   10240       multiply_9[0][0]                 
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 57, 57, 32)   9216        activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 57, 57, 64)   27648       activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 57, 57, 32)   96          conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 57, 57, 32)   96          conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 57, 57, 64)   192         conv2d_66[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 57, 57, 32)   0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 57, 57, 32)   0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 57, 57, 64)   0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
block35_9_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_61[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_66[0][0]              
__________________________________________________________________________________________________
block35_9_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_9_mixed[0][0]            
__________________________________________________________________________________________________
block35_9 (Lambda)              (None, 57, 57, 320)  0           multiply_9[0][0]                 
                                                                 block35_9_conv[0][0]             
__________________________________________________________________________________________________
block35_9_ac (Activation)       (None, 57, 57, 320)  0           block35_9[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_10 (Gl (None, 320)          0           block35_9_ac[0][0]               
__________________________________________________________________________________________________
reshape_10 (Reshape)            (None, 1, 1, 320)    0           global_average_pooling2d_10[0][0]
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 1, 1, 20)     6400        reshape_10[0][0]                 
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 1, 1, 320)    6400        dense_19[0][0]                   
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, 57, 57, 320)  0           block35_9_ac[0][0]               
                                                                 dense_20[0][0]                   
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 57, 57, 32)   10240       multiply_10[0][0]                
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 57, 57, 32)   96          conv2d_70[0][0]                  
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 57, 57, 32)   0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 57, 57, 32)   10240       multiply_10[0][0]                
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 57, 57, 48)   13824       activation_70[0][0]              
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 57, 57, 32)   96          conv2d_68[0][0]                  
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 57, 57, 48)   144         conv2d_71[0][0]                  
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 57, 57, 32)   0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 57, 57, 48)   0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 57, 57, 32)   10240       multiply_10[0][0]                
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 57, 57, 32)   9216        activation_68[0][0]              
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 57, 57, 64)   27648       activation_71[0][0]              
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 57, 57, 32)   96          conv2d_67[0][0]                  
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 57, 57, 32)   96          conv2d_69[0][0]                  
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 57, 57, 64)   192         conv2d_72[0][0]                  
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 57, 57, 32)   0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 57, 57, 32)   0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 57, 57, 64)   0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
block35_10_mixed (Concatenate)  (None, 57, 57, 128)  0           activation_67[0][0]              
                                                                 activation_69[0][0]              
                                                                 activation_72[0][0]              
__________________________________________________________________________________________________
block35_10_conv (Conv2D)        (None, 57, 57, 320)  41280       block35_10_mixed[0][0]           
__________________________________________________________________________________________________
block35_10 (Lambda)             (None, 57, 57, 320)  0           multiply_10[0][0]                
                                                                 block35_10_conv[0][0]            
__________________________________________________________________________________________________
block35_10_ac (Activation)      (None, 57, 57, 320)  0           block35_10[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_11 (Gl (None, 320)          0           block35_10_ac[0][0]              
__________________________________________________________________________________________________
reshape_11 (Reshape)            (None, 1, 1, 320)    0           global_average_pooling2d_11[0][0]
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 1, 1, 20)     6400        reshape_11[0][0]                 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 1, 1, 320)    6400        dense_21[0][0]                   
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, 57, 57, 320)  0           block35_10_ac[0][0]              
                                                                 dense_22[0][0]                   
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 57, 57, 256)  81920       multiply_11[0][0]                
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 57, 57, 256)  768         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 57, 57, 256)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 57, 57, 256)  589824      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 57, 57, 256)  768         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 57, 57, 256)  0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 28, 28, 384)  1105920     multiply_11[0][0]                
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 28, 28, 384)  884736      activation_75[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 28, 28, 384)  1152        conv2d_73[0][0]                  
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 28, 28, 384)  1152        conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 28, 28, 384)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 28, 28, 384)  0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 320)  0           multiply_11[0][0]                
__________________________________________________________________________________________________
mixed_6a (Concatenate)          (None, 28, 28, 1088) 0           activation_73[0][0]              
                                                                 activation_76[0][0]              
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
global_average_pooling2d_12 (Gl (None, 1088)         0           mixed_6a[0][0]                   
__________________________________________________________________________________________________
reshape_12 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_12[0][0]
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1, 1, 68)     73984       reshape_12[0][0]                 
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 1, 1, 1088)   73984       dense_23[0][0]                   
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, 28, 28, 1088) 0           mixed_6a[0][0]                   
                                                                 dense_24[0][0]                   
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 28, 28, 128)  139264      multiply_12[0][0]                
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 28, 28, 128)  384         conv2d_78[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 28, 28, 128)  0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 28, 28, 160)  143360      activation_78[0][0]              
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 28, 28, 160)  480         conv2d_79[0][0]                  
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 28, 28, 160)  0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 28, 28, 192)  208896      multiply_12[0][0]                
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 28, 28, 192)  215040      activation_79[0][0]              
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 28, 28, 192)  576         conv2d_77[0][0]                  
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 28, 28, 192)  576         conv2d_80[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 28, 28, 192)  0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 28, 28, 192)  0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
block17_1_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_77[0][0]              
                                                                 activation_80[0][0]              
__________________________________________________________________________________________________
block17_1_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_1_mixed[0][0]            
__________________________________________________________________________________________________
block17_1 (Lambda)              (None, 28, 28, 1088) 0           multiply_12[0][0]                
                                                                 block17_1_conv[0][0]             
__________________________________________________________________________________________________
block17_1_ac (Activation)       (None, 28, 28, 1088) 0           block17_1[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_13 (Gl (None, 1088)         0           block17_1_ac[0][0]               
__________________________________________________________________________________________________
reshape_13 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_13[0][0]
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 1, 1, 68)     73984       reshape_13[0][0]                 
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 1, 1, 1088)   73984       dense_25[0][0]                   
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, 28, 28, 1088) 0           block17_1_ac[0][0]               
                                                                 dense_26[0][0]                   
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 28, 28, 128)  139264      multiply_13[0][0]                
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 28, 28, 128)  384         conv2d_82[0][0]                  
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 28, 28, 128)  0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 28, 28, 160)  143360      activation_82[0][0]              
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 28, 28, 160)  480         conv2d_83[0][0]                  
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 28, 28, 160)  0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 28, 28, 192)  208896      multiply_13[0][0]                
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 28, 28, 192)  215040      activation_83[0][0]              
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 28, 28, 192)  576         conv2d_81[0][0]                  
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 28, 28, 192)  576         conv2d_84[0][0]                  
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 28, 28, 192)  0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 28, 28, 192)  0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
block17_2_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_81[0][0]              
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
block17_2_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_2_mixed[0][0]            
__________________________________________________________________________________________________
block17_2 (Lambda)              (None, 28, 28, 1088) 0           multiply_13[0][0]                
                                                                 block17_2_conv[0][0]             
__________________________________________________________________________________________________
block17_2_ac (Activation)       (None, 28, 28, 1088) 0           block17_2[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_14 (Gl (None, 1088)         0           block17_2_ac[0][0]               
__________________________________________________________________________________________________
reshape_14 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_14[0][0]
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 1, 1, 68)     73984       reshape_14[0][0]                 
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 1, 1, 1088)   73984       dense_27[0][0]                   
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, 28, 28, 1088) 0           block17_2_ac[0][0]               
                                                                 dense_28[0][0]                   
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 28, 28, 128)  139264      multiply_14[0][0]                
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 28, 28, 128)  384         conv2d_86[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 28, 28, 128)  0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 28, 28, 160)  143360      activation_86[0][0]              
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 28, 28, 160)  480         conv2d_87[0][0]                  
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 28, 28, 160)  0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 28, 28, 192)  208896      multiply_14[0][0]                
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 28, 28, 192)  215040      activation_87[0][0]              
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 28, 28, 192)  576         conv2d_85[0][0]                  
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 28, 28, 192)  576         conv2d_88[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 28, 28, 192)  0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 28, 28, 192)  0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
block17_3_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_85[0][0]              
                                                                 activation_88[0][0]              
__________________________________________________________________________________________________
block17_3_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_3_mixed[0][0]            
__________________________________________________________________________________________________
block17_3 (Lambda)              (None, 28, 28, 1088) 0           multiply_14[0][0]                
                                                                 block17_3_conv[0][0]             
__________________________________________________________________________________________________
block17_3_ac (Activation)       (None, 28, 28, 1088) 0           block17_3[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_15 (Gl (None, 1088)         0           block17_3_ac[0][0]               
__________________________________________________________________________________________________
reshape_15 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_15[0][0]
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 1, 1, 68)     73984       reshape_15[0][0]                 
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 1, 1, 1088)   73984       dense_29[0][0]                   
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, 28, 28, 1088) 0           block17_3_ac[0][0]               
                                                                 dense_30[0][0]                   
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 28, 28, 128)  139264      multiply_15[0][0]                
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 28, 28, 128)  384         conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 28, 28, 128)  0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 28, 28, 160)  143360      activation_90[0][0]              
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 28, 28, 160)  480         conv2d_91[0][0]                  
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 28, 28, 160)  0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 28, 28, 192)  208896      multiply_15[0][0]                
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 28, 28, 192)  215040      activation_91[0][0]              
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 28, 28, 192)  576         conv2d_89[0][0]                  
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 28, 28, 192)  576         conv2d_92[0][0]                  
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 28, 28, 192)  0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 28, 28, 192)  0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
block17_4_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_89[0][0]              
                                                                 activation_92[0][0]              
__________________________________________________________________________________________________
block17_4_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_4_mixed[0][0]            
__________________________________________________________________________________________________
block17_4 (Lambda)              (None, 28, 28, 1088) 0           multiply_15[0][0]                
                                                                 block17_4_conv[0][0]             
__________________________________________________________________________________________________
block17_4_ac (Activation)       (None, 28, 28, 1088) 0           block17_4[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_16 (Gl (None, 1088)         0           block17_4_ac[0][0]               
__________________________________________________________________________________________________
reshape_16 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_16[0][0]
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1, 1, 68)     73984       reshape_16[0][0]                 
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 1, 1, 1088)   73984       dense_31[0][0]                   
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, 28, 28, 1088) 0           block17_4_ac[0][0]               
                                                                 dense_32[0][0]                   
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 28, 28, 128)  139264      multiply_16[0][0]                
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 28, 28, 128)  384         conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 28, 28, 128)  0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 28, 28, 160)  143360      activation_94[0][0]              
__________________________________________________________________________________________________
batch_normalization_95 (BatchNo (None, 28, 28, 160)  480         conv2d_95[0][0]                  
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 28, 28, 160)  0           batch_normalization_95[0][0]     
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 28, 28, 192)  208896      multiply_16[0][0]                
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 28, 28, 192)  215040      activation_95[0][0]              
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 28, 28, 192)  576         conv2d_93[0][0]                  
__________________________________________________________________________________________________
batch_normalization_96 (BatchNo (None, 28, 28, 192)  576         conv2d_96[0][0]                  
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 28, 28, 192)  0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 28, 28, 192)  0           batch_normalization_96[0][0]     
__________________________________________________________________________________________________
block17_5_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_93[0][0]              
                                                                 activation_96[0][0]              
__________________________________________________________________________________________________
block17_5_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_5_mixed[0][0]            
__________________________________________________________________________________________________
block17_5 (Lambda)              (None, 28, 28, 1088) 0           multiply_16[0][0]                
                                                                 block17_5_conv[0][0]             
__________________________________________________________________________________________________
block17_5_ac (Activation)       (None, 28, 28, 1088) 0           block17_5[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_17 (Gl (None, 1088)         0           block17_5_ac[0][0]               
__________________________________________________________________________________________________
reshape_17 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_17[0][0]
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 1, 1, 68)     73984       reshape_17[0][0]                 
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 1, 1, 1088)   73984       dense_33[0][0]                   
__________________________________________________________________________________________________
multiply_17 (Multiply)          (None, 28, 28, 1088) 0           block17_5_ac[0][0]               
                                                                 dense_34[0][0]                   
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 28, 28, 128)  139264      multiply_17[0][0]                
__________________________________________________________________________________________________
batch_normalization_98 (BatchNo (None, 28, 28, 128)  384         conv2d_98[0][0]                  
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 28, 28, 128)  0           batch_normalization_98[0][0]     
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 28, 28, 160)  143360      activation_98[0][0]              
__________________________________________________________________________________________________
batch_normalization_99 (BatchNo (None, 28, 28, 160)  480         conv2d_99[0][0]                  
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 28, 28, 160)  0           batch_normalization_99[0][0]     
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 28, 28, 192)  208896      multiply_17[0][0]                
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 28, 28, 192)  215040      activation_99[0][0]              
__________________________________________________________________________________________________
batch_normalization_97 (BatchNo (None, 28, 28, 192)  576         conv2d_97[0][0]                  
__________________________________________________________________________________________________
batch_normalization_100 (BatchN (None, 28, 28, 192)  576         conv2d_100[0][0]                 
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 28, 28, 192)  0           batch_normalization_97[0][0]     
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 28, 28, 192)  0           batch_normalization_100[0][0]    
__________________________________________________________________________________________________
block17_6_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_97[0][0]              
                                                                 activation_100[0][0]             
__________________________________________________________________________________________________
block17_6_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_6_mixed[0][0]            
__________________________________________________________________________________________________
block17_6 (Lambda)              (None, 28, 28, 1088) 0           multiply_17[0][0]                
                                                                 block17_6_conv[0][0]             
__________________________________________________________________________________________________
block17_6_ac (Activation)       (None, 28, 28, 1088) 0           block17_6[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_18 (Gl (None, 1088)         0           block17_6_ac[0][0]               
__________________________________________________________________________________________________
reshape_18 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_18[0][0]
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 1, 1, 68)     73984       reshape_18[0][0]                 
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 1, 1, 1088)   73984       dense_35[0][0]                   
__________________________________________________________________________________________________
multiply_18 (Multiply)          (None, 28, 28, 1088) 0           block17_6_ac[0][0]               
                                                                 dense_36[0][0]                   
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 28, 28, 128)  139264      multiply_18[0][0]                
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 28, 28, 128)  384         conv2d_102[0][0]                 
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 28, 28, 128)  0           batch_normalization_102[0][0]    
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 28, 28, 160)  143360      activation_102[0][0]             
__________________________________________________________________________________________________
batch_normalization_103 (BatchN (None, 28, 28, 160)  480         conv2d_103[0][0]                 
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 28, 28, 160)  0           batch_normalization_103[0][0]    
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 28, 28, 192)  208896      multiply_18[0][0]                
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 28, 28, 192)  215040      activation_103[0][0]             
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 28, 28, 192)  576         conv2d_101[0][0]                 
__________________________________________________________________________________________________
batch_normalization_104 (BatchN (None, 28, 28, 192)  576         conv2d_104[0][0]                 
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 28, 28, 192)  0           batch_normalization_101[0][0]    
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 28, 28, 192)  0           batch_normalization_104[0][0]    
__________________________________________________________________________________________________
block17_7_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_101[0][0]             
                                                                 activation_104[0][0]             
__________________________________________________________________________________________________
block17_7_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_7_mixed[0][0]            
__________________________________________________________________________________________________
block17_7 (Lambda)              (None, 28, 28, 1088) 0           multiply_18[0][0]                
                                                                 block17_7_conv[0][0]             
__________________________________________________________________________________________________
block17_7_ac (Activation)       (None, 28, 28, 1088) 0           block17_7[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_19 (Gl (None, 1088)         0           block17_7_ac[0][0]               
__________________________________________________________________________________________________
reshape_19 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_19[0][0]
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 1, 1, 68)     73984       reshape_19[0][0]                 
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 1, 1, 1088)   73984       dense_37[0][0]                   
__________________________________________________________________________________________________
multiply_19 (Multiply)          (None, 28, 28, 1088) 0           block17_7_ac[0][0]               
                                                                 dense_38[0][0]                   
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 28, 28, 128)  139264      multiply_19[0][0]                
__________________________________________________________________________________________________
batch_normalization_106 (BatchN (None, 28, 28, 128)  384         conv2d_106[0][0]                 
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 28, 28, 128)  0           batch_normalization_106[0][0]    
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 28, 28, 160)  143360      activation_106[0][0]             
__________________________________________________________________________________________________
batch_normalization_107 (BatchN (None, 28, 28, 160)  480         conv2d_107[0][0]                 
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 28, 28, 160)  0           batch_normalization_107[0][0]    
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 28, 28, 192)  208896      multiply_19[0][0]                
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 28, 28, 192)  215040      activation_107[0][0]             
__________________________________________________________________________________________________
batch_normalization_105 (BatchN (None, 28, 28, 192)  576         conv2d_105[0][0]                 
__________________________________________________________________________________________________
batch_normalization_108 (BatchN (None, 28, 28, 192)  576         conv2d_108[0][0]                 
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 28, 28, 192)  0           batch_normalization_105[0][0]    
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 28, 28, 192)  0           batch_normalization_108[0][0]    
__________________________________________________________________________________________________
block17_8_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_105[0][0]             
                                                                 activation_108[0][0]             
__________________________________________________________________________________________________
block17_8_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_8_mixed[0][0]            
__________________________________________________________________________________________________
block17_8 (Lambda)              (None, 28, 28, 1088) 0           multiply_19[0][0]                
                                                                 block17_8_conv[0][0]             
__________________________________________________________________________________________________
block17_8_ac (Activation)       (None, 28, 28, 1088) 0           block17_8[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_20 (Gl (None, 1088)         0           block17_8_ac[0][0]               
__________________________________________________________________________________________________
reshape_20 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_20[0][0]
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 1, 1, 68)     73984       reshape_20[0][0]                 
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 1, 1, 1088)   73984       dense_39[0][0]                   
__________________________________________________________________________________________________
multiply_20 (Multiply)          (None, 28, 28, 1088) 0           block17_8_ac[0][0]               
                                                                 dense_40[0][0]                   
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 28, 28, 128)  139264      multiply_20[0][0]                
__________________________________________________________________________________________________
batch_normalization_110 (BatchN (None, 28, 28, 128)  384         conv2d_110[0][0]                 
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 28, 28, 128)  0           batch_normalization_110[0][0]    
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 28, 28, 160)  143360      activation_110[0][0]             
__________________________________________________________________________________________________
batch_normalization_111 (BatchN (None, 28, 28, 160)  480         conv2d_111[0][0]                 
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 28, 28, 160)  0           batch_normalization_111[0][0]    
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 28, 28, 192)  208896      multiply_20[0][0]                
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 28, 28, 192)  215040      activation_111[0][0]             
__________________________________________________________________________________________________
batch_normalization_109 (BatchN (None, 28, 28, 192)  576         conv2d_109[0][0]                 
__________________________________________________________________________________________________
batch_normalization_112 (BatchN (None, 28, 28, 192)  576         conv2d_112[0][0]                 
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 28, 28, 192)  0           batch_normalization_109[0][0]    
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 28, 28, 192)  0           batch_normalization_112[0][0]    
__________________________________________________________________________________________________
block17_9_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_109[0][0]             
                                                                 activation_112[0][0]             
__________________________________________________________________________________________________
block17_9_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_9_mixed[0][0]            
__________________________________________________________________________________________________
block17_9 (Lambda)              (None, 28, 28, 1088) 0           multiply_20[0][0]                
                                                                 block17_9_conv[0][0]             
__________________________________________________________________________________________________
block17_9_ac (Activation)       (None, 28, 28, 1088) 0           block17_9[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_21 (Gl (None, 1088)         0           block17_9_ac[0][0]               
__________________________________________________________________________________________________
reshape_21 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_21[0][0]
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 1, 1, 68)     73984       reshape_21[0][0]                 
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 1, 1, 1088)   73984       dense_41[0][0]                   
__________________________________________________________________________________________________
multiply_21 (Multiply)          (None, 28, 28, 1088) 0           block17_9_ac[0][0]               
                                                                 dense_42[0][0]                   
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 28, 28, 128)  139264      multiply_21[0][0]                
__________________________________________________________________________________________________
batch_normalization_114 (BatchN (None, 28, 28, 128)  384         conv2d_114[0][0]                 
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 28, 28, 128)  0           batch_normalization_114[0][0]    
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 28, 28, 160)  143360      activation_114[0][0]             
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 28, 28, 160)  480         conv2d_115[0][0]                 
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 28, 28, 160)  0           batch_normalization_115[0][0]    
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 28, 28, 192)  208896      multiply_21[0][0]                
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 28, 28, 192)  215040      activation_115[0][0]             
__________________________________________________________________________________________________
batch_normalization_113 (BatchN (None, 28, 28, 192)  576         conv2d_113[0][0]                 
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 28, 28, 192)  576         conv2d_116[0][0]                 
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 28, 28, 192)  0           batch_normalization_113[0][0]    
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 28, 28, 192)  0           batch_normalization_116[0][0]    
__________________________________________________________________________________________________
block17_10_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_113[0][0]             
                                                                 activation_116[0][0]             
__________________________________________________________________________________________________
block17_10_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_10_mixed[0][0]           
__________________________________________________________________________________________________
block17_10 (Lambda)             (None, 28, 28, 1088) 0           multiply_21[0][0]                
                                                                 block17_10_conv[0][0]            
__________________________________________________________________________________________________
block17_10_ac (Activation)      (None, 28, 28, 1088) 0           block17_10[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_22 (Gl (None, 1088)         0           block17_10_ac[0][0]              
__________________________________________________________________________________________________
reshape_22 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_22[0][0]
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 1, 1, 68)     73984       reshape_22[0][0]                 
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 1, 1, 1088)   73984       dense_43[0][0]                   
__________________________________________________________________________________________________
multiply_22 (Multiply)          (None, 28, 28, 1088) 0           block17_10_ac[0][0]              
                                                                 dense_44[0][0]                   
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 28, 28, 128)  139264      multiply_22[0][0]                
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 28, 28, 128)  384         conv2d_118[0][0]                 
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 28, 28, 128)  0           batch_normalization_118[0][0]    
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 28, 28, 160)  143360      activation_118[0][0]             
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 28, 28, 160)  480         conv2d_119[0][0]                 
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 28, 28, 160)  0           batch_normalization_119[0][0]    
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 28, 28, 192)  208896      multiply_22[0][0]                
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 28, 28, 192)  215040      activation_119[0][0]             
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 28, 28, 192)  576         conv2d_117[0][0]                 
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 28, 28, 192)  576         conv2d_120[0][0]                 
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 28, 28, 192)  0           batch_normalization_117[0][0]    
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 28, 28, 192)  0           batch_normalization_120[0][0]    
__________________________________________________________________________________________________
block17_11_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_117[0][0]             
                                                                 activation_120[0][0]             
__________________________________________________________________________________________________
block17_11_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_11_mixed[0][0]           
__________________________________________________________________________________________________
block17_11 (Lambda)             (None, 28, 28, 1088) 0           multiply_22[0][0]                
                                                                 block17_11_conv[0][0]            
__________________________________________________________________________________________________
block17_11_ac (Activation)      (None, 28, 28, 1088) 0           block17_11[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_23 (Gl (None, 1088)         0           block17_11_ac[0][0]              
__________________________________________________________________________________________________
reshape_23 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_23[0][0]
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 1, 1, 68)     73984       reshape_23[0][0]                 
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 1, 1, 1088)   73984       dense_45[0][0]                   
__________________________________________________________________________________________________
multiply_23 (Multiply)          (None, 28, 28, 1088) 0           block17_11_ac[0][0]              
                                                                 dense_46[0][0]                   
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 28, 28, 128)  139264      multiply_23[0][0]                
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 28, 28, 128)  384         conv2d_122[0][0]                 
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 28, 28, 128)  0           batch_normalization_122[0][0]    
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 28, 28, 160)  143360      activation_122[0][0]             
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 28, 28, 160)  480         conv2d_123[0][0]                 
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 28, 28, 160)  0           batch_normalization_123[0][0]    
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 28, 28, 192)  208896      multiply_23[0][0]                
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 28, 28, 192)  215040      activation_123[0][0]             
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 28, 28, 192)  576         conv2d_121[0][0]                 
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 28, 28, 192)  576         conv2d_124[0][0]                 
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 28, 28, 192)  0           batch_normalization_121[0][0]    
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 28, 28, 192)  0           batch_normalization_124[0][0]    
__________________________________________________________________________________________________
block17_12_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_121[0][0]             
                                                                 activation_124[0][0]             
__________________________________________________________________________________________________
block17_12_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_12_mixed[0][0]           
__________________________________________________________________________________________________
block17_12 (Lambda)             (None, 28, 28, 1088) 0           multiply_23[0][0]                
                                                                 block17_12_conv[0][0]            
__________________________________________________________________________________________________
block17_12_ac (Activation)      (None, 28, 28, 1088) 0           block17_12[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_24 (Gl (None, 1088)         0           block17_12_ac[0][0]              
__________________________________________________________________________________________________
reshape_24 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_24[0][0]
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 1, 1, 68)     73984       reshape_24[0][0]                 
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 1, 1, 1088)   73984       dense_47[0][0]                   
__________________________________________________________________________________________________
multiply_24 (Multiply)          (None, 28, 28, 1088) 0           block17_12_ac[0][0]              
                                                                 dense_48[0][0]                   
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 28, 28, 128)  139264      multiply_24[0][0]                
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 28, 28, 128)  384         conv2d_126[0][0]                 
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 28, 28, 128)  0           batch_normalization_126[0][0]    
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 28, 28, 160)  143360      activation_126[0][0]             
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 28, 28, 160)  480         conv2d_127[0][0]                 
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 28, 28, 160)  0           batch_normalization_127[0][0]    
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 28, 28, 192)  208896      multiply_24[0][0]                
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 28, 28, 192)  215040      activation_127[0][0]             
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 28, 28, 192)  576         conv2d_125[0][0]                 
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 28, 28, 192)  576         conv2d_128[0][0]                 
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 28, 28, 192)  0           batch_normalization_125[0][0]    
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 28, 28, 192)  0           batch_normalization_128[0][0]    
__________________________________________________________________________________________________
block17_13_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_125[0][0]             
                                                                 activation_128[0][0]             
__________________________________________________________________________________________________
block17_13_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_13_mixed[0][0]           
__________________________________________________________________________________________________
block17_13 (Lambda)             (None, 28, 28, 1088) 0           multiply_24[0][0]                
                                                                 block17_13_conv[0][0]            
__________________________________________________________________________________________________
block17_13_ac (Activation)      (None, 28, 28, 1088) 0           block17_13[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_25 (Gl (None, 1088)         0           block17_13_ac[0][0]              
__________________________________________________________________________________________________
reshape_25 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_25[0][0]
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 1, 1, 68)     73984       reshape_25[0][0]                 
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 1, 1, 1088)   73984       dense_49[0][0]                   
__________________________________________________________________________________________________
multiply_25 (Multiply)          (None, 28, 28, 1088) 0           block17_13_ac[0][0]              
                                                                 dense_50[0][0]                   
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 28, 28, 128)  139264      multiply_25[0][0]                
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 28, 28, 128)  384         conv2d_130[0][0]                 
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 28, 28, 128)  0           batch_normalization_130[0][0]    
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 28, 28, 160)  143360      activation_130[0][0]             
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 28, 28, 160)  480         conv2d_131[0][0]                 
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 28, 28, 160)  0           batch_normalization_131[0][0]    
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 28, 28, 192)  208896      multiply_25[0][0]                
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 28, 28, 192)  215040      activation_131[0][0]             
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 28, 28, 192)  576         conv2d_129[0][0]                 
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 28, 28, 192)  576         conv2d_132[0][0]                 
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 28, 28, 192)  0           batch_normalization_129[0][0]    
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 28, 28, 192)  0           batch_normalization_132[0][0]    
__________________________________________________________________________________________________
block17_14_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_129[0][0]             
                                                                 activation_132[0][0]             
__________________________________________________________________________________________________
block17_14_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_14_mixed[0][0]           
__________________________________________________________________________________________________
block17_14 (Lambda)             (None, 28, 28, 1088) 0           multiply_25[0][0]                
                                                                 block17_14_conv[0][0]            
__________________________________________________________________________________________________
block17_14_ac (Activation)      (None, 28, 28, 1088) 0           block17_14[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_26 (Gl (None, 1088)         0           block17_14_ac[0][0]              
__________________________________________________________________________________________________
reshape_26 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_26[0][0]
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 1, 1, 68)     73984       reshape_26[0][0]                 
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 1, 1, 1088)   73984       dense_51[0][0]                   
__________________________________________________________________________________________________
multiply_26 (Multiply)          (None, 28, 28, 1088) 0           block17_14_ac[0][0]              
                                                                 dense_52[0][0]                   
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 28, 28, 128)  139264      multiply_26[0][0]                
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 28, 28, 128)  384         conv2d_134[0][0]                 
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 28, 28, 128)  0           batch_normalization_134[0][0]    
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 28, 28, 160)  143360      activation_134[0][0]             
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 28, 28, 160)  480         conv2d_135[0][0]                 
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 28, 28, 160)  0           batch_normalization_135[0][0]    
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 28, 28, 192)  208896      multiply_26[0][0]                
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 28, 28, 192)  215040      activation_135[0][0]             
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 28, 28, 192)  576         conv2d_133[0][0]                 
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 28, 28, 192)  576         conv2d_136[0][0]                 
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 28, 28, 192)  0           batch_normalization_133[0][0]    
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 28, 28, 192)  0           batch_normalization_136[0][0]    
__________________________________________________________________________________________________
block17_15_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_133[0][0]             
                                                                 activation_136[0][0]             
__________________________________________________________________________________________________
block17_15_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_15_mixed[0][0]           
__________________________________________________________________________________________________
block17_15 (Lambda)             (None, 28, 28, 1088) 0           multiply_26[0][0]                
                                                                 block17_15_conv[0][0]            
__________________________________________________________________________________________________
block17_15_ac (Activation)      (None, 28, 28, 1088) 0           block17_15[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_27 (Gl (None, 1088)         0           block17_15_ac[0][0]              
__________________________________________________________________________________________________
reshape_27 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_27[0][0]
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 1, 1, 68)     73984       reshape_27[0][0]                 
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 1, 1, 1088)   73984       dense_53[0][0]                   
__________________________________________________________________________________________________
multiply_27 (Multiply)          (None, 28, 28, 1088) 0           block17_15_ac[0][0]              
                                                                 dense_54[0][0]                   
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 28, 28, 128)  139264      multiply_27[0][0]                
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 28, 28, 128)  384         conv2d_138[0][0]                 
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 28, 28, 128)  0           batch_normalization_138[0][0]    
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 28, 28, 160)  143360      activation_138[0][0]             
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 28, 28, 160)  480         conv2d_139[0][0]                 
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 28, 28, 160)  0           batch_normalization_139[0][0]    
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 28, 28, 192)  208896      multiply_27[0][0]                
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 28, 28, 192)  215040      activation_139[0][0]             
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 28, 28, 192)  576         conv2d_137[0][0]                 
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 28, 28, 192)  576         conv2d_140[0][0]                 
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 28, 28, 192)  0           batch_normalization_137[0][0]    
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 28, 28, 192)  0           batch_normalization_140[0][0]    
__________________________________________________________________________________________________
block17_16_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_137[0][0]             
                                                                 activation_140[0][0]             
__________________________________________________________________________________________________
block17_16_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_16_mixed[0][0]           
__________________________________________________________________________________________________
block17_16 (Lambda)             (None, 28, 28, 1088) 0           multiply_27[0][0]                
                                                                 block17_16_conv[0][0]            
__________________________________________________________________________________________________
block17_16_ac (Activation)      (None, 28, 28, 1088) 0           block17_16[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_28 (Gl (None, 1088)         0           block17_16_ac[0][0]              
__________________________________________________________________________________________________
reshape_28 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_28[0][0]
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 1, 1, 68)     73984       reshape_28[0][0]                 
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 1, 1, 1088)   73984       dense_55[0][0]                   
__________________________________________________________________________________________________
multiply_28 (Multiply)          (None, 28, 28, 1088) 0           block17_16_ac[0][0]              
                                                                 dense_56[0][0]                   
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 28, 28, 128)  139264      multiply_28[0][0]                
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 28, 28, 128)  384         conv2d_142[0][0]                 
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 28, 28, 128)  0           batch_normalization_142[0][0]    
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 28, 28, 160)  143360      activation_142[0][0]             
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 28, 28, 160)  480         conv2d_143[0][0]                 
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 28, 28, 160)  0           batch_normalization_143[0][0]    
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 28, 28, 192)  208896      multiply_28[0][0]                
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 28, 28, 192)  215040      activation_143[0][0]             
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 28, 28, 192)  576         conv2d_141[0][0]                 
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 28, 28, 192)  576         conv2d_144[0][0]                 
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 28, 28, 192)  0           batch_normalization_141[0][0]    
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 28, 28, 192)  0           batch_normalization_144[0][0]    
__________________________________________________________________________________________________
block17_17_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_141[0][0]             
                                                                 activation_144[0][0]             
__________________________________________________________________________________________________
block17_17_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_17_mixed[0][0]           
__________________________________________________________________________________________________
block17_17 (Lambda)             (None, 28, 28, 1088) 0           multiply_28[0][0]                
                                                                 block17_17_conv[0][0]            
__________________________________________________________________________________________________
block17_17_ac (Activation)      (None, 28, 28, 1088) 0           block17_17[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_29 (Gl (None, 1088)         0           block17_17_ac[0][0]              
__________________________________________________________________________________________________
reshape_29 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_29[0][0]
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 1, 1, 68)     73984       reshape_29[0][0]                 
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 1, 1, 1088)   73984       dense_57[0][0]                   
__________________________________________________________________________________________________
multiply_29 (Multiply)          (None, 28, 28, 1088) 0           block17_17_ac[0][0]              
                                                                 dense_58[0][0]                   
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 28, 28, 128)  139264      multiply_29[0][0]                
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 28, 28, 128)  384         conv2d_146[0][0]                 
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 28, 28, 128)  0           batch_normalization_146[0][0]    
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 28, 28, 160)  143360      activation_146[0][0]             
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 28, 28, 160)  480         conv2d_147[0][0]                 
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 28, 28, 160)  0           batch_normalization_147[0][0]    
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 28, 28, 192)  208896      multiply_29[0][0]                
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 28, 28, 192)  215040      activation_147[0][0]             
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 28, 28, 192)  576         conv2d_145[0][0]                 
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 28, 28, 192)  576         conv2d_148[0][0]                 
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 28, 28, 192)  0           batch_normalization_145[0][0]    
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 28, 28, 192)  0           batch_normalization_148[0][0]    
__________________________________________________________________________________________________
block17_18_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_145[0][0]             
                                                                 activation_148[0][0]             
__________________________________________________________________________________________________
block17_18_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_18_mixed[0][0]           
__________________________________________________________________________________________________
block17_18 (Lambda)             (None, 28, 28, 1088) 0           multiply_29[0][0]                
                                                                 block17_18_conv[0][0]            
__________________________________________________________________________________________________
block17_18_ac (Activation)      (None, 28, 28, 1088) 0           block17_18[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_30 (Gl (None, 1088)         0           block17_18_ac[0][0]              
__________________________________________________________________________________________________
reshape_30 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_30[0][0]
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 1, 1, 68)     73984       reshape_30[0][0]                 
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 1, 1, 1088)   73984       dense_59[0][0]                   
__________________________________________________________________________________________________
multiply_30 (Multiply)          (None, 28, 28, 1088) 0           block17_18_ac[0][0]              
                                                                 dense_60[0][0]                   
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 28, 28, 128)  139264      multiply_30[0][0]                
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 28, 28, 128)  384         conv2d_150[0][0]                 
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 28, 28, 128)  0           batch_normalization_150[0][0]    
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 28, 28, 160)  143360      activation_150[0][0]             
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 28, 28, 160)  480         conv2d_151[0][0]                 
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 28, 28, 160)  0           batch_normalization_151[0][0]    
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 28, 28, 192)  208896      multiply_30[0][0]                
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 28, 28, 192)  215040      activation_151[0][0]             
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 28, 28, 192)  576         conv2d_149[0][0]                 
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 28, 28, 192)  576         conv2d_152[0][0]                 
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 28, 28, 192)  0           batch_normalization_149[0][0]    
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 28, 28, 192)  0           batch_normalization_152[0][0]    
__________________________________________________________________________________________________
block17_19_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_149[0][0]             
                                                                 activation_152[0][0]             
__________________________________________________________________________________________________
block17_19_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_19_mixed[0][0]           
__________________________________________________________________________________________________
block17_19 (Lambda)             (None, 28, 28, 1088) 0           multiply_30[0][0]                
                                                                 block17_19_conv[0][0]            
__________________________________________________________________________________________________
block17_19_ac (Activation)      (None, 28, 28, 1088) 0           block17_19[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_31 (Gl (None, 1088)         0           block17_19_ac[0][0]              
__________________________________________________________________________________________________
reshape_31 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_31[0][0]
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 1, 1, 68)     73984       reshape_31[0][0]                 
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 1, 1, 1088)   73984       dense_61[0][0]                   
__________________________________________________________________________________________________
multiply_31 (Multiply)          (None, 28, 28, 1088) 0           block17_19_ac[0][0]              
                                                                 dense_62[0][0]                   
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 28, 28, 128)  139264      multiply_31[0][0]                
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 28, 28, 128)  384         conv2d_154[0][0]                 
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 28, 28, 128)  0           batch_normalization_154[0][0]    
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 28, 28, 160)  143360      activation_154[0][0]             
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 28, 28, 160)  480         conv2d_155[0][0]                 
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 28, 28, 160)  0           batch_normalization_155[0][0]    
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 28, 28, 192)  208896      multiply_31[0][0]                
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 28, 28, 192)  215040      activation_155[0][0]             
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 28, 28, 192)  576         conv2d_153[0][0]                 
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 28, 28, 192)  576         conv2d_156[0][0]                 
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 28, 28, 192)  0           batch_normalization_153[0][0]    
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 28, 28, 192)  0           batch_normalization_156[0][0]    
__________________________________________________________________________________________________
block17_20_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_153[0][0]             
                                                                 activation_156[0][0]             
__________________________________________________________________________________________________
block17_20_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_20_mixed[0][0]           
__________________________________________________________________________________________________
block17_20 (Lambda)             (None, 28, 28, 1088) 0           multiply_31[0][0]                
                                                                 block17_20_conv[0][0]            
__________________________________________________________________________________________________
block17_20_ac (Activation)      (None, 28, 28, 1088) 0           block17_20[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_32 (Gl (None, 1088)         0           block17_20_ac[0][0]              
__________________________________________________________________________________________________
reshape_32 (Reshape)            (None, 1, 1, 1088)   0           global_average_pooling2d_32[0][0]
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 1, 1, 68)     73984       reshape_32[0][0]                 
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 1, 1, 1088)   73984       dense_63[0][0]                   
__________________________________________________________________________________________________
multiply_32 (Multiply)          (None, 28, 28, 1088) 0           block17_20_ac[0][0]              
                                                                 dense_64[0][0]                   
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 28, 28, 256)  278528      multiply_32[0][0]                
__________________________________________________________________________________________________
batch_normalization_161 (BatchN (None, 28, 28, 256)  768         conv2d_161[0][0]                 
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 28, 28, 256)  0           batch_normalization_161[0][0]    
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 28, 28, 256)  278528      multiply_32[0][0]                
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 28, 28, 256)  278528      multiply_32[0][0]                
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 28, 28, 288)  663552      activation_161[0][0]             
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 28, 28, 256)  768         conv2d_157[0][0]                 
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 28, 28, 256)  768         conv2d_159[0][0]                 
__________________________________________________________________________________________________
batch_normalization_162 (BatchN (None, 28, 28, 288)  864         conv2d_162[0][0]                 
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 28, 28, 256)  0           batch_normalization_157[0][0]    
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 28, 28, 256)  0           batch_normalization_159[0][0]    
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 28, 28, 288)  0           batch_normalization_162[0][0]    
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 13, 13, 384)  884736      activation_157[0][0]             
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 13, 13, 288)  663552      activation_159[0][0]             
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 13, 13, 320)  829440      activation_162[0][0]             
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 13, 13, 384)  1152        conv2d_158[0][0]                 
__________________________________________________________________________________________________
batch_normalization_160 (BatchN (None, 13, 13, 288)  864         conv2d_160[0][0]                 
__________________________________________________________________________________________________
batch_normalization_163 (BatchN (None, 13, 13, 320)  960         conv2d_163[0][0]                 
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 13, 13, 384)  0           batch_normalization_158[0][0]    
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 13, 13, 288)  0           batch_normalization_160[0][0]    
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 13, 13, 320)  0           batch_normalization_163[0][0]    
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 1088) 0           multiply_32[0][0]                
__________________________________________________________________________________________________
mixed_7a (Concatenate)          (None, 13, 13, 2080) 0           activation_158[0][0]             
                                                                 activation_160[0][0]             
                                                                 activation_163[0][0]             
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
global_average_pooling2d_33 (Gl (None, 2080)         0           mixed_7a[0][0]                   
__________________________________________________________________________________________________
reshape_33 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_33[0][0]
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 1, 1, 130)    270400      reshape_33[0][0]                 
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 1, 1, 2080)   270400      dense_65[0][0]                   
__________________________________________________________________________________________________
multiply_33 (Multiply)          (None, 13, 13, 2080) 0           mixed_7a[0][0]                   
                                                                 dense_66[0][0]                   
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 13, 13, 192)  399360      multiply_33[0][0]                
__________________________________________________________________________________________________
batch_normalization_165 (BatchN (None, 13, 13, 192)  576         conv2d_165[0][0]                 
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 13, 13, 192)  0           batch_normalization_165[0][0]    
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 13, 13, 224)  129024      activation_165[0][0]             
__________________________________________________________________________________________________
batch_normalization_166 (BatchN (None, 13, 13, 224)  672         conv2d_166[0][0]                 
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 13, 13, 224)  0           batch_normalization_166[0][0]    
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 13, 13, 192)  399360      multiply_33[0][0]                
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 13, 13, 256)  172032      activation_166[0][0]             
__________________________________________________________________________________________________
batch_normalization_164 (BatchN (None, 13, 13, 192)  576         conv2d_164[0][0]                 
__________________________________________________________________________________________________
batch_normalization_167 (BatchN (None, 13, 13, 256)  768         conv2d_167[0][0]                 
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 13, 13, 192)  0           batch_normalization_164[0][0]    
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 13, 13, 256)  0           batch_normalization_167[0][0]    
__________________________________________________________________________________________________
block8_1_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_164[0][0]             
                                                                 activation_167[0][0]             
__________________________________________________________________________________________________
block8_1_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_1_mixed[0][0]             
__________________________________________________________________________________________________
block8_1 (Lambda)               (None, 13, 13, 2080) 0           multiply_33[0][0]                
                                                                 block8_1_conv[0][0]              
__________________________________________________________________________________________________
block8_1_ac (Activation)        (None, 13, 13, 2080) 0           block8_1[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_34 (Gl (None, 2080)         0           block8_1_ac[0][0]                
__________________________________________________________________________________________________
reshape_34 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_34[0][0]
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 1, 1, 130)    270400      reshape_34[0][0]                 
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 1, 1, 2080)   270400      dense_67[0][0]                   
__________________________________________________________________________________________________
multiply_34 (Multiply)          (None, 13, 13, 2080) 0           block8_1_ac[0][0]                
                                                                 dense_68[0][0]                   
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 13, 13, 192)  399360      multiply_34[0][0]                
__________________________________________________________________________________________________
batch_normalization_169 (BatchN (None, 13, 13, 192)  576         conv2d_169[0][0]                 
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 13, 13, 192)  0           batch_normalization_169[0][0]    
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 13, 13, 224)  129024      activation_169[0][0]             
__________________________________________________________________________________________________
batch_normalization_170 (BatchN (None, 13, 13, 224)  672         conv2d_170[0][0]                 
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 13, 13, 224)  0           batch_normalization_170[0][0]    
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 13, 13, 192)  399360      multiply_34[0][0]                
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 13, 13, 256)  172032      activation_170[0][0]             
__________________________________________________________________________________________________
batch_normalization_168 (BatchN (None, 13, 13, 192)  576         conv2d_168[0][0]                 
__________________________________________________________________________________________________
batch_normalization_171 (BatchN (None, 13, 13, 256)  768         conv2d_171[0][0]                 
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 13, 13, 192)  0           batch_normalization_168[0][0]    
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 13, 13, 256)  0           batch_normalization_171[0][0]    
__________________________________________________________________________________________________
block8_2_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_168[0][0]             
                                                                 activation_171[0][0]             
__________________________________________________________________________________________________
block8_2_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_2_mixed[0][0]             
__________________________________________________________________________________________________
block8_2 (Lambda)               (None, 13, 13, 2080) 0           multiply_34[0][0]                
                                                                 block8_2_conv[0][0]              
__________________________________________________________________________________________________
block8_2_ac (Activation)        (None, 13, 13, 2080) 0           block8_2[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_35 (Gl (None, 2080)         0           block8_2_ac[0][0]                
__________________________________________________________________________________________________
reshape_35 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_35[0][0]
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 1, 1, 130)    270400      reshape_35[0][0]                 
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 1, 1, 2080)   270400      dense_69[0][0]                   
__________________________________________________________________________________________________
multiply_35 (Multiply)          (None, 13, 13, 2080) 0           block8_2_ac[0][0]                
                                                                 dense_70[0][0]                   
__________________________________________________________________________________________________
conv2d_173 (Conv2D)             (None, 13, 13, 192)  399360      multiply_35[0][0]                
__________________________________________________________________________________________________
batch_normalization_173 (BatchN (None, 13, 13, 192)  576         conv2d_173[0][0]                 
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 13, 13, 192)  0           batch_normalization_173[0][0]    
__________________________________________________________________________________________________
conv2d_174 (Conv2D)             (None, 13, 13, 224)  129024      activation_173[0][0]             
__________________________________________________________________________________________________
batch_normalization_174 (BatchN (None, 13, 13, 224)  672         conv2d_174[0][0]                 
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 13, 13, 224)  0           batch_normalization_174[0][0]    
__________________________________________________________________________________________________
conv2d_172 (Conv2D)             (None, 13, 13, 192)  399360      multiply_35[0][0]                
__________________________________________________________________________________________________
conv2d_175 (Conv2D)             (None, 13, 13, 256)  172032      activation_174[0][0]             
__________________________________________________________________________________________________
batch_normalization_172 (BatchN (None, 13, 13, 192)  576         conv2d_172[0][0]                 
__________________________________________________________________________________________________
batch_normalization_175 (BatchN (None, 13, 13, 256)  768         conv2d_175[0][0]                 
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 13, 13, 192)  0           batch_normalization_172[0][0]    
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 13, 13, 256)  0           batch_normalization_175[0][0]    
__________________________________________________________________________________________________
block8_3_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_172[0][0]             
                                                                 activation_175[0][0]             
__________________________________________________________________________________________________
block8_3_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_3_mixed[0][0]             
__________________________________________________________________________________________________
block8_3 (Lambda)               (None, 13, 13, 2080) 0           multiply_35[0][0]                
                                                                 block8_3_conv[0][0]              
__________________________________________________________________________________________________
block8_3_ac (Activation)        (None, 13, 13, 2080) 0           block8_3[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_36 (Gl (None, 2080)         0           block8_3_ac[0][0]                
__________________________________________________________________________________________________
reshape_36 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_36[0][0]
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 1, 1, 130)    270400      reshape_36[0][0]                 
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 1, 1, 2080)   270400      dense_71[0][0]                   
__________________________________________________________________________________________________
multiply_36 (Multiply)          (None, 13, 13, 2080) 0           block8_3_ac[0][0]                
                                                                 dense_72[0][0]                   
__________________________________________________________________________________________________
conv2d_177 (Conv2D)             (None, 13, 13, 192)  399360      multiply_36[0][0]                
__________________________________________________________________________________________________
batch_normalization_177 (BatchN (None, 13, 13, 192)  576         conv2d_177[0][0]                 
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 13, 13, 192)  0           batch_normalization_177[0][0]    
__________________________________________________________________________________________________
conv2d_178 (Conv2D)             (None, 13, 13, 224)  129024      activation_177[0][0]             
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 13, 13, 224)  672         conv2d_178[0][0]                 
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 13, 13, 224)  0           batch_normalization_178[0][0]    
__________________________________________________________________________________________________
conv2d_176 (Conv2D)             (None, 13, 13, 192)  399360      multiply_36[0][0]                
__________________________________________________________________________________________________
conv2d_179 (Conv2D)             (None, 13, 13, 256)  172032      activation_178[0][0]             
__________________________________________________________________________________________________
batch_normalization_176 (BatchN (None, 13, 13, 192)  576         conv2d_176[0][0]                 
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 13, 13, 256)  768         conv2d_179[0][0]                 
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 13, 13, 192)  0           batch_normalization_176[0][0]    
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 13, 13, 256)  0           batch_normalization_179[0][0]    
__________________________________________________________________________________________________
block8_4_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_176[0][0]             
                                                                 activation_179[0][0]             
__________________________________________________________________________________________________
block8_4_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_4_mixed[0][0]             
__________________________________________________________________________________________________
block8_4 (Lambda)               (None, 13, 13, 2080) 0           multiply_36[0][0]                
                                                                 block8_4_conv[0][0]              
__________________________________________________________________________________________________
block8_4_ac (Activation)        (None, 13, 13, 2080) 0           block8_4[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_37 (Gl (None, 2080)         0           block8_4_ac[0][0]                
__________________________________________________________________________________________________
reshape_37 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_37[0][0]
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 1, 1, 130)    270400      reshape_37[0][0]                 
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 1, 1, 2080)   270400      dense_73[0][0]                   
__________________________________________________________________________________________________
multiply_37 (Multiply)          (None, 13, 13, 2080) 0           block8_4_ac[0][0]                
                                                                 dense_74[0][0]                   
__________________________________________________________________________________________________
conv2d_181 (Conv2D)             (None, 13, 13, 192)  399360      multiply_37[0][0]                
__________________________________________________________________________________________________
batch_normalization_181 (BatchN (None, 13, 13, 192)  576         conv2d_181[0][0]                 
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 13, 13, 192)  0           batch_normalization_181[0][0]    
__________________________________________________________________________________________________
conv2d_182 (Conv2D)             (None, 13, 13, 224)  129024      activation_181[0][0]             
__________________________________________________________________________________________________
batch_normalization_182 (BatchN (None, 13, 13, 224)  672         conv2d_182[0][0]                 
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 13, 13, 224)  0           batch_normalization_182[0][0]    
__________________________________________________________________________________________________
conv2d_180 (Conv2D)             (None, 13, 13, 192)  399360      multiply_37[0][0]                
__________________________________________________________________________________________________
conv2d_183 (Conv2D)             (None, 13, 13, 256)  172032      activation_182[0][0]             
__________________________________________________________________________________________________
batch_normalization_180 (BatchN (None, 13, 13, 192)  576         conv2d_180[0][0]                 
__________________________________________________________________________________________________
batch_normalization_183 (BatchN (None, 13, 13, 256)  768         conv2d_183[0][0]                 
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 13, 13, 192)  0           batch_normalization_180[0][0]    
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 13, 13, 256)  0           batch_normalization_183[0][0]    
__________________________________________________________________________________________________
block8_5_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_180[0][0]             
                                                                 activation_183[0][0]             
__________________________________________________________________________________________________
block8_5_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_5_mixed[0][0]             
__________________________________________________________________________________________________
block8_5 (Lambda)               (None, 13, 13, 2080) 0           multiply_37[0][0]                
                                                                 block8_5_conv[0][0]              
__________________________________________________________________________________________________
block8_5_ac (Activation)        (None, 13, 13, 2080) 0           block8_5[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_38 (Gl (None, 2080)         0           block8_5_ac[0][0]                
__________________________________________________________________________________________________
reshape_38 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_38[0][0]
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 1, 1, 130)    270400      reshape_38[0][0]                 
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 1, 1, 2080)   270400      dense_75[0][0]                   
__________________________________________________________________________________________________
multiply_38 (Multiply)          (None, 13, 13, 2080) 0           block8_5_ac[0][0]                
                                                                 dense_76[0][0]                   
__________________________________________________________________________________________________
conv2d_185 (Conv2D)             (None, 13, 13, 192)  399360      multiply_38[0][0]                
__________________________________________________________________________________________________
batch_normalization_185 (BatchN (None, 13, 13, 192)  576         conv2d_185[0][0]                 
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 13, 13, 192)  0           batch_normalization_185[0][0]    
__________________________________________________________________________________________________
conv2d_186 (Conv2D)             (None, 13, 13, 224)  129024      activation_185[0][0]             
__________________________________________________________________________________________________
batch_normalization_186 (BatchN (None, 13, 13, 224)  672         conv2d_186[0][0]                 
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 13, 13, 224)  0           batch_normalization_186[0][0]    
__________________________________________________________________________________________________
conv2d_184 (Conv2D)             (None, 13, 13, 192)  399360      multiply_38[0][0]                
__________________________________________________________________________________________________
conv2d_187 (Conv2D)             (None, 13, 13, 256)  172032      activation_186[0][0]             
__________________________________________________________________________________________________
batch_normalization_184 (BatchN (None, 13, 13, 192)  576         conv2d_184[0][0]                 
__________________________________________________________________________________________________
batch_normalization_187 (BatchN (None, 13, 13, 256)  768         conv2d_187[0][0]                 
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 13, 13, 192)  0           batch_normalization_184[0][0]    
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 13, 13, 256)  0           batch_normalization_187[0][0]    
__________________________________________________________________________________________________
block8_6_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_184[0][0]             
                                                                 activation_187[0][0]             
__________________________________________________________________________________________________
block8_6_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_6_mixed[0][0]             
__________________________________________________________________________________________________
block8_6 (Lambda)               (None, 13, 13, 2080) 0           multiply_38[0][0]                
                                                                 block8_6_conv[0][0]              
__________________________________________________________________________________________________
block8_6_ac (Activation)        (None, 13, 13, 2080) 0           block8_6[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_39 (Gl (None, 2080)         0           block8_6_ac[0][0]                
__________________________________________________________________________________________________
reshape_39 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_39[0][0]
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 1, 1, 130)    270400      reshape_39[0][0]                 
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 1, 1, 2080)   270400      dense_77[0][0]                   
__________________________________________________________________________________________________
multiply_39 (Multiply)          (None, 13, 13, 2080) 0           block8_6_ac[0][0]                
                                                                 dense_78[0][0]                   
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 13, 13, 192)  399360      multiply_39[0][0]                
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 13, 13, 192)  576         conv2d_189[0][0]                 
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 13, 13, 192)  0           batch_normalization_189[0][0]    
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 13, 13, 224)  129024      activation_189[0][0]             
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 13, 13, 224)  672         conv2d_190[0][0]                 
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 13, 13, 224)  0           batch_normalization_190[0][0]    
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 13, 13, 192)  399360      multiply_39[0][0]                
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 13, 13, 256)  172032      activation_190[0][0]             
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 13, 13, 192)  576         conv2d_188[0][0]                 
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 13, 13, 256)  768         conv2d_191[0][0]                 
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 13, 13, 192)  0           batch_normalization_188[0][0]    
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 13, 13, 256)  0           batch_normalization_191[0][0]    
__________________________________________________________________________________________________
block8_7_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_188[0][0]             
                                                                 activation_191[0][0]             
__________________________________________________________________________________________________
block8_7_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_7_mixed[0][0]             
__________________________________________________________________________________________________
block8_7 (Lambda)               (None, 13, 13, 2080) 0           multiply_39[0][0]                
                                                                 block8_7_conv[0][0]              
__________________________________________________________________________________________________
block8_7_ac (Activation)        (None, 13, 13, 2080) 0           block8_7[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_40 (Gl (None, 2080)         0           block8_7_ac[0][0]                
__________________________________________________________________________________________________
reshape_40 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_40[0][0]
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 1, 1, 130)    270400      reshape_40[0][0]                 
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 1, 1, 2080)   270400      dense_79[0][0]                   
__________________________________________________________________________________________________
multiply_40 (Multiply)          (None, 13, 13, 2080) 0           block8_7_ac[0][0]                
                                                                 dense_80[0][0]                   
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 13, 13, 192)  399360      multiply_40[0][0]                
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 13, 13, 192)  576         conv2d_193[0][0]                 
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 13, 13, 192)  0           batch_normalization_193[0][0]    
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 13, 13, 224)  129024      activation_193[0][0]             
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 13, 13, 224)  672         conv2d_194[0][0]                 
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 13, 13, 224)  0           batch_normalization_194[0][0]    
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 13, 13, 192)  399360      multiply_40[0][0]                
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 13, 13, 256)  172032      activation_194[0][0]             
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 13, 13, 192)  576         conv2d_192[0][0]                 
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 13, 13, 256)  768         conv2d_195[0][0]                 
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 13, 13, 192)  0           batch_normalization_192[0][0]    
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 13, 13, 256)  0           batch_normalization_195[0][0]    
__________________________________________________________________________________________________
block8_8_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_192[0][0]             
                                                                 activation_195[0][0]             
__________________________________________________________________________________________________
block8_8_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_8_mixed[0][0]             
__________________________________________________________________________________________________
block8_8 (Lambda)               (None, 13, 13, 2080) 0           multiply_40[0][0]                
                                                                 block8_8_conv[0][0]              
__________________________________________________________________________________________________
block8_8_ac (Activation)        (None, 13, 13, 2080) 0           block8_8[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_41 (Gl (None, 2080)         0           block8_8_ac[0][0]                
__________________________________________________________________________________________________
reshape_41 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_41[0][0]
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 1, 1, 130)    270400      reshape_41[0][0]                 
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 1, 1, 2080)   270400      dense_81[0][0]                   
__________________________________________________________________________________________________
multiply_41 (Multiply)          (None, 13, 13, 2080) 0           block8_8_ac[0][0]                
                                                                 dense_82[0][0]                   
__________________________________________________________________________________________________
conv2d_197 (Conv2D)             (None, 13, 13, 192)  399360      multiply_41[0][0]                
__________________________________________________________________________________________________
batch_normalization_197 (BatchN (None, 13, 13, 192)  576         conv2d_197[0][0]                 
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 13, 13, 192)  0           batch_normalization_197[0][0]    
__________________________________________________________________________________________________
conv2d_198 (Conv2D)             (None, 13, 13, 224)  129024      activation_197[0][0]             
__________________________________________________________________________________________________
batch_normalization_198 (BatchN (None, 13, 13, 224)  672         conv2d_198[0][0]                 
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 13, 13, 224)  0           batch_normalization_198[0][0]    
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 13, 13, 192)  399360      multiply_41[0][0]                
__________________________________________________________________________________________________
conv2d_199 (Conv2D)             (None, 13, 13, 256)  172032      activation_198[0][0]             
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 13, 13, 192)  576         conv2d_196[0][0]                 
__________________________________________________________________________________________________
batch_normalization_199 (BatchN (None, 13, 13, 256)  768         conv2d_199[0][0]                 
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 13, 13, 192)  0           batch_normalization_196[0][0]    
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 13, 13, 256)  0           batch_normalization_199[0][0]    
__________________________________________________________________________________________________
block8_9_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_196[0][0]             
                                                                 activation_199[0][0]             
__________________________________________________________________________________________________
block8_9_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_9_mixed[0][0]             
__________________________________________________________________________________________________
block8_9 (Lambda)               (None, 13, 13, 2080) 0           multiply_41[0][0]                
                                                                 block8_9_conv[0][0]              
__________________________________________________________________________________________________
block8_9_ac (Activation)        (None, 13, 13, 2080) 0           block8_9[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_42 (Gl (None, 2080)         0           block8_9_ac[0][0]                
__________________________________________________________________________________________________
reshape_42 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_42[0][0]
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 1, 1, 130)    270400      reshape_42[0][0]                 
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 1, 1, 2080)   270400      dense_83[0][0]                   
__________________________________________________________________________________________________
multiply_42 (Multiply)          (None, 13, 13, 2080) 0           block8_9_ac[0][0]                
                                                                 dense_84[0][0]                   
__________________________________________________________________________________________________
conv2d_201 (Conv2D)             (None, 13, 13, 192)  399360      multiply_42[0][0]                
__________________________________________________________________________________________________
batch_normalization_201 (BatchN (None, 13, 13, 192)  576         conv2d_201[0][0]                 
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 13, 13, 192)  0           batch_normalization_201[0][0]    
__________________________________________________________________________________________________
conv2d_202 (Conv2D)             (None, 13, 13, 224)  129024      activation_201[0][0]             
__________________________________________________________________________________________________
batch_normalization_202 (BatchN (None, 13, 13, 224)  672         conv2d_202[0][0]                 
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 13, 13, 224)  0           batch_normalization_202[0][0]    
__________________________________________________________________________________________________
conv2d_200 (Conv2D)             (None, 13, 13, 192)  399360      multiply_42[0][0]                
__________________________________________________________________________________________________
conv2d_203 (Conv2D)             (None, 13, 13, 256)  172032      activation_202[0][0]             
__________________________________________________________________________________________________
batch_normalization_200 (BatchN (None, 13, 13, 192)  576         conv2d_200[0][0]                 
__________________________________________________________________________________________________
batch_normalization_203 (BatchN (None, 13, 13, 256)  768         conv2d_203[0][0]                 
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 13, 13, 192)  0           batch_normalization_200[0][0]    
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 13, 13, 256)  0           batch_normalization_203[0][0]    
__________________________________________________________________________________________________
block8_10_mixed (Concatenate)   (None, 13, 13, 448)  0           activation_200[0][0]             
                                                                 activation_203[0][0]             
__________________________________________________________________________________________________
block8_10_conv (Conv2D)         (None, 13, 13, 2080) 933920      block8_10_mixed[0][0]            
__________________________________________________________________________________________________
block8_10 (Lambda)              (None, 13, 13, 2080) 0           multiply_42[0][0]                
                                                                 block8_10_conv[0][0]             
__________________________________________________________________________________________________
global_average_pooling2d_43 (Gl (None, 2080)         0           block8_10[0][0]                  
__________________________________________________________________________________________________
reshape_43 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_43[0][0]
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 1, 1, 130)    270400      reshape_43[0][0]                 
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 1, 1, 2080)   270400      dense_85[0][0]                   
__________________________________________________________________________________________________
multiply_43 (Multiply)          (None, 13, 13, 2080) 0           block8_10[0][0]                  
                                                                 dense_86[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_44 (Gl (None, 2080)         0           multiply_43[0][0]                
__________________________________________________________________________________________________
reshape_44 (Reshape)            (None, 1, 1, 2080)   0           global_average_pooling2d_44[0][0]
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 1, 1, 130)    270400      reshape_44[0][0]                 
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 1, 1, 2080)   270400      dense_87[0][0]                   
__________________________________________________________________________________________________
multiply_44 (Multiply)          (None, 13, 13, 2080) 0           multiply_43[0][0]                
                                                                 dense_88[0][0]                   
__________________________________________________________________________________________________
conv_7b (Conv2D)                (None, 13, 13, 1536) 3194880     multiply_44[0][0]                
__________________________________________________________________________________________________
conv_7b_bn (BatchNormalization) (None, 13, 13, 1536) 4608        conv_7b[0][0]                    
__________________________________________________________________________________________________
conv_7b_ac (Activation)         (None, 13, 13, 1536) 0           conv_7b_bn[0][0]                 
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 
__________________________________________________________________________________________________
predictions (Dense)             (None, 103)          158311      avg_pool[0][0]                   
==================================================================================================
Total params: 64,232,775
Trainable params: 64,172,231
Non-trainable params: 60,544
__________________________________________________________________________________________________
None
Epoch 1/7

   1/9924 [..............................] - ETA: 16:06:52 - loss: 0.1749 - top_3_accuracy: 1.0000 - acc: 1.0000
   2/9924 [..............................] - ETA: 8:50:21 - loss: 0.3844 - top_3_accuracy: 1.0000 - acc: 0.8750 
   3/9924 [..............................] - ETA: 6:24:48 - loss: 0.4932 - top_3_accuracy: 0.9583 - acc: 0.8333
   4/9924 [..............................] - ETA: 5:12:02 - loss: 0.4202 - top_3_accuracy: 0.9688 - acc: 0.8438
   5/9924 [..............................] - ETA: 4:28:22 - loss: 0.3849 - top_3_accuracy: 0.9750 - acc: 0.8750
   6/9924 [..............................] - ETA: 3:59:14 - loss: 0.3755 - top_3_accuracy: 0.9792 - acc: 0.8542
   7/9924 [..............................] - ETA: 3:38:25 - loss: 0.3615 - top_3_accuracy: 0.9821 - acc: 0.8571
   8/9924 [..............................] - ETA: 3:22:49 - loss: 0.3818 - top_3_accuracy: 0.9688 - acc: 0.8594
   9/9924 [..............................] - ETA: 3:10:43 - loss: 0.3712 - top_3_accuracy: 0.9722 - acc: 0.8750
  10/9924 [..............................] - ETA: 3:01:01 - loss: 0.3345 - top_3_accuracy: 0.9750 - acc: 0.8875
  11/9924 [..............................] - ETA: 2:53:04 - loss: 0.3296 - top_3_accuracy: 0.9773 - acc: 0.8864
  12/9924 [..............................] - ETA: 2:46:26 - loss: 0.3277 - top_3_accuracy: 0.9792 - acc: 0.8854
  13/9924 [..............................] - ETA: 2:40:49 - loss: 0.3328 - top_3_accuracy: 0.9808 - acc: 0.8750
  14/9924 [..............................] - ETA: 2:36:01 - loss: 0.3163 - top_3_accuracy: 0.9821 - acc: 0.8839
  15/9924 [..............................] - ETA: 2:31:50 - loss: 0.3648 - top_3_accuracy: 0.9750 - acc: 0.8833
  16/9924 [..............................] - ETA: 2:28:12 - loss: 0.3610 - top_3_accuracy: 0.9766 - acc: 0.8828
  17/9924 [..............................] - ETA: 2:24:57 - loss: 0.3495 - top_3_accuracy: 0.9779 - acc: 0.8897
  18/9924 [..............................] - ETA: 2:22:05 - loss: 0.3520 - top_3_accuracy: 0.9792 - acc: 0.8889
  19/9924 [..............................] - ETA: 2:19:31 - loss: 0.3426 - top_3_accuracy: 0.9803 - acc: 0.8947
  20/9924 [..............................] - ETA: 2:17:13 - loss: 0.3414 - top_3_accuracy: 0.9812 - acc: 0.8938
  21/9924 [..............................] - ETA: 2:15:08 - loss: 0.3400 - top_3_accuracy: 0.9821 - acc: 0.8929
  22/9924 [..............................] - ETA: 2:13:14 - loss: 0.3284 - top_3_accuracy: 0.9830 - acc: 0.8977
  23/9924 [..............................] - ETA: 2:11:31 - loss: 0.3289 - top_3_accuracy: 0.9837 - acc: 0.8967
  24/9924 [..............................] - ETA: 2:09:56 - loss: 0.3458 - top_3_accuracy: 0.9792 - acc: 0.8958
  25/9924 [..............................] - ETA: 2:08:28 - loss: 0.3452 - top_3_accuracy: 0.9800 - acc: 0.8950
  26/9924 [..............................] - ETA: 2:07:06 - loss: 0.3492 - top_3_accuracy: 0.9808 - acc: 0.8942
  27/9924 [..............................] - ETA: 2:05:51 - loss: 0.3485 - top_3_accuracy: 0.9815 - acc: 0.8981
  28/9924 [..............................] - ETA: 2:04:41 - loss: 0.3438 - top_3_accuracy: 0.9821 - acc: 0.9018
  29/9924 [..............................] - ETA: 2:03:36 - loss: 0.3374 - top_3_accuracy: 0.9828 - acc: 0.9009
  30/9924 [..............................] - ETA: 2:02:36 - loss: 0.3276 - top_3_accuracy: 0.9833 - acc: 0.9042
  31/9924 [..............................] - ETA: 2:01:39 - loss: 0.3252 - top_3_accuracy: 0.9798 - acc: 0.9032
  32/9924 [..............................] - ETA: 2:00:45 - loss: 0.3608 - top_3_accuracy: 0.9766 - acc: 0.8906
  33/9924 [..............................] - ETA: 1:59:55 - loss: 0.3543 - top_3_accuracy: 0.9773 - acc: 0.8939
  34/9924 [..............................] - ETA: 1:59:08 - loss: 0.3475 - top_3_accuracy: 0.9779 - acc: 0.8971
  35/9924 [..............................] - ETA: 1:58:24 - loss: 0.3487 - top_3_accuracy: 0.9786 - acc: 0.9000
  36/9924 [..............................] - ETA: 1:57:42 - loss: 0.3460 - top_3_accuracy: 0.9792 - acc: 0.8993
  37/9924 [..............................] - ETA: 1:57:02 - loss: 0.3667 - top_3_accuracy: 0.9764 - acc: 0.8953
  38/9924 [..............................] - ETA: 1:56:25 - loss: 0.3587 - top_3_accuracy: 0.9770 - acc: 0.8980
  39/9924 [..............................] - ETA: 1:55:49 - loss: 0.3567 - top_3_accuracy: 0.9776 - acc: 0.8974
  40/9924 [..............................] - ETA: 1:55:16 - loss: 0.3512 - top_3_accuracy: 0.9781 - acc: 0.9000
  41/9924 [..............................] - ETA: 1:54:43 - loss: 0.3522 - top_3_accuracy: 0.9787 - acc: 0.8994
  42/9924 [..............................] - ETA: 1:54:13 - loss: 0.3461 - top_3_accuracy: 0.9792 - acc: 0.9018
  43/9924 [..............................] - ETA: 1:53:43 - loss: 0.3418 - top_3_accuracy: 0.9797 - acc: 0.9041
  44/9924 [..............................] - ETA: 1:53:15 - loss: 0.3412 - top_3_accuracy: 0.9801 - acc: 0.9034
  45/9924 [..............................] - ETA: 1:52:49 - loss: 0.3439 - top_3_accuracy: 0.9806 - acc: 0.9000
  46/9924 [..............................] - ETA: 1:52:23 - loss: 0.3545 - top_3_accuracy: 0.9810 - acc: 0.8940
  47/9924 [..............................] - ETA: 1:51:59 - loss: 0.3612 - top_3_accuracy: 0.9787 - acc: 0.8910
  48/9924 [..............................] - ETA: 1:51:35 - loss: 0.3747 - top_3_accuracy: 0.9792 - acc: 0.8854
  49/9924 [..............................] - ETA: 1:51:13 - loss: 0.3726 - top_3_accuracy: 0.9796 - acc: 0.8878
  50/9924 [..............................] - ETA: 1:50:51 - loss: 0.3729 - top_3_accuracy: 0.9800 - acc: 0.8875
  51/9924 [..............................] - ETA: 1:50:30 - loss: 0.3723 - top_3_accuracy: 0.9804 - acc: 0.8873
  52/9924 [..............................] - ETA: 1:50:10 - loss: 0.3662 - top_3_accuracy: 0.9808 - acc: 0.8894
  53/9924 [..............................] - ETA: 1:49:50 - loss: 0.3740 - top_3_accuracy: 0.9788 - acc: 0.8868
  54/9924 [..............................] - ETA: 1:49:31 - loss: 0.3737 - top_3_accuracy: 0.9792 - acc: 0.8889
  55/9924 [..............................] - ETA: 1:49:13 - loss: 0.3806 - top_3_accuracy: 0.9795 - acc: 0.8886
  56/9924 [..............................] - ETA: 1:48:56 - loss: 0.3770 - top_3_accuracy: 0.9799 - acc: 0.8884
  57/9924 [..............................] - ETA: 1:48:39 - loss: 0.3772 - top_3_accuracy: 0.9803 - acc: 0.8882
  58/9924 [..............................] - ETA: 1:48:23 - loss: 0.3711 - top_3_accuracy: 0.9806 - acc: 0.8901
  59/9924 [..............................] - ETA: 1:48:07 - loss: 0.3832 - top_3_accuracy: 0.9767 - acc: 0.8835
  60/9924 [..............................] - ETA: 1:47:52 - loss: 0.3868 - top_3_accuracy: 0.9771 - acc: 0.8812
  61/9924 [..............................] - ETA: 1:47:37 - loss: 0.3808 - top_3_accuracy: 0.9775 - acc: 0.8832
  62/9924 [..............................] - ETA: 1:47:23 - loss: 0.3852 - top_3_accuracy: 0.9778 - acc: 0.8790
  63/9924 [..............................] - ETA: 1:47:09 - loss: 0.3829 - top_3_accuracy: 0.9782 - acc: 0.8810
  64/9924 [..............................] - ETA: 1:46:56 - loss: 0.3791 - top_3_accuracy: 0.9785 - acc: 0.8828
  65/9924 [..............................] - ETA: 1:46:43 - loss: 0.3873 - top_3_accuracy: 0.9788 - acc: 0.8788
  66/9924 [..............................] - ETA: 1:46:30 - loss: 0.3939 - top_3_accuracy: 0.9792 - acc: 0.8750
  67/9924 [..............................] - ETA: 1:46:18 - loss: 0.3967 - top_3_accuracy: 0.9776 - acc: 0.8750
  68/9924 [..............................] - ETA: 1:46:06 - loss: 0.3977 - top_3_accuracy: 0.9761 - acc: 0.8750
  69/9924 [..............................] - ETA: 1:45:54 - loss: 0.3970 - top_3_accuracy: 0.9764 - acc: 0.8750
  70/9924 [..............................] - ETA: 1:45:43 - loss: 0.3976 - top_3_accuracy: 0.9750 - acc: 0.8750
  71/9924 [..............................] - ETA: 1:45:32 - loss: 0.3988 - top_3_accuracy: 0.9754 - acc: 0.8750
  72/9924 [..............................] - ETA: 1:45:22 - loss: 0.4027 - top_3_accuracy: 0.9757 - acc: 0.8715
  73/9924 [..............................] - ETA: 1:45:11 - loss: 0.4064 - top_3_accuracy: 0.9760 - acc: 0.8699
  74/9924 [..............................] - ETA: 1:45:01 - loss: 0.4098 - top_3_accuracy: 0.9764 - acc: 0.8682
  75/9924 [..............................] - ETA: 1:44:51 - loss: 0.4098 - top_3_accuracy: 0.9767 - acc: 0.8683
  76/9924 [..............................] - ETA: 1:44:41 - loss: 0.4133 - top_3_accuracy: 0.9770 - acc: 0.8684
  77/9924 [..............................] - ETA: 1:44:32 - loss: 0.4145 - top_3_accuracy: 0.9773 - acc: 0.8685
  78/9924 [..............................] - ETA: 1:44:23 - loss: 0.4116 - top_3_accuracy: 0.9776 - acc: 0.8702
  79/9924 [..............................] - ETA: 1:44:14 - loss: 0.4104 - top_3_accuracy: 0.9778 - acc: 0.8703
  80/9924 [..............................] - ETA: 1:44:05 - loss: 0.4116 - top_3_accuracy: 0.9766 - acc: 0.8703
  81/9924 [..............................] - ETA: 1:43:56 - loss: 0.4176 - top_3_accuracy: 0.9769 - acc: 0.8673
  82/9924 [..............................] - ETA: 1:43:48 - loss: 0.4154 - top_3_accuracy: 0.9771 - acc: 0.8689
  83/9924 [..............................] - ETA: 1:43:40 - loss: 0.4147 - top_3_accuracy: 0.9774 - acc: 0.8690
  84/9924 [..............................] - ETA: 1:43:32 - loss: 0.4149 - top_3_accuracy: 0.9777 - acc: 0.8705
  85/9924 [..............................] - ETA: 1:43:24 - loss: 0.4163 - top_3_accuracy: 0.9765 - acc: 0.8706
  86/9924 [..............................] - ETA: 1:43:17 - loss: 0.4242 - top_3_accuracy: 0.9738 - acc: 0.8692
  87/9924 [..............................] - ETA: 1:43:09 - loss: 0.4295 - top_3_accuracy: 0.9727 - acc: 0.8678
  88/9924 [..............................] - ETA: 1:43:02 - loss: 0.4285 - top_3_accuracy: 0.9730 - acc: 0.8679
  89/9924 [..............................] - ETA: 1:42:55 - loss: 0.4284 - top_3_accuracy: 0.9733 - acc: 0.8680
  90/9924 [..............................] - ETA: 1:42:48 - loss: 0.4248 - top_3_accuracy: 0.9736 - acc: 0.8694
  91/9924 [..............................] - ETA: 1:42:41 - loss: 0.4235 - top_3_accuracy: 0.9739 - acc: 0.8695
  92/9924 [..............................] - ETA: 1:42:34 - loss: 0.4247 - top_3_accuracy: 0.9742 - acc: 0.8682
  93/9924 [..............................] - ETA: 1:42:27 - loss: 0.4309 - top_3_accuracy: 0.9718 - acc: 0.8656
  94/9924 [..............................] - ETA: 1:42:21 - loss: 0.4368 - top_3_accuracy: 0.9721 - acc: 0.8630
  95/9924 [..............................] - ETA: 1:42:15 - loss: 0.4332 - top_3_accuracy: 0.9724 - acc: 0.8645
  96/9924 [..............................] - ETA: 1:42:08 - loss: 0.4369 - top_3_accuracy: 0.9714 - acc: 0.8646
  97/9924 [..............................] - ETA: 1:42:02 - loss: 0.4347 - top_3_accuracy: 0.9716 - acc: 0.8660
  98/9924 [..............................] - ETA: 1:41:56 - loss: 0.4330 - top_3_accuracy: 0.9719 - acc: 0.8673
  99/9924 [..............................] - ETA: 1:41:50 - loss: 0.4345 - top_3_accuracy: 0.9722 - acc: 0.8649
 100/9924 [..............................] - ETA: 1:41:45 - loss: 0.4359 - top_3_accuracy: 0.9725 - acc: 0.8625
 101/9924 [..............................] - ETA: 1:41:39 - loss: 0.4349 - top_3_accuracy: 0.9728 - acc: 0.8614
 102/9924 [..............................] - ETA: 1:41:33 - loss: 0.4354 - top_3_accuracy: 0.9730 - acc: 0.8603
 103/9924 [..............................] - ETA: 1:41:28 - loss: 0.4376 - top_3_accuracy: 0.9733 - acc: 0.8604
 104/9924 [..............................] - ETA: 1:41:22 - loss: 0.4469 - top_3_accuracy: 0.9724 - acc: 0.8582
 105/9924 [..............................] - ETA: 1:41:17 - loss: 0.4492 - top_3_accuracy: 0.9714 - acc: 0.8583
 106/9924 [..............................] - ETA: 1:41:12 - loss: 0.4530 - top_3_accuracy: 0.9705 - acc: 0.8573
 107/9924 [..............................] - ETA: 1:41:07 - loss: 0.4570 - top_3_accuracy: 0.9696 - acc: 0.8575
 108/9924 [..............................] - ETA: 1:41:02 - loss: 0.4598 - top_3_accuracy: 0.9688 - acc: 0.8553
 109/9924 [..............................] - ETA: 1:40:57 - loss: 0.4615 - top_3_accuracy: 0.9690 - acc: 0.8532
 110/9924 [..............................] - ETA: 1:40:52 - loss: 0.4652 - top_3_accuracy: 0.9693 - acc: 0.8500
 111/9924 [..............................] - ETA: 1:40:47 - loss: 0.4727 - top_3_accuracy: 0.9685 - acc: 0.8480
 112/9924 [..............................] - ETA: 1:40:43 - loss: 0.4737 - top_3_accuracy: 0.9676 - acc: 0.8482
 113/9924 [..............................] - ETA: 1:40:38 - loss: 0.4767 - top_3_accuracy: 0.9668 - acc: 0.8473
 114/9924 [..............................] - ETA: 1:40:34 - loss: 0.4763 - top_3_accuracy: 0.9660 - acc: 0.8476
 115/9924 [..............................] - ETA: 1:40:29 - loss: 0.4740 - top_3_accuracy: 0.9663 - acc: 0.8489
 116/9924 [..............................] - ETA: 1:40:25 - loss: 0.4729 - top_3_accuracy: 0.9666 - acc: 0.8491
 117/9924 [..............................] - ETA: 1:40:21 - loss: 0.4707 - top_3_accuracy: 0.9669 - acc: 0.8494
 118/9924 [..............................] - ETA: 1:40:16 - loss: 0.4675 - top_3_accuracy: 0.9672 - acc: 0.8506
 119/9924 [..............................] - ETA: 1:40:12 - loss: 0.4657 - top_3_accuracy: 0.9674 - acc: 0.8508
 120/9924 [..............................] - ETA: 1:40:08 - loss: 0.4630 - top_3_accuracy: 0.9677 - acc: 0.8521
 121/9924 [..............................] - ETA: 1:40:04 - loss: 0.4661 - top_3_accuracy: 0.9680 - acc: 0.8512
 122/9924 [..............................] - ETA: 1:40:00 - loss: 0.4636 - top_3_accuracy: 0.9682 - acc: 0.8525
 123/9924 [..............................] - ETA: 1:39:56 - loss: 0.4674 - top_3_accuracy: 0.9685 - acc: 0.8516
 124/9924 [..............................] - ETA: 1:39:52 - loss: 0.4697 - top_3_accuracy: 0.9677 - acc: 0.8508
 125/9924 [..............................] - ETA: 1:39:48 - loss: 0.4705 - top_3_accuracy: 0.9670 - acc: 0.8510
 126/9924 [..............................] - ETA: 1:39:44 - loss: 0.4686 - top_3_accuracy: 0.9673 - acc: 0.8512
 127/9924 [..............................] - ETA: 1:39:41 - loss: 0.4681 - top_3_accuracy: 0.9675 - acc: 0.8514
 128/9924 [..............................] - ETA: 1:39:37 - loss: 0.4653 - top_3_accuracy: 0.9678 - acc: 0.8525
 129/9924 [..............................] - ETA: 1:39:34 - loss: 0.4646 - top_3_accuracy: 0.9680 - acc: 0.8527
 130/9924 [..............................] - ETA: 1:39:30 - loss: 0.4613 - top_3_accuracy: 0.9683 - acc: 0.8538
 131/9924 [..............................] - ETA: 1:39:26 - loss: 0.4608 - top_3_accuracy: 0.9676 - acc: 0.8540
 132/9924 [..............................] - ETA: 1:39:23 - loss: 0.4600 - top_3_accuracy: 0.9678 - acc: 0.8532
 133/9924 [..............................] - ETA: 1:39:20 - loss: 0.4620 - top_3_accuracy: 0.9680 - acc: 0.8524
 134/9924 [..............................] - ETA: 1:39:16 - loss: 0.4594 - top_3_accuracy: 0.9683 - acc: 0.8535
 135/9924 [..............................] - ETA: 1:39:13 - loss: 0.4626 - top_3_accuracy: 0.9685 - acc: 0.8528
 136/9924 [..............................] - ETA: 1:39:09 - loss: 0.4647 - top_3_accuracy: 0.9678 - acc: 0.8529
 137/9924 [..............................] - ETA: 1:39:06 - loss: 0.4625 - top_3_accuracy: 0.9681 - acc: 0.8531
 138/9924 [..............................] - ETA: 1:39:03 - loss: 0.4644 - top_3_accuracy: 0.9683 - acc: 0.8524
 139/9924 [..............................] - ETA: 1:39:00 - loss: 0.4621 - top_3_accuracy: 0.9685 - acc: 0.8534
 140/9924 [..............................] - ETA: 1:38:57 - loss: 0.4606 - top_3_accuracy: 0.9688 - acc: 0.8545
 141/9924 [..............................] - ETA: 1:38:53 - loss: 0.4607 - top_3_accuracy: 0.9690 - acc: 0.8537
 142/9924 [..............................] - ETA: 1:38:50 - loss: 0.4634 - top_3_accuracy: 0.9674 - acc: 0.8530
 143/9924 [..............................] - ETA: 1:38:47 - loss: 0.4611 - top_3_accuracy: 0.9677 - acc: 0.8540
 144/9924 [..............................] - ETA: 1:38:44 - loss: 0.4588 - top_3_accuracy: 0.9679 - acc: 0.8550
 145/9924 [..............................] - ETA: 1:38:41 - loss: 0.4563 - top_3_accuracy: 0.9681 - acc: 0.8560
 146/9924 [..............................] - ETA: 1:38:38 - loss: 0.4578 - top_3_accuracy: 0.9683 - acc: 0.8553
 147/9924 [..............................] - ETA: 1:38:35 - loss: 0.4558 - top_3_accuracy: 0.9685 - acc: 0.8563
 148/9924 [..............................] - ETA: 1:38:32 - loss: 0.4558 - top_3_accuracy: 0.9679 - acc: 0.8556
 149/9924 [..............................] - ETA: 1:38:30 - loss: 0.4559 - top_3_accuracy: 0.9681 - acc: 0.8549
 150/9924 [..............................] - ETA: 1:38:27 - loss: 0.4547 - top_3_accuracy: 0.9683 - acc: 0.8550
 151/9924 [..............................] - ETA: 1:38:24 - loss: 0.4518 - top_3_accuracy: 0.9685 - acc: 0.8560
 152/9924 [..............................] - ETA: 1:38:21 - loss: 0.4547 - top_3_accuracy: 0.9679 - acc: 0.8561
 153/9924 [..............................] - ETA: 1:38:19 - loss: 0.4530 - top_3_accuracy: 0.9681 - acc: 0.8570
 154/9924 [..............................] - ETA: 1:38:16 - loss: 0.4531 - top_3_accuracy: 0.9675 - acc: 0.8571
 155/9924 [..............................] - ETA: 1:38:13 - loss: 0.4560 - top_3_accuracy: 0.9669 - acc: 0.8565
 156/9924 [..............................] - ETA: 1:38:11 - loss: 0.4532 - top_3_accuracy: 0.9671 - acc: 0.8574
 157/9924 [..............................] - ETA: 1:38:08 - loss: 0.4540 - top_3_accuracy: 0.9674 - acc: 0.8567
 158/9924 [..............................] - ETA: 1:38:06 - loss: 0.4529 - top_3_accuracy: 0.9676 - acc: 0.8568
 159/9924 [..............................] - ETA: 1:38:03 - loss: 0.4576 - top_3_accuracy: 0.9678 - acc: 0.8553
 160/9924 [..............................] - ETA: 1:38:00 - loss: 0.4554 - top_3_accuracy: 0.9680 - acc: 0.8562
 161/9924 [..............................] - ETA: 1:37:58 - loss: 0.4555 - top_3_accuracy: 0.9682 - acc: 0.8556
 162/9924 [..............................] - ETA: 1:37:55 - loss: 0.4590 - top_3_accuracy: 0.9676 - acc: 0.8542
 163/9924 [..............................] - ETA: 1:37:53 - loss: 0.4589 - top_3_accuracy: 0.9678 - acc: 0.8535
 164/9924 [..............................] - ETA: 1:37:51 - loss: 0.4582 - top_3_accuracy: 0.9680 - acc: 0.8537
 165/9924 [..............................] - ETA: 1:37:48 - loss: 0.4570 - top_3_accuracy: 0.9682 - acc: 0.8545
 166/9924 [..............................] - ETA: 1:37:46 - loss: 0.4568 - top_3_accuracy: 0.9676 - acc: 0.8547
 167/9924 [..............................] - ETA: 1:37:43 - loss: 0.4593 - top_3_accuracy: 0.9671 - acc: 0.8540
 168/9924 [..............................] - ETA: 1:37:41 - loss: 0.4612 - top_3_accuracy: 0.9665 - acc: 0.8542
 169/9924 [..............................] - ETA: 1:37:39 - loss: 0.4593 - top_3_accuracy: 0.9667 - acc: 0.8550
 170/9924 [..............................] - ETA: 1:37:36 - loss: 0.4575 - top_3_accuracy: 0.9669 - acc: 0.8559
 171/9924 [..............................] - ETA: 1:37:34 - loss: 0.4562 - top_3_accuracy: 0.9671 - acc: 0.8567
 172/9924 [..............................] - ETA: 1:37:32 - loss: 0.4559 - top_3_accuracy: 0.9673 - acc: 0.8568
 173/9924 [..............................] - ETA: 1:37:30 - loss: 0.4563 - top_3_accuracy: 0.9668 - acc: 0.8569
 174/9924 [..............................] - ETA: 1:37:27 - loss: 0.4567 - top_3_accuracy: 0.9670 - acc: 0.8570
 175/9924 [..............................] - ETA: 1:37:25 - loss: 0.4549 - top_3_accuracy: 0.9671 - acc: 0.8579
 176/9924 [..............................] - ETA: 1:37:23 - loss: 0.4528 - top_3_accuracy: 0.9673 - acc: 0.8587
 177/9924 [..............................] - ETA: 1:37:21 - loss: 0.4550 - top_3_accuracy: 0.9675 - acc: 0.8588
 178/9924 [..............................] - ETA: 1:37:19 - loss: 0.4536 - top_3_accuracy: 0.9677 - acc: 0.8588
 179/9924 [..............................] - ETA: 1:37:16 - loss: 0.4548 - top_3_accuracy: 0.9672 - acc: 0.8589
 180/9924 [..............................] - ETA: 1:37:14 - loss: 0.4543 - top_3_accuracy: 0.9667 - acc: 0.8590
 181/9924 [..............................] - ETA: 1:37:12 - loss: 0.4538 - top_3_accuracy: 0.9669 - acc: 0.8591
 182/9924 [..............................] - ETA: 1:37:10 - loss: 0.4551 - top_3_accuracy: 0.9663 - acc: 0.8585
 183/9924 [..............................] - ETA: 1:37:08 - loss: 0.4539 - top_3_accuracy: 0.9665 - acc: 0.8593
 184/9924 [..............................] - ETA: 1:37:06 - loss: 0.4527 - top_3_accuracy: 0.9667 - acc: 0.8594
 185/9924 [..............................] - ETA: 1:37:04 - loss: 0.4535 - top_3_accuracy: 0.9662 - acc: 0.8595
 186/9924 [..............................] - ETA: 1:37:02 - loss: 0.4532 - top_3_accuracy: 0.9664 - acc: 0.8595
 187/9924 [..............................] - ETA: 1:37:00 - loss: 0.4524 - top_3_accuracy: 0.9666 - acc: 0.8596
 188/9924 [..............................] - ETA: 1:36:58 - loss: 0.4533 - top_3_accuracy: 0.9668 - acc: 0.8584
 189/9924 [..............................] - ETA: 1:36:56 - loss: 0.4536 - top_3_accuracy: 0.9669 - acc: 0.8578
 190/9924 [..............................] - ETA: 1:36:54 - loss: 0.4541 - top_3_accuracy: 0.9664 - acc: 0.8579
 191/9924 [..............................] - ETA: 1:36:52 - loss: 0.4547 - top_3_accuracy: 0.9666 - acc: 0.8573
 192/9924 [..............................] - ETA: 1:36:50 - loss: 0.4543 - top_3_accuracy: 0.9668 - acc: 0.8574
 193/9924 [..............................] - ETA: 1:36:48 - loss: 0.4535 - top_3_accuracy: 0.9670 - acc: 0.8575
 194/9924 [..............................] - ETA: 1:36:46 - loss: 0.4523 - top_3_accuracy: 0.9671 - acc: 0.8582
 195/9924 [..............................] - ETA: 1:36:44 - loss: 0.4526 - top_3_accuracy: 0.9673 - acc: 0.8590
 196/9924 [..............................] - ETA: 1:36:43 - loss: 0.4561 - top_3_accuracy: 0.9662 - acc: 0.8578
 197/9924 [..............................] - ETA: 1:36:41 - loss: 0.4560 - top_3_accuracy: 0.9664 - acc: 0.8585
 198/9924 [..............................] - ETA: 1:36:39 - loss: 0.4575 - top_3_accuracy: 0.9659 - acc: 0.8580
 199/9924 [..............................] - ETA: 1:36:37 - loss: 0.4567 - top_3_accuracy: 0.9661 - acc: 0.8574
 200/9924 [..............................] - ETA: 1:36:35 - loss: 0.4555 - top_3_accuracy: 0.9663 - acc: 0.8575
 201/9924 [..............................] - ETA: 1:36:33 - loss: 0.4612 - top_3_accuracy: 0.9652 - acc: 0.8563
 202/9924 [..............................] - ETA: 1:36:32 - loss: 0.4622 - top_3_accuracy: 0.9647 - acc: 0.8558
 203/9924 [..............................] - ETA: 1:36:30 - loss: 0.4618 - top_3_accuracy: 0.9649 - acc: 0.8559
 204/9924 [..............................] - ETA: 1:36:28 - loss: 0.4621 - top_3_accuracy: 0.9651 - acc: 0.8560
 205/9924 [..............................] - ETA: 1:36:26 - loss: 0.4619 - top_3_accuracy: 0.9652 - acc: 0.8555
 206/9924 [..............................] - ETA: 1:36:24 - loss: 0.4621 - top_3_accuracy: 0.9654 - acc: 0.8556
 207/9924 [..............................] - ETA: 1:36:23 - loss: 0.4620 - top_3_accuracy: 0.9650 - acc: 0.8557
 208/9924 [..............................] - ETA: 1:36:21 - loss: 0.4621 - top_3_accuracy: 0.9645 - acc: 0.8558
 209/9924 [..............................] - ETA: 1:36:19 - loss: 0.4619 - top_3_accuracy: 0.9647 - acc: 0.8559
 210/9924 [..............................] - ETA: 1:36:17 - loss: 0.4661 - top_3_accuracy: 0.9637 - acc: 0.8548
 211/9924 [..............................] - ETA: 1:36:16 - loss: 0.4673 - top_3_accuracy: 0.9639 - acc: 0.8543
 212/9924 [..............................] - ETA: 1:36:14 - loss: 0.4717 - top_3_accuracy: 0.9634 - acc: 0.8526
 213/9924 [..............................] - ETA: 1:36:12 - loss: 0.4710 - top_3_accuracy: 0.9636 - acc: 0.8527
 214/9924 [..............................] - ETA: 1:36:11 - loss: 0.4703 - top_3_accuracy: 0.9638 - acc: 0.8528
 215/9924 [..............................] - ETA: 1:36:09 - loss: 0.4713 - top_3_accuracy: 0.9634 - acc: 0.8523
 216/9924 [..............................] - ETA: 1:36:07 - loss: 0.4707 - top_3_accuracy: 0.9635 - acc: 0.8524
 217/9924 [..............................] - ETA: 1:36:06 - loss: 0.4704 - top_3_accuracy: 0.9637 - acc: 0.8525
 218/9924 [..............................] - ETA: 1:36:04 - loss: 0.4700 - top_3_accuracy: 0.9633 - acc: 0.8526
 219/9924 [..............................] - ETA: 1:36:02 - loss: 0.4690 - top_3_accuracy: 0.9635 - acc: 0.8533
 220/9924 [..............................] - ETA: 1:36:01 - loss: 0.4679 - top_3_accuracy: 0.9636 - acc: 0.8540
 221/9924 [..............................] - ETA: 1:35:59 - loss: 0.4672 - top_3_accuracy: 0.9638 - acc: 0.8541
 222/9924 [..............................] - ETA: 1:35:58 - loss: 0.4665 - top_3_accuracy: 0.9640 - acc: 0.8547
 223/9924 [..............................] - ETA: 1:35:56 - loss: 0.4672 - top_3_accuracy: 0.9641 - acc: 0.8543
 224/9924 [..............................] - ETA: 1:35:55 - loss: 0.4684 - top_3_accuracy: 0.9637 - acc: 0.8538
 225/9924 [..............................] - ETA: 1:35:53 - loss: 0.4668 - top_3_accuracy: 0.9639 - acc: 0.8544
 226/9924 [..............................] - ETA: 1:35:52 - loss: 0.4674 - top_3_accuracy: 0.9640 - acc: 0.8545
 227/9924 [..............................] - ETA: 1:35:50 - loss: 0.4664 - top_3_accuracy: 0.9642 - acc: 0.8552
 228/9924 [..............................] - ETA: 1:35:48 - loss: 0.4664 - top_3_accuracy: 0.9644 - acc: 0.8547
 229/9924 [..............................] - ETA: 1:35:47 - loss: 0.4668 - top_3_accuracy: 0.9645 - acc: 0.8543
 230/9924 [..............................] - ETA: 1:35:45 - loss: 0.4653 - top_3_accuracy: 0.9647 - acc: 0.8549
 231/9924 [..............................] - ETA: 1:35:44 - loss: 0.4642 - top_3_accuracy: 0.9648 - acc: 0.8550
 232/9924 [..............................] - ETA: 1:35:42 - loss: 0.4645 - top_3_accuracy: 0.9650 - acc: 0.8545
 233/9924 [..............................] - ETA: 1:35:41 - loss: 0.4640 - top_3_accuracy: 0.9651 - acc: 0.8552
 234/9924 [..............................] - ETA: 1:35:39 - loss: 0.4642 - top_3_accuracy: 0.9647 - acc: 0.8547
 235/9924 [..............................] - ETA: 1:35:38 - loss: 0.4665 - top_3_accuracy: 0.9638 - acc: 0.8543
 236/9924 [..............................] - ETA: 1:35:37 - loss: 0.4652 - top_3_accuracy: 0.9640 - acc: 0.8549
 237/9924 [..............................] - ETA: 1:35:35 - loss: 0.4646 - top_3_accuracy: 0.9641 - acc: 0.8555
 238/9924 [..............................] - ETA: 1:35:34 - loss: 0.4646 - top_3_accuracy: 0.9643 - acc: 0.8556
 239/9924 [..............................] - ETA: 1:35:32 - loss: 0.4685 - top_3_accuracy: 0.9634 - acc: 0.8546
 240/9924 [..............................] - ETA: 1:35:31 - loss: 0.4697 - top_3_accuracy: 0.9635 - acc: 0.8536
 241/9924 [..............................] - ETA: 1:35:30 - loss: 0.4744 - top_3_accuracy: 0.9632 - acc: 0.8522
 242/9924 [..............................] - ETA: 1:35:28 - loss: 0.4742 - top_3_accuracy: 0.9633 - acc: 0.8518
 243/9924 [..............................] - ETA: 1:35:27 - loss: 0.4724 - top_3_accuracy: 0.9635 - acc: 0.8524
 244/9924 [..............................] - ETA: 1:35:26 - loss: 0.4707 - top_3_accuracy: 0.9636 - acc: 0.8530
 245/9924 [..............................] - ETA: 1:35:24 - loss: 0.4701 - top_3_accuracy: 0.9633 - acc: 0.8531
 246/9924 [..............................] - ETA: 1:35:23 - loss: 0.4686 - top_3_accuracy: 0.9634 - acc: 0.8537
 247/9924 [..............................] - ETA: 1:35:22 - loss: 0.4710 - top_3_accuracy: 0.9631 - acc: 0.8527
 248/9924 [..............................] - ETA: 1:35:20 - loss: 0.4750 - top_3_accuracy: 0.9622 - acc: 0.8513
 249/9924 [..............................] - ETA: 1:35:19 - loss: 0.4745 - top_3_accuracy: 0.9623 - acc: 0.8514
 250/9924 [..............................] - ETA: 1:35:18 - loss: 0.4742 - top_3_accuracy: 0.9625 - acc: 0.8515
 251/9924 [..............................] - ETA: 1:35:16 - loss: 0.4728 - top_3_accuracy: 0.9626 - acc: 0.8521
 252/9924 [..............................] - ETA: 1:35:15 - loss: 0.4714 - top_3_accuracy: 0.9628 - acc: 0.8527
 253/9924 [..............................] - ETA: 1:35:14 - loss: 0.4712 - top_3_accuracy: 0.9629 - acc: 0.8523
 254/9924 [..............................] - ETA: 1:35:12 - loss: 0.4759 - top_3_accuracy: 0.9626 - acc: 0.8504
 255/9924 [..............................] - ETA: 1:35:11 - loss: 0.4753 - top_3_accuracy: 0.9627 - acc: 0.8505
 256/9924 [..............................] - ETA: 1:35:10 - loss: 0.4790 - top_3_accuracy: 0.9619 - acc: 0.8501
 257/9924 [..............................] - ETA: 1:35:09 - loss: 0.4788 - top_3_accuracy: 0.9621 - acc: 0.8507
 258/9924 [..............................] - ETA: 1:35:07 - loss: 0.4812 - top_3_accuracy: 0.9622 - acc: 0.8493
 259/9924 [..............................] - ETA: 1:35:06 - loss: 0.4805 - top_3_accuracy: 0.9624 - acc: 0.8494
 260/9924 [..............................] - ETA: 1:35:05 - loss: 0.4816 - top_3_accuracy: 0.9620 - acc: 0.8490
 261/9924 [..............................] - ETA: 1:35:03 - loss: 0.4804 - top_3_accuracy: 0.9622 - acc: 0.8496
 262/9924 [..............................] - ETA: 1:35:02 - loss: 0.4804 - top_3_accuracy: 0.9623 - acc: 0.8492
 263/9924 [..............................] - ETA: 1:35:01 - loss: 0.4820 - top_3_accuracy: 0.9620 - acc: 0.8489
 264/9924 [..............................] - ETA: 1:35:00 - loss: 0.4828 - top_3_accuracy: 0.9621 - acc: 0.8490
 265/9924 [..............................] - ETA: 1:34:58 - loss: 0.4828 - top_3_accuracy: 0.9623 - acc: 0.8486
 266/9924 [..............................] - ETA: 1:34:57 - loss: 0.4842 - top_3_accuracy: 0.9619 - acc: 0.8482
 267/9924 [..............................] - ETA: 1:34:56 - loss: 0.4834 - top_3_accuracy: 0.9621 - acc: 0.8483
 268/9924 [..............................] - ETA: 1:34:55 - loss: 0.4841 - top_3_accuracy: 0.9618 - acc: 0.8479
 269/9924 [..............................] - ETA: 1:34:54 - loss: 0.4848 - top_3_accuracy: 0.9614 - acc: 0.8480
 270/9924 [..............................] - ETA: 1:34:52 - loss: 0.4876 - top_3_accuracy: 0.9606 - acc: 0.8468
 271/9924 [..............................] - ETA: 1:34:51 - loss: 0.4870 - top_3_accuracy: 0.9608 - acc: 0.8464
 272/9924 [..............................] - ETA: 1:34:50 - loss: 0.4868 - top_3_accuracy: 0.9605 - acc: 0.8465
 273/9924 [..............................] - ETA: 1:34:49 - loss: 0.4857 - top_3_accuracy: 0.9606 - acc: 0.8471
 274/9924 [..............................] - ETA: 1:34:48 - loss: 0.4851 - top_3_accuracy: 0.9608 - acc: 0.8476
 275/9924 [..............................] - ETA: 1:34:46 - loss: 0.4844 - top_3_accuracy: 0.9609 - acc: 0.8477
 276/9924 [..............................] - ETA: 1:34:45 - loss: 0.4837 - top_3_accuracy: 0.9611 - acc: 0.8483
 277/9924 [..............................] - ETA: 1:34:44 - loss: 0.4843 - top_3_accuracy: 0.9607 - acc: 0.8479
 278/9924 [..............................] - ETA: 1:34:43 - loss: 0.4843 - top_3_accuracy: 0.9609 - acc: 0.8476
 279/9924 [..............................] - ETA: 1:34:42 - loss: 0.4844 - top_3_accuracy: 0.9610 - acc: 0.8477
 280/9924 [..............................] - ETA: 1:34:41 - loss: 0.4845 - top_3_accuracy: 0.9607 - acc: 0.8478
 281/9924 [..............................] - ETA: 1:34:39 - loss: 0.4833 - top_3_accuracy: 0.9609 - acc: 0.8483
 282/9924 [..............................] - ETA: 1:34:38 - loss: 0.4825 - top_3_accuracy: 0.9610 - acc: 0.8484
 283/9924 [..............................] - ETA: 1:34:37 - loss: 0.4824 - top_3_accuracy: 0.9611 - acc: 0.8481
 284/9924 [..............................] - ETA: 1:34:36 - loss: 0.4831 - top_3_accuracy: 0.9608 - acc: 0.8477
 285/9924 [..............................] - ETA: 1:34:35 - loss: 0.4825 - top_3_accuracy: 0.9610 - acc: 0.8478
 286/9924 [..............................] - ETA: 1:34:34 - loss: 0.4845 - top_3_accuracy: 0.9607 - acc: 0.8479
 287/9924 [..............................] - ETA: 1:34:32 - loss: 0.4846 - top_3_accuracy: 0.9608 - acc: 0.8480
 288/9924 [..............................] - ETA: 1:34:31 - loss: 0.4837 - top_3_accuracy: 0.9609 - acc: 0.8485
 289/9924 [..............................] - ETA: 1:34:30 - loss: 0.4832 - top_3_accuracy: 0.9611 - acc: 0.8490
 290/9924 [..............................] - ETA: 1:34:29 - loss: 0.4837 - top_3_accuracy: 0.9612 - acc: 0.8487
 291/9924 [..............................] - ETA: 1:34:28 - loss: 0.4830 - top_3_accuracy: 0.9613 - acc: 0.8488
 292/9924 [..............................] - ETA: 1:34:27 - loss: 0.4822 - top_3_accuracy: 0.9615 - acc: 0.8485
 293/9924 [..............................] - ETA: 1:34:26 - loss: 0.4834 - top_3_accuracy: 0.9616 - acc: 0.8481
 294/9924 [..............................] - ETA: 1:34:25 - loss: 0.4836 - top_3_accuracy: 0.9613 - acc: 0.8482
 295/9924 [..............................] - ETA: 1:34:24 - loss: 0.4832 - top_3_accuracy: 0.9614 - acc: 0.8483
 296/9924 [..............................] - ETA: 1:34:22 - loss: 0.4833 - top_3_accuracy: 0.9616 - acc: 0.8484
 297/9924 [..............................] - ETA: 1:34:21 - loss: 0.4842 - top_3_accuracy: 0.9613 - acc: 0.8481
 298/9924 [..............................] - ETA: 1:34:20 - loss: 0.4854 - top_3_accuracy: 0.9610 - acc: 0.8477
 299/9924 [..............................] - ETA: 1:34:19 - loss: 0.4838 - top_3_accuracy: 0.9611 - acc: 0.8482
 300/9924 [..............................] - ETA: 1:34:18 - loss: 0.4837 - top_3_accuracy: 0.9613 - acc: 0.8479
 301/9924 [..............................] - ETA: 1:34:17 - loss: 0.4862 - top_3_accuracy: 0.9610 - acc: 0.8472
 302/9924 [..............................] - ETA: 1:34:16 - loss: 0.4851 - top_3_accuracy: 0.9611 - acc: 0.8477
 303/9924 [..............................] - ETA: 1:34:15 - loss: 0.4845 - top_3_accuracy: 0.9612 - acc: 0.8478
 304/9924 [..............................] - ETA: 1:34:14 - loss: 0.4838 - top_3_accuracy: 0.9613 - acc: 0.8479
 305/9924 [..............................] - ETA: 1:34:13 - loss: 0.4826 - top_3_accuracy: 0.9615 - acc: 0.8484
 306/9924 [..............................] - ETA: 1:34:12 - loss: 0.4820 - top_3_accuracy: 0.9616 - acc: 0.8484
 307/9924 [..............................] - ETA: 1:34:11 - loss: 0.4810 - top_3_accuracy: 0.9617 - acc: 0.8489
 308/9924 [..............................] - ETA: 1:34:09 - loss: 0.4807 - top_3_accuracy: 0.9619 - acc: 0.8490
 309/9924 [..............................] - ETA: 1:34:08 - loss: 0.4810 - top_3_accuracy: 0.9616 - acc: 0.8491
 310/9924 [..............................] - ETA: 1:34:07 - loss: 0.4819 - top_3_accuracy: 0.9617 - acc: 0.8484
 311/9924 [..............................] - ETA: 1:34:06 - loss: 0.4816 - top_3_accuracy: 0.9618 - acc: 0.8485
 312/9924 [..............................] - ETA: 1:34:05 - loss: 0.4815 - top_3_accuracy: 0.9615 - acc: 0.8486
 313/9924 [..............................] - ETA: 1:34:04 - loss: 0.4828 - top_3_accuracy: 0.9613 - acc: 0.8478
 314/9924 [..............................] - ETA: 1:34:03 - loss: 0.4843 - top_3_accuracy: 0.9610 - acc: 0.8471
 315/9924 [..............................] - ETA: 1:34:02 - loss: 0.4866 - top_3_accuracy: 0.9607 - acc: 0.8460
 316/9924 [..............................] - ETA: 1:34:01 - loss: 0.4877 - top_3_accuracy: 0.9604 - acc: 0.8457
 317/9924 [..............................] - ETA: 1:34:00 - loss: 0.4873 - top_3_accuracy: 0.9606 - acc: 0.8458
 318/9924 [..............................] - ETA: 1:33:59 - loss: 0.4872 - top_3_accuracy: 0.9607 - acc: 0.8459
 319/9924 [..............................] - ETA: 1:33:58 - loss: 0.4864 - top_3_accuracy: 0.9608 - acc: 0.8460
 320/9924 [..............................] - ETA: 1:33:57 - loss: 0.4854 - top_3_accuracy: 0.9609 - acc: 0.8461
 321/9924 [..............................] - ETA: 1:33:56 - loss: 0.4851 - top_3_accuracy: 0.9611 - acc: 0.8462
 322/9924 [..............................] - ETA: 1:33:55 - loss: 0.4843 - top_3_accuracy: 0.9612 - acc: 0.8467
 323/9924 [..............................] - ETA: 1:33:54 - loss: 0.4833 - top_3_accuracy: 0.9613 - acc: 0.8471
 324/9924 [..............................] - ETA: 1:33:53 - loss: 0.4824 - top_3_accuracy: 0.9614 - acc: 0.8476
 325/9924 [..............................] - ETA: 1:33:52 - loss: 0.4849 - top_3_accuracy: 0.9612 - acc: 0.8473
 326/9924 [..............................] - ETA: 1:33:51 - loss: 0.4845 - top_3_accuracy: 0.9613 - acc: 0.8474
 327/9924 [..............................] - ETA: 1:33:50 - loss: 0.4859 - top_3_accuracy: 0.9614 - acc: 0.8471
 328/9924 [..............................] - ETA: 1:33:49 - loss: 0.4873 - top_3_accuracy: 0.9611 - acc: 0.8464
 329/9924 [..............................] - ETA: 1:33:48 - loss: 0.4872 - top_3_accuracy: 0.9612 - acc: 0.8465
 330/9924 [..............................] - ETA: 1:33:47 - loss: 0.4888 - top_3_accuracy: 0.9606 - acc: 0.8462
 331/9924 [>.............................] - ETA: 1:33:46 - loss: 0.4896 - top_3_accuracy: 0.9603 - acc: 0.8463
 332/9924 [>.............................] - ETA: 1:33:45 - loss: 0.4889 - top_3_accuracy: 0.9605 - acc: 0.8464
 333/9924 [>.............................] - ETA: 1:33:44 - loss: 0.4876 - top_3_accuracy: 0.9606 - acc: 0.8468
 334/9924 [>.............................] - ETA: 1:33:43 - loss: 0.4881 - top_3_accuracy: 0.9603 - acc: 0.8469
 335/9924 [>.............................] - ETA: 1:33:42 - loss: 0.4880 - top_3_accuracy: 0.9604 - acc: 0.8470
 336/9924 [>.............................] - ETA: 1:33:41 - loss: 0.4873 - top_3_accuracy: 0.9606 - acc: 0.8471
 337/9924 [>.............................] - ETA: 1:33:40 - loss: 0.4881 - top_3_accuracy: 0.9607 - acc: 0.8472
 338/9924 [>.............................] - ETA: 1:33:39 - loss: 0.4893 - top_3_accuracy: 0.9608 - acc: 0.8462
 339/9924 [>.............................] - ETA: 1:33:38 - loss: 0.4892 - top_3_accuracy: 0.9609 - acc: 0.8459
 340/9924 [>.............................] - ETA: 1:33:37 - loss: 0.4895 - top_3_accuracy: 0.9607 - acc: 0.8456
 341/9924 [>.............................] - ETA: 1:33:36 - loss: 0.4886 - top_3_accuracy: 0.9608 - acc: 0.8457
 342/9924 [>.............................] - ETA: 1:33:35 - loss: 0.4893 - top_3_accuracy: 0.9609 - acc: 0.8454
 343/9924 [>.............................] - ETA: 1:33:34 - loss: 0.4896 - top_3_accuracy: 0.9606 - acc: 0.8455
 344/9924 [>.............................] - ETA: 1:33:33 - loss: 0.4905 - top_3_accuracy: 0.9604 - acc: 0.8452
 345/9924 [>.............................] - ETA: 1:33:32 - loss: 0.4902 - top_3_accuracy: 0.9605 - acc: 0.8453
 346/9924 [>.............................] - ETA: 1:33:31 - loss: 0.4910 - top_3_accuracy: 0.9606 - acc: 0.8450
 347/9924 [>.............................] - ETA: 1:33:30 - loss: 0.4903 - top_3_accuracy: 0.9607 - acc: 0.8455
 348/9924 [>.............................] - ETA: 1:33:29 - loss: 0.4897 - top_3_accuracy: 0.9608 - acc: 0.8455
 349/9924 [>.............................] - ETA: 1:33:28 - loss: 0.4922 - top_3_accuracy: 0.9606 - acc: 0.8449
 350/9924 [>.............................] - ETA: 1:33:27 - loss: 0.4926 - top_3_accuracy: 0.9607 - acc: 0.8443
 351/9924 [>.............................] - ETA: 1:33:26 - loss: 0.4934 - top_3_accuracy: 0.9605 - acc: 0.8437
 352/9924 [>.............................] - ETA: 1:33:25 - loss: 0.4945 - top_3_accuracy: 0.9606 - acc: 0.8430
 353/9924 [>.............................] - ETA: 1:33:24 - loss: 0.4940 - top_3_accuracy: 0.9607 - acc: 0.8431
 354/9924 [>.............................] - ETA: 1:33:24 - loss: 0.4940 - top_3_accuracy: 0.9608 - acc: 0.8432
 355/9924 [>.............................] - ETA: 1:33:23 - loss: 0.4928 - top_3_accuracy: 0.9609 - acc: 0.8437
 356/9924 [>.............................] - ETA: 1:33:22 - loss: 0.4941 - top_3_accuracy: 0.9607 - acc: 0.8434
 357/9924 [>.............................] - ETA: 1:33:21 - loss: 0.4931 - top_3_accuracy: 0.9608 - acc: 0.8438
 358/9924 [>.............................] - ETA: 1:33:20 - loss: 0.4925 - top_3_accuracy: 0.9609 - acc: 0.8439
 359/9924 [>.............................] - ETA: 1:33:19 - loss: 0.4947 - top_3_accuracy: 0.9603 - acc: 0.8433
 360/9924 [>.............................] - ETA: 1:33:18 - loss: 0.4956 - top_3_accuracy: 0.9604 - acc: 0.8427
 361/9924 [>.............................] - ETA: 1:33:17 - loss: 0.4962 - top_3_accuracy: 0.9602 - acc: 0.8428
 362/9924 [>.............................] - ETA: 1:33:16 - loss: 0.4955 - top_3_accuracy: 0.9603 - acc: 0.8429
 363/9924 [>.............................] - ETA: 1:33:15 - loss: 0.4954 - top_3_accuracy: 0.9604 - acc: 0.8430
 364/9924 [>.............................] - ETA: 1:33:14 - loss: 0.4950 - top_3_accuracy: 0.9605 - acc: 0.8427
 365/9924 [>.............................] - ETA: 1:33:13 - loss: 0.4942 - top_3_accuracy: 0.9606 - acc: 0.8432
 366/9924 [>.............................] - ETA: 1:33:12 - loss: 0.4954 - top_3_accuracy: 0.9604 - acc: 0.8432
 367/9924 [>.............................] - ETA: 1:33:11 - loss: 0.4971 - top_3_accuracy: 0.9605 - acc: 0.8420
 368/9924 [>.............................] - ETA: 1:33:10 - loss: 0.4964 - top_3_accuracy: 0.9606 - acc: 0.8424
 369/9924 [>.............................] - ETA: 1:33:09 - loss: 0.4951 - top_3_accuracy: 0.9607 - acc: 0.8428
 370/9924 [>.............................] - ETA: 1:33:09 - loss: 0.4948 - top_3_accuracy: 0.9608 - acc: 0.8426
 371/9924 [>.............................] - ETA: 1:33:08 - loss: 0.4939 - top_3_accuracy: 0.9609 - acc: 0.8430
 372/9924 [>.............................] - ETA: 1:33:07 - loss: 0.4948 - top_3_accuracy: 0.9607 - acc: 0.8424
 373/9924 [>.............................] - ETA: 1:33:06 - loss: 0.4952 - top_3_accuracy: 0.9605 - acc: 0.8425
 374/9924 [>.............................] - ETA: 1:33:05 - loss: 0.4943 - top_3_accuracy: 0.9606 - acc: 0.8429
 375/9924 [>.............................] - ETA: 1:33:04 - loss: 0.4945 - top_3_accuracy: 0.9603 - acc: 0.8430
 376/9924 [>.............................] - ETA: 1:33:03 - loss: 0.4950 - top_3_accuracy: 0.9601 - acc: 0.8431
 377/9924 [>.............................] - ETA: 1:33:02 - loss: 0.4949 - top_3_accuracy: 0.9602 - acc: 0.8428
 378/9924 [>.............................] - ETA: 1:33:01 - loss: 0.4962 - top_3_accuracy: 0.9600 - acc: 0.8429
 379/9924 [>.............................] - ETA: 1:33:00 - loss: 0.4958 - top_3_accuracy: 0.9601 - acc: 0.8430
 380/9924 [>.............................] - ETA: 1:33:00 - loss: 0.4961 - top_3_accuracy: 0.9599 - acc: 0.8428
 381/9924 [>.............................] - ETA: 1:32:59 - loss: 0.4968 - top_3_accuracy: 0.9600 - acc: 0.8425
 382/9924 [>.............................] - ETA: 1:32:58 - loss: 0.4967 - top_3_accuracy: 0.9601 - acc: 0.8426
 383/9924 [>.............................] - ETA: 1:32:57 - loss: 0.4971 - top_3_accuracy: 0.9599 - acc: 0.8427
 384/9924 [>.............................] - ETA: 1:32:56 - loss: 0.4965 - top_3_accuracy: 0.9600 - acc: 0.8428
 385/9924 [>.............................] - ETA: 1:32:55 - loss: 0.4970 - top_3_accuracy: 0.9601 - acc: 0.8425
 386/9924 [>.............................] - ETA: 1:32:54 - loss: 0.4992 - top_3_accuracy: 0.9598 - acc: 0.8416
 387/9924 [>.............................] - ETA: 1:32:53 - loss: 0.4988 - top_3_accuracy: 0.9599 - acc: 0.8417
 388/9924 [>.............................] - ETA: 1:32:52 - loss: 0.4987 - top_3_accuracy: 0.9597 - acc: 0.8415
 389/9924 [>.............................] - ETA: 1:32:52 - loss: 0.4982 - top_3_accuracy: 0.9598 - acc: 0.8416
 390/9924 [>.............................] - ETA: 1:32:51 - loss: 0.4982 - top_3_accuracy: 0.9599 - acc: 0.8413
 391/9924 [>.............................] - ETA: 1:32:50 - loss: 0.4989 - top_3_accuracy: 0.9597 - acc: 0.8411
 392/9924 [>.............................] - ETA: 1:32:49 - loss: 0.4982 - top_3_accuracy: 0.9598 - acc: 0.8415
 393/9924 [>.............................] - ETA: 1:32:48 - loss: 0.4977 - top_3_accuracy: 0.9599 - acc: 0.8416
 394/9924 [>.............................] - ETA: 1:32:47 - loss: 0.4977 - top_3_accuracy: 0.9597 - acc: 0.8414
 395/9924 [>.............................] - ETA: 1:32:46 - loss: 0.4971 - top_3_accuracy: 0.9598 - acc: 0.8418
 396/9924 [>.............................] - ETA: 1:32:45 - loss: 0.4977 - top_3_accuracy: 0.9599 - acc: 0.8419
 397/9924 [>.............................] - ETA: 1:32:45 - loss: 0.4983 - top_3_accuracy: 0.9597 - acc: 0.8419
 398/9924 [>.............................] - ETA: 1:32:44 - loss: 0.4990 - top_3_accuracy: 0.9592 - acc: 0.8417
 399/9924 [>.............................] - ETA: 1:32:43 - loss: 0.4992 - top_3_accuracy: 0.9593 - acc: 0.8418
 400/9924 [>.............................] - ETA: 1:32:42 - loss: 0.5002 - top_3_accuracy: 0.9594 - acc: 0.8413
 401/9924 [>.............................] - ETA: 1:32:41 - loss: 0.5012 - top_3_accuracy: 0.9592 - acc: 0.8413
 402/9924 [>.............................] - ETA: 1:32:40 - loss: 0.5013 - top_3_accuracy: 0.9593 - acc: 0.8411
 403/9924 [>.............................] - ETA: 1:32:39 - loss: 0.5007 - top_3_accuracy: 0.9594 - acc: 0.8415
 404/9924 [>.............................] - ETA: 1:32:39 - loss: 0.5002 - top_3_accuracy: 0.9595 - acc: 0.8416
 405/9924 [>.............................] - ETA: 1:32:38 - loss: 0.5000 - top_3_accuracy: 0.9596 - acc: 0.8417
 406/9924 [>.............................] - ETA: 1:32:37 - loss: 0.5037 - top_3_accuracy: 0.9587 - acc: 0.8408
 407/9924 [>.............................] - ETA: 1:32:36 - loss: 0.5030 - top_3_accuracy: 0.9588 - acc: 0.8412
 408/9924 [>.............................] - ETA: 1:32:35 - loss: 0.5029 - top_3_accuracy: 0.9586 - acc: 0.8413
 409/9924 [>.............................] - ETA: 1:32:34 - loss: 0.5026 - top_3_accuracy: 0.9587 - acc: 0.8411
 410/9924 [>.............................] - ETA: 1:32:33 - loss: 0.5025 - top_3_accuracy: 0.9588 - acc: 0.8412
 411/9924 [>.............................] - ETA: 1:32:33 - loss: 0.5023 - top_3_accuracy: 0.9589 - acc: 0.8409
 412/9924 [>.............................] - ETA: 1:32:32 - loss: 0.5018 - top_3_accuracy: 0.9590 - acc: 0.8410
 413/9924 [>.............................] - ETA: 1:32:31 - loss: 0.5016 - top_3_accuracy: 0.9588 - acc: 0.8411
 414/9924 [>.............................] - ETA: 1:32:30 - loss: 0.5013 - top_3_accuracy: 0.9589 - acc: 0.8412
 415/9924 [>.............................] - ETA: 1:32:29 - loss: 0.5008 - top_3_accuracy: 0.9590 - acc: 0.8413
 416/9924 [>.............................] - ETA: 1:32:28 - loss: 0.4997 - top_3_accuracy: 0.9591 - acc: 0.8416
 417/9924 [>.............................] - ETA: 1:32:27 - loss: 0.4988 - top_3_accuracy: 0.9592 - acc: 0.8420
 418/9924 [>.............................] - ETA: 1:32:27 - loss: 0.5001 - top_3_accuracy: 0.9587 - acc: 0.8418
 419/9924 [>.............................] - ETA: 1:32:26 - loss: 0.5004 - top_3_accuracy: 0.9585 - acc: 0.8416
 420/9924 [>.............................] - ETA: 1:32:25 - loss: 0.5018 - top_3_accuracy: 0.9583 - acc: 0.8411
 421/9924 [>.............................] - ETA: 1:32:24 - loss: 0.5025 - top_3_accuracy: 0.9581 - acc: 0.8409
 422/9924 [>.............................] - ETA: 1:32:23 - loss: 0.5020 - top_3_accuracy: 0.9582 - acc: 0.8409
 423/9924 [>.............................] - ETA: 1:32:23 - loss: 0.5016 - top_3_accuracy: 0.9583 - acc: 0.8410
 424/9924 [>.............................] - ETA: 1:32:22 - loss: 0.5013 - top_3_accuracy: 0.9584 - acc: 0.8414
 425/9924 [>.............................] - ETA: 1:32:21 - loss: 0.5007 - top_3_accuracy: 0.9585 - acc: 0.8415
 426/9924 [>.............................] - ETA: 1:32:20 - loss: 0.5019 - top_3_accuracy: 0.9580 - acc: 0.8413
 427/9924 [>.............................] - ETA: 1:32:19 - loss: 0.5021 - top_3_accuracy: 0.9581 - acc: 0.8410
 428/9924 [>.............................] - ETA: 1:32:18 - loss: 0.5032 - top_3_accuracy: 0.9579 - acc: 0.8405
 429/9924 [>.............................] - ETA: 1:32:18 - loss: 0.5024 - top_3_accuracy: 0.9580 - acc: 0.8409
 430/9924 [>.............................] - ETA: 1:32:17 - loss: 0.5042 - top_3_accuracy: 0.9578 - acc: 0.8407
 431/9924 [>.............................] - ETA: 1:32:16 - loss: 0.5037 - top_3_accuracy: 0.9579 - acc: 0.8408
 432/9924 [>.............................] - ETA: 1:32:15 - loss: 0.5031 - top_3_accuracy: 0.9580 - acc: 0.8409
 433/9924 [>.............................] - ETA: 1:32:14 - loss: 0.5025 - top_3_accuracy: 0.9581 - acc: 0.8409
 434/9924 [>.............................] - ETA: 1:32:13 - loss: 0.5016 - top_3_accuracy: 0.9582 - acc: 0.8413
 435/9924 [>.............................] - ETA: 1:32:13 - loss: 0.5008 - top_3_accuracy: 0.9583 - acc: 0.8417
 436/9924 [>.............................] - ETA: 1:32:12 - loss: 0.5004 - top_3_accuracy: 0.9581 - acc: 0.8417
 437/9924 [>.............................] - ETA: 1:32:11 - loss: 0.4998 - top_3_accuracy: 0.9582 - acc: 0.8421
 438/9924 [>.............................] - ETA: 1:32:10 - loss: 0.4991 - top_3_accuracy: 0.9583 - acc: 0.8422
 439/9924 [>.............................] - ETA: 1:32:10 - loss: 0.5001 - top_3_accuracy: 0.9581 - acc: 0.8420
 440/9924 [>.............................] - ETA: 1:32:09 - loss: 0.4995 - top_3_accuracy: 0.9582 - acc: 0.8420
 441/9924 [>.............................] - ETA: 1:32:08 - loss: 0.5000 - top_3_accuracy: 0.9583 - acc: 0.8418
 442/9924 [>.............................] - ETA: 1:32:07 - loss: 0.4991 - top_3_accuracy: 0.9584 - acc: 0.8422
 443/9924 [>.............................] - ETA: 1:32:06 - loss: 0.4998 - top_3_accuracy: 0.9585 - acc: 0.8420
 444/9924 [>.............................] - ETA: 1:32:05 - loss: 0.5008 - top_3_accuracy: 0.9586 - acc: 0.8421
 445/9924 [>.............................] - ETA: 1:32:05 - loss: 0.5003 - top_3_accuracy: 0.9587 - acc: 0.8424
 446/9924 [>.............................] - ETA: 1:32:04 - loss: 0.4997 - top_3_accuracy: 0.9588 - acc: 0.8428
 447/9924 [>.............................] - ETA: 1:32:03 - loss: 0.4993 - top_3_accuracy: 0.9589 - acc: 0.8431
 448/9924 [>.............................] - ETA: 1:32:02 - loss: 0.4990 - top_3_accuracy: 0.9590 - acc: 0.8432
 449/9924 [>.............................] - ETA: 1:32:01 - loss: 0.4996 - top_3_accuracy: 0.9588 - acc: 0.8430
 450/9924 [>.............................] - ETA: 1:32:01 - loss: 0.5010 - top_3_accuracy: 0.9586 - acc: 0.8428
 451/9924 [>.............................] - ETA: 1:32:00 - loss: 0.5023 - top_3_accuracy: 0.9584 - acc: 0.8420
 452/9924 [>.............................] - ETA: 1:31:59 - loss: 0.5024 - top_3_accuracy: 0.9585 - acc: 0.8421
 453/9924 [>.............................] - ETA: 1:31:58 - loss: 0.5046 - top_3_accuracy: 0.9586 - acc: 0.8419
 454/9924 [>.............................] - ETA: 1:31:57 - loss: 0.5037 - top_3_accuracy: 0.9587 - acc: 0.8422
 455/9924 [>.............................] - ETA: 1:31:57 - loss: 0.5038 - top_3_accuracy: 0.9585 - acc: 0.8423
 456/9924 [>.............................] - ETA: 1:31:56 - loss: 0.5035 - top_3_accuracy: 0.9586 - acc: 0.8424
 457/9924 [>.............................] - ETA: 1:31:55 - loss: 0.5029 - top_3_accuracy: 0.9587 - acc: 0.8425
 458/9924 [>.............................] - ETA: 1:31:54 - loss: 0.5033 - top_3_accuracy: 0.9588 - acc: 0.8422
 459/9924 [>.............................] - ETA: 1:31:53 - loss: 0.5034 - top_3_accuracy: 0.9586 - acc: 0.8423
 460/9924 [>.............................] - ETA: 1:31:53 - loss: 0.5049 - top_3_accuracy: 0.9584 - acc: 0.8418
 461/9924 [>.............................] - ETA: 1:31:52 - loss: 0.5061 - top_3_accuracy: 0.9577 - acc: 0.8414
 462/9924 [>.............................] - ETA: 1:31:51 - loss: 0.5061 - top_3_accuracy: 0.9578 - acc: 0.8415
 463/9924 [>.............................] - ETA: 1:31:50 - loss: 0.5056 - top_3_accuracy: 0.9579 - acc: 0.8415
 464/9924 [>.............................] - ETA: 1:31:50 - loss: 0.5057 - top_3_accuracy: 0.9577 - acc: 0.8413
 465/9924 [>.............................] - ETA: 1:31:49 - loss: 0.5063 - top_3_accuracy: 0.9578 - acc: 0.8409
 466/9924 [>.............................] - ETA: 1:31:48 - loss: 0.5065 - top_3_accuracy: 0.9579 - acc: 0.8409
 467/9924 [>.............................] - ETA: 1:31:47 - loss: 0.5065 - top_3_accuracy: 0.9577 - acc: 0.8410
 468/9924 [>.............................] - ETA: 1:31:46 - loss: 0.5062 - top_3_accuracy: 0.9578 - acc: 0.8408
 469/9924 [>.............................] - ETA: 1:31:46 - loss: 0.5079 - top_3_accuracy: 0.9576 - acc: 0.8401
 470/9924 [>.............................] - ETA: 1:31:45 - loss: 0.5070 - top_3_accuracy: 0.9577 - acc: 0.8404
 471/9924 [>.............................] - ETA: 1:31:44 - loss: 0.5070 - top_3_accuracy: 0.9575 - acc: 0.8405
 472/9924 [>.............................] - ETA: 1:31:43 - loss: 0.5074 - top_3_accuracy: 0.9574 - acc: 0.8406
 473/9924 [>.............................] - ETA: 1:31:43 - loss: 0.5096 - top_3_accuracy: 0.9572 - acc: 0.8396
 474/9924 [>.............................] - ETA: 1:31:42 - loss: 0.5107 - top_3_accuracy: 0.9570 - acc: 0.8394
 475/9924 [>.............................] - ETA: 1:31:41 - loss: 0.5130 - top_3_accuracy: 0.9566 - acc: 0.8382
 476/9924 [>.............................] - ETA: 1:31:40 - loss: 0.5124 - top_3_accuracy: 0.9567 - acc: 0.8385
 477/9924 [>.............................] - ETA: 1:31:39 - loss: 0.5123 - top_3_accuracy: 0.9565 - acc: 0.8386
 478/9924 [>.............................] - ETA: 1:31:39 - loss: 0.5122 - top_3_accuracy: 0.9566 - acc: 0.8387
 479/9924 [>.............................] - ETA: 1:31:38 - loss: 0.5121 - top_3_accuracy: 0.9567 - acc: 0.8387
 480/9924 [>.............................] - ETA: 1:31:37 - loss: 0.5121 - top_3_accuracy: 0.9568 - acc: 0.8388
 481/9924 [>.............................] - ETA: 1:31:36 - loss: 0.5115 - top_3_accuracy: 0.9569 - acc: 0.8391
 482/9924 [>.............................] - ETA: 1:31:36 - loss: 0.5115 - top_3_accuracy: 0.9570 - acc: 0.8392
 483/9924 [>.............................] - ETA: 1:31:35 - loss: 0.5119 - top_3_accuracy: 0.9568 - acc: 0.8393
 484/9924 [>.............................] - ETA: 1:31:34 - loss: 0.5112 - top_3_accuracy: 0.9569 - acc: 0.8396
 485/9924 [>.............................] - ETA: 1:31:33 - loss: 0.5121 - top_3_accuracy: 0.9567 - acc: 0.8394
 486/9924 [>.............................] - ETA: 1:31:33 - loss: 0.5112 - top_3_accuracy: 0.9568 - acc: 0.8398
 487/9924 [>.............................] - ETA: 1:31:32 - loss: 0.5113 - top_3_accuracy: 0.9566 - acc: 0.8396
 488/9924 [>.............................] - ETA: 1:31:31 - loss: 0.5114 - top_3_accuracy: 0.9567 - acc: 0.8397
 489/9924 [>.............................] - ETA: 1:31:30 - loss: 0.5116 - top_3_accuracy: 0.9565 - acc: 0.8395
 490/9924 [>.............................] - ETA: 1:31:29 - loss: 0.5130 - top_3_accuracy: 0.9561 - acc: 0.8393
 491/9924 [>.............................] - ETA: 1:31:29 - loss: 0.5130 - top_3_accuracy: 0.9562 - acc: 0.8394
 492/9924 [>.............................] - ETA: 1:31:28 - loss: 0.5135 - top_3_accuracy: 0.9563 - acc: 0.8392
 493/9924 [>.............................] - ETA: 1:31:27 - loss: 0.5136 - top_3_accuracy: 0.9564 - acc: 0.8387
 494/9924 [>.............................] - ETA: 1:31:26 - loss: 0.5133 - top_3_accuracy: 0.9565 - acc: 0.8386
 495/9924 [>.............................] - ETA: 1:31:26 - loss: 0.5133 - top_3_accuracy: 0.9566 - acc: 0.8384
 496/9924 [>.............................] - ETA: 1:31:25 - loss: 0.5133 - top_3_accuracy: 0.9564 - acc: 0.8385
 497/9924 [>.............................] - ETA: 1:31:24 - loss: 0.5127 - top_3_accuracy: 0.9565 - acc: 0.8388
 498/9924 [>.............................] - ETA: 1:31:24 - loss: 0.5120 - top_3_accuracy: 0.9566 - acc: 0.8391
 499/9924 [>.............................] - ETA: 1:31:23 - loss: 0.5112 - top_3_accuracy: 0.9567 - acc: 0.8394
 500/9924 [>.............................] - ETA: 1:31:22 - loss: 0.5121 - top_3_accuracy: 0.9563 - acc: 0.8390
 501/9924 [>.............................] - ETA: 1:31:21 - loss: 0.5116 - top_3_accuracy: 0.9563 - acc: 0.8388
 502/9924 [>.............................] - ETA: 1:31:21 - loss: 0.5113 - top_3_accuracy: 0.9564 - acc: 0.8386
 503/9924 [>.............................] - ETA: 1:31:20 - loss: 0.5113 - top_3_accuracy: 0.9563 - acc: 0.8387
 504/9924 [>.............................] - ETA: 1:31:19 - loss: 0.5115 - top_3_accuracy: 0.9561 - acc: 0.8388
 505/9924 [>.............................] - ETA: 1:31:18 - loss: 0.5112 - top_3_accuracy: 0.9562 - acc: 0.8389
 506/9924 [>.............................] - ETA: 1:31:18 - loss: 0.5116 - top_3_accuracy: 0.9563 - acc: 0.8384
 507/9924 [>.............................] - ETA: 1:31:17 - loss: 0.5113 - top_3_accuracy: 0.9564 - acc: 0.8385
 508/9924 [>.............................] - ETA: 1:31:16 - loss: 0.5121 - top_3_accuracy: 0.9562 - acc: 0.8381
 509/9924 [>.............................] - ETA: 1:31:15 - loss: 0.5119 - top_3_accuracy: 0.9563 - acc: 0.8379
 510/9924 [>.............................] - ETA: 1:31:15 - loss: 0.5114 - top_3_accuracy: 0.9564 - acc: 0.8382
 511/9924 [>.............................] - ETA: 1:31:14 - loss: 0.5108 - top_3_accuracy: 0.9565 - acc: 0.8386
 512/9924 [>.............................] - ETA: 1:31:13 - loss: 0.5119 - top_3_accuracy: 0.9563 - acc: 0.8381
 513/9924 [>.............................] - ETA: 1:31:12 - loss: 0.5113 - top_3_accuracy: 0.9564 - acc: 0.8385
 514/9924 [>.............................] - ETA: 1:31:12 - loss: 0.5125 - top_3_accuracy: 0.9562 - acc: 0.8380
 515/9924 [>.............................] - ETA: 1:31:11 - loss: 0.5128 - top_3_accuracy: 0.9561 - acc: 0.8381
 516/9924 [>.............................] - ETA: 1:31:10 - loss: 0.5123 - top_3_accuracy: 0.9562 - acc: 0.8384
 517/9924 [>.............................] - ETA: 1:31:09 - loss: 0.5119 - top_3_accuracy: 0.9562 - acc: 0.8385
 518/9924 [>.............................] - ETA: 1:31:09 - loss: 0.5115 - top_3_accuracy: 0.9563 - acc: 0.8386
 519/9924 [>.............................] - ETA: 1:31:08 - loss: 0.5113 - top_3_accuracy: 0.9562 - acc: 0.8386
 520/9924 [>.............................] - ETA: 1:31:07 - loss: 0.5121 - top_3_accuracy: 0.9560 - acc: 0.8382
 521/9924 [>.............................] - ETA: 1:31:06 - loss: 0.5117 - top_3_accuracy: 0.9561 - acc: 0.8385
 522/9924 [>.............................] - ETA: 1:31:06 - loss: 0.5113 - top_3_accuracy: 0.9562 - acc: 0.8388
 523/9924 [>.............................] - ETA: 1:31:05 - loss: 0.5105 - top_3_accuracy: 0.9563 - acc: 0.8391
 524/9924 [>.............................] - ETA: 1:31:04 - loss: 0.5100 - top_3_accuracy: 0.9563 - acc: 0.8392
 525/9924 [>.............................] - ETA: 1:31:03 - loss: 0.5097 - top_3_accuracy: 0.9564 - acc: 0.8395
 526/9924 [>.............................] - ETA: 1:31:03 - loss: 0.5098 - top_3_accuracy: 0.9565 - acc: 0.8394
 527/9924 [>.............................] - ETA: 1:31:02 - loss: 0.5099 - top_3_accuracy: 0.9566 - acc: 0.8392
 528/9924 [>.............................] - ETA: 1:31:01 - loss: 0.5091 - top_3_accuracy: 0.9567 - acc: 0.8395
 529/9924 [>.............................] - ETA: 1:31:00 - loss: 0.5097 - top_3_accuracy: 0.9565 - acc: 0.8393
 530/9924 [>.............................] - ETA: 1:31:00 - loss: 0.5102 - top_3_accuracy: 0.9566 - acc: 0.8392
 531/9924 [>.............................] - ETA: 1:30:59 - loss: 0.5108 - top_3_accuracy: 0.9567 - acc: 0.8390
 532/9924 [>.............................] - ETA: 1:30:58 - loss: 0.5107 - top_3_accuracy: 0.9568 - acc: 0.8388
 533/9924 [>.............................] - ETA: 1:30:58 - loss: 0.5107 - top_3_accuracy: 0.9566 - acc: 0.8389
 534/9924 [>.............................] - ETA: 1:30:57 - loss: 0.5108 - top_3_accuracy: 0.9567 - acc: 0.8385
 535/9924 [>.............................] - ETA: 1:30:56 - loss: 0.5105 - top_3_accuracy: 0.9568 - acc: 0.8386
 536/9924 [>.............................] - ETA: 1:30:55 - loss: 0.5105 - top_3_accuracy: 0.9569 - acc: 0.8384
 537/9924 [>.............................] - ETA: 1:30:55 - loss: 0.5103 - top_3_accuracy: 0.9567 - acc: 0.8385
 538/9924 [>.............................] - ETA: 1:30:54 - loss: 0.5107 - top_3_accuracy: 0.9566 - acc: 0.8383
 539/9924 [>.............................] - ETA: 1:30:53 - loss: 0.5102 - top_3_accuracy: 0.9566 - acc: 0.8384
 540/9924 [>.............................] - ETA: 1:30:52 - loss: 0.5102 - top_3_accuracy: 0.9567 - acc: 0.8384
 541/9924 [>.............................] - ETA: 1:30:52 - loss: 0.5104 - top_3_accuracy: 0.9568 - acc: 0.8383
 542/9924 [>.............................] - ETA: 1:30:51 - loss: 0.5105 - top_3_accuracy: 0.9569 - acc: 0.8381
 543/9924 [>.............................] - ETA: 1:30:50 - loss: 0.5107 - top_3_accuracy: 0.9570 - acc: 0.8377
 544/9924 [>.............................] - ETA: 1:30:49 - loss: 0.5105 - top_3_accuracy: 0.9570 - acc: 0.8378
 545/9924 [>.............................] - ETA: 1:30:49 - loss: 0.5105 - top_3_accuracy: 0.9571 - acc: 0.8378
 546/9924 [>.............................] - ETA: 1:30:48 - loss: 0.5106 - top_3_accuracy: 0.9572 - acc: 0.8379
 547/9924 [>.............................] - ETA: 1:30:47 - loss: 0.5108 - top_3_accuracy: 0.9570 - acc: 0.8380
 548/9924 [>.............................] - ETA: 1:30:47 - loss: 0.5107 - top_3_accuracy: 0.9569 - acc: 0.8380
 549/9924 [>.............................] - ETA: 1:30:46 - loss: 0.5104 - top_3_accuracy: 0.9570 - acc: 0.8381
 550/9924 [>.............................] - ETA: 1:30:45 - loss: 0.5106 - top_3_accuracy: 0.9570 - acc: 0.8377
 551/9924 [>.............................] - ETA: 1:30:44 - loss: 0.5114 - top_3_accuracy: 0.9569 - acc: 0.8376
 552/9924 [>.............................] - ETA: 1:30:44 - loss: 0.5107 - top_3_accuracy: 0.9570 - acc: 0.8379
 553/9924 [>.............................] - ETA: 1:30:43 - loss: 0.5113 - top_3_accuracy: 0.9568 - acc: 0.8379
 554/9924 [>.............................] - ETA: 1:30:42 - loss: 0.5118 - top_3_accuracy: 0.9569 - acc: 0.8380
 555/9924 [>.............................] - ETA: 1:30:42 - loss: 0.5113 - top_3_accuracy: 0.9570 - acc: 0.8383
 556/9924 [>.............................] - ETA: 1:30:41 - loss: 0.5119 - top_3_accuracy: 0.9568 - acc: 0.8381
 557/9924 [>.............................] - ETA: 1:30:40 - loss: 0.5113 - top_3_accuracy: 0.9569 - acc: 0.8384
 558/9924 [>.............................] - ETA: 1:30:39 - loss: 0.5111 - top_3_accuracy: 0.9568 - acc: 0.8385
 559/9924 [>.............................] - ETA: 1:30:39 - loss: 0.5108 - top_3_accuracy: 0.9568 - acc: 0.8386
 560/9924 [>.............................] - ETA: 1:30:38 - loss: 0.5102 - top_3_accuracy: 0.9569 - acc: 0.8386
 561/9924 [>.............................] - ETA: 1:30:37 - loss: 0.5107 - top_3_accuracy: 0.9570 - acc: 0.8385
 562/9924 [>.............................] - ETA: 1:30:37 - loss: 0.5099 - top_3_accuracy: 0.9571 - acc: 0.8387
 563/9924 [>.............................] - ETA: 1:30:36 - loss: 0.5092 - top_3_accuracy: 0.9571 - acc: 0.8390
 564/9924 [>.............................] - ETA: 1:30:35 - loss: 0.5101 - top_3_accuracy: 0.9570 - acc: 0.8389
 565/9924 [>.............................] - ETA: 1:30:34 - loss: 0.5100 - top_3_accuracy: 0.9571 - acc: 0.8389
 566/9924 [>.............................] - ETA: 1:30:34 - loss: 0.5098 - top_3_accuracy: 0.9572 - acc: 0.8390
 567/9924 [>.............................] - ETA: 1:30:33 - loss: 0.5100 - top_3_accuracy: 0.9570 - acc: 0.8388
 568/9924 [>.............................] - ETA: 1:30:32 - loss: 0.5101 - top_3_accuracy: 0.9571 - acc: 0.8389
 569/9924 [>.............................] - ETA: 1:30:32 - loss: 0.5119 - top_3_accuracy: 0.9569 - acc: 0.8388
 570/9924 [>.............................] - ETA: 1:30:31 - loss: 0.5113 - top_3_accuracy: 0.9570 - acc: 0.8390
 571/9924 [>.............................] - ETA: 1:30:30 - loss: 0.5119 - top_3_accuracy: 0.9569 - acc: 0.8389
 572/9924 [>.............................] - ETA: 1:30:29 - loss: 0.5141 - top_3_accuracy: 0.9565 - acc: 0.8385
 573/9924 [>.............................] - ETA: 1:30:29 - loss: 0.5144 - top_3_accuracy: 0.9564 - acc: 0.8386
 574/9924 [>.............................] - ETA: 1:30:28 - loss: 0.5136 - top_3_accuracy: 0.9564 - acc: 0.8389
 575/9924 [>.............................] - ETA: 1:30:27 - loss: 0.5131 - top_3_accuracy: 0.9565 - acc: 0.8389
 576/9924 [>.............................] - ETA: 1:30:27 - loss: 0.5124 - top_3_accuracy: 0.9566 - acc: 0.8392
 577/9924 [>.............................] - ETA: 1:30:26 - loss: 0.5130 - top_3_accuracy: 0.9565 - acc: 0.8393
 578/9924 [>.............................] - ETA: 1:30:25 - loss: 0.5127 - top_3_accuracy: 0.9565 - acc: 0.8395
 579/9924 [>.............................] - ETA: 1:30:25 - loss: 0.5121 - top_3_accuracy: 0.9566 - acc: 0.8398
 580/9924 [>.............................] - ETA: 1:30:24 - loss: 0.5113 - top_3_accuracy: 0.9567 - acc: 0.8401
 581/9924 [>.............................] - ETA: 1:30:23 - loss: 0.5119 - top_3_accuracy: 0.9568 - acc: 0.8401
 582/9924 [>.............................] - ETA: 1:30:22 - loss: 0.5126 - top_3_accuracy: 0.9568 - acc: 0.8398
 583/9924 [>.............................] - ETA: 1:30:22 - loss: 0.5134 - top_3_accuracy: 0.9567 - acc: 0.8394
 584/9924 [>.............................] - ETA: 1:30:21 - loss: 0.5129 - top_3_accuracy: 0.9568 - acc: 0.8397
 585/9924 [>.............................] - ETA: 1:30:20 - loss: 0.5133 - top_3_accuracy: 0.9566 - acc: 0.8395
 586/9924 [>.............................] - ETA: 1:30:20 - loss: 0.5129 - top_3_accuracy: 0.9567 - acc: 0.8396
 587/9924 [>.............................] - ETA: 1:30:19 - loss: 0.5129 - top_3_accuracy: 0.9566 - acc: 0.8397
 588/9924 [>.............................] - ETA: 1:30:18 - loss: 0.5139 - top_3_accuracy: 0.9564 - acc: 0.8393
 589/9924 [>.............................] - ETA: 1:30:17 - loss: 0.5137 - top_3_accuracy: 0.9565 - acc: 0.8393
 590/9924 [>.............................] - ETA: 1:30:17 - loss: 0.5130 - top_3_accuracy: 0.9566 - acc: 0.8396
 591/9924 [>.............................] - ETA: 1:30:16 - loss: 0.5129 - top_3_accuracy: 0.9566 - acc: 0.8395
 592/9924 [>.............................] - ETA: 1:30:15 - loss: 0.5129 - top_3_accuracy: 0.9565 - acc: 0.8395
 593/9924 [>.............................] - ETA: 1:30:15 - loss: 0.5130 - top_3_accuracy: 0.9564 - acc: 0.8396
 594/9924 [>.............................] - ETA: 1:30:14 - loss: 0.5146 - top_3_accuracy: 0.9560 - acc: 0.8394
 595/9924 [>.............................] - ETA: 1:30:13 - loss: 0.5139 - top_3_accuracy: 0.9561 - acc: 0.8397
 596/9924 [>.............................] - ETA: 1:30:13 - loss: 0.5138 - top_3_accuracy: 0.9562 - acc: 0.8396
 597/9924 [>.............................] - ETA: 1:30:12 - loss: 0.5140 - top_3_accuracy: 0.9560 - acc: 0.8396
 598/9924 [>.............................] - ETA: 1:30:11 - loss: 0.5144 - top_3_accuracy: 0.9561 - acc: 0.8395
 599/9924 [>.............................] - ETA: 1:30:10 - loss: 0.5154 - top_3_accuracy: 0.9562 - acc: 0.8391
 600/9924 [>.............................] - ETA: 1:30:10 - loss: 0.5151 - top_3_accuracy: 0.9563 - acc: 0.8392
 601/9924 [>.............................] - ETA: 1:30:09 - loss: 0.5146 - top_3_accuracy: 0.9563 - acc: 0.8394
 602/9924 [>.............................] - ETA: 1:30:08 - loss: 0.5143 - top_3_accuracy: 0.9564 - acc: 0.8395
 603/9924 [>.............................] - ETA: 1:30:08 - loss: 0.5145 - top_3_accuracy: 0.9563 - acc: 0.8396
 604/9924 [>.............................] - ETA: 1:30:07 - loss: 0.5144 - top_3_accuracy: 0.9561 - acc: 0.8396
 605/9924 [>.............................] - ETA: 1:30:06 - loss: 0.5137 - top_3_accuracy: 0.9562 - acc: 0.8399
 606/9924 [>.............................] - ETA: 1:30:06 - loss: 0.5137 - top_3_accuracy: 0.9563 - acc: 0.8397
 607/9924 [>.............................] - ETA: 1:30:05 - loss: 0.5134 - top_3_accuracy: 0.9563 - acc: 0.8400
 608/9924 [>.............................] - ETA: 1:30:04 - loss: 0.5135 - top_3_accuracy: 0.9564 - acc: 0.8398
 609/9924 [>.............................] - ETA: 1:30:03 - loss: 0.5133 - top_3_accuracy: 0.9565 - acc: 0.8401
 610/9924 [>.............................] - ETA: 1:30:03 - loss: 0.5129 - top_3_accuracy: 0.9566 - acc: 0.8402
 611/9924 [>.............................] - ETA: 1:30:02 - loss: 0.5126 - top_3_accuracy: 0.9566 - acc: 0.8400
 612/9924 [>.............................] - ETA: 1:30:01 - loss: 0.5132 - top_3_accuracy: 0.9565 - acc: 0.8397
 613/9924 [>.............................] - ETA: 1:30:01 - loss: 0.5127 - top_3_accuracy: 0.9566 - acc: 0.8399
 614/9924 [>.............................] - ETA: 1:30:00 - loss: 0.5120 - top_3_accuracy: 0.9566 - acc: 0.8402
 615/9924 [>.............................] - ETA: 1:29:59 - loss: 0.5114 - top_3_accuracy: 0.9567 - acc: 0.8404
 616/9924 [>.............................] - ETA: 1:29:59 - loss: 0.5114 - top_3_accuracy: 0.9568 - acc: 0.8405
 617/9924 [>.............................] - ETA: 1:29:58 - loss: 0.5115 - top_3_accuracy: 0.9568 - acc: 0.8404
 618/9924 [>.............................] - ETA: 1:29:57 - loss: 0.5115 - top_3_accuracy: 0.9569 - acc: 0.8402
 619/9924 [>.............................] - ETA: 1:29:57 - loss: 0.5116 - top_3_accuracy: 0.9568 - acc: 0.8403
 620/9924 [>.............................] - ETA: 1:29:56 - loss: 0.5112 - top_3_accuracy: 0.9569 - acc: 0.8405
 621/9924 [>.............................] - ETA: 1:29:55 - loss: 0.5112 - top_3_accuracy: 0.9569 - acc: 0.8406
 622/9924 [>.............................] - ETA: 1:29:55 - loss: 0.5106 - top_3_accuracy: 0.9570 - acc: 0.8408
 623/9924 [>.............................] - ETA: 1:29:54 - loss: 0.5121 - top_3_accuracy: 0.9567 - acc: 0.8405
 624/9924 [>.............................] - ETA: 1:29:53 - loss: 0.5116 - top_3_accuracy: 0.9567 - acc: 0.8407
 625/9924 [>.............................] - ETA: 1:29:52 - loss: 0.5117 - top_3_accuracy: 0.9568 - acc: 0.8404
 626/9924 [>.............................] - ETA: 1:29:52 - loss: 0.5116 - top_3_accuracy: 0.9569 - acc: 0.8403
 627/9924 [>.............................] - ETA: 1:29:51 - loss: 0.5122 - top_3_accuracy: 0.9569 - acc: 0.8397
 628/9924 [>.............................] - ETA: 1:29:50 - loss: 0.5125 - top_3_accuracy: 0.9568 - acc: 0.8398
 629/9924 [>.............................] - ETA: 1:29:50 - loss: 0.5122 - top_3_accuracy: 0.9569 - acc: 0.8398
 630/9924 [>.............................] - ETA: 1:29:49 - loss: 0.5120 - top_3_accuracy: 0.9567 - acc: 0.8399
 631/9924 [>.............................] - ETA: 1:29:48 - loss: 0.5134 - top_3_accuracy: 0.9562 - acc: 0.8393
 632/9924 [>.............................] - ETA: 1:29:48 - loss: 0.5132 - top_3_accuracy: 0.9563 - acc: 0.8394
 633/9924 [>.............................] - ETA: 1:29:47 - loss: 0.5128 - top_3_accuracy: 0.9564 - acc: 0.8395
 634/9924 [>.............................] - ETA: 1:29:46 - loss: 0.5127 - top_3_accuracy: 0.9562 - acc: 0.8395
 635/9924 [>.............................] - ETA: 1:29:46 - loss: 0.5122 - top_3_accuracy: 0.9563 - acc: 0.8398
 636/9924 [>.............................] - ETA: 1:29:45 - loss: 0.5119 - top_3_accuracy: 0.9564 - acc: 0.8396
 637/9924 [>.............................] - ETA: 1:29:44 - loss: 0.5121 - top_3_accuracy: 0.9562 - acc: 0.8397
 638/9924 [>.............................] - ETA: 1:29:44 - loss: 0.5114 - top_3_accuracy: 0.9563 - acc: 0.8399
 639/9924 [>.............................] - ETA: 1:29:43 - loss: 0.5118 - top_3_accuracy: 0.9562 - acc: 0.8398
 640/9924 [>.............................] - ETA: 1:29:42 - loss: 0.5127 - top_3_accuracy: 0.9561 - acc: 0.8395
 641/9924 [>.............................] - ETA: 1:29:42 - loss: 0.5123 - top_3_accuracy: 0.9561 - acc: 0.8395
 642/9924 [>.............................] - ETA: 1:29:41 - loss: 0.5115 - top_3_accuracy: 0.9562 - acc: 0.8398
 643/9924 [>.............................] - ETA: 1:29:40 - loss: 0.5114 - top_3_accuracy: 0.9563 - acc: 0.8398
 644/9924 [>.............................] - ETA: 1:29:40 - loss: 0.5111 - top_3_accuracy: 0.9563 - acc: 0.8399
 645/9924 [>.............................] - ETA: 1:29:39 - loss: 0.5123 - top_3_accuracy: 0.9562 - acc: 0.8395
 646/9924 [>.............................] - ETA: 1:29:38 - loss: 0.5132 - top_3_accuracy: 0.9561 - acc: 0.8392
 647/9924 [>.............................] - ETA: 1:29:37 - loss: 0.5126 - top_3_accuracy: 0.9561 - acc: 0.8395
 648/9924 [>.............................] - ETA: 1:29:37 - loss: 0.5131 - top_3_accuracy: 0.9560 - acc: 0.8395
 649/9924 [>.............................] - ETA: 1:29:36 - loss: 0.5133 - top_3_accuracy: 0.9561 - acc: 0.8394
 650/9924 [>.............................] - ETA: 1:29:35 - loss: 0.5127 - top_3_accuracy: 0.9562 - acc: 0.8396
 651/9924 [>.............................] - ETA: 1:29:35 - loss: 0.5132 - top_3_accuracy: 0.9560 - acc: 0.8395
 652/9924 [>.............................] - ETA: 1:29:34 - loss: 0.5130 - top_3_accuracy: 0.9561 - acc: 0.8395
 653/9924 [>.............................] - ETA: 1:29:33 - loss: 0.5125 - top_3_accuracy: 0.9562 - acc: 0.8398
 654/9924 [>.............................] - ETA: 1:29:33 - loss: 0.5139 - top_3_accuracy: 0.9558 - acc: 0.8396
 655/9924 [>.............................] - ETA: 1:29:32 - loss: 0.5144 - top_3_accuracy: 0.9557 - acc: 0.8393
 656/9924 [>.............................] - ETA: 1:29:31 - loss: 0.5150 - top_3_accuracy: 0.9556 - acc: 0.8392
 657/9924 [>.............................] - ETA: 1:29:31 - loss: 0.5146 - top_3_accuracy: 0.9557 - acc: 0.8392
 658/9924 [>.............................] - ETA: 1:29:30 - loss: 0.5146 - top_3_accuracy: 0.9557 - acc: 0.8393
 659/9924 [>.............................] - ETA: 1:29:29 - loss: 0.5144 - top_3_accuracy: 0.9558 - acc: 0.8393
 660/9924 [>.............................] - ETA: 1:29:29 - loss: 0.5145 - top_3_accuracy: 0.9559 - acc: 0.8394
 661/9924 [>.............................] - ETA: 1:29:28 - loss: 0.5138 - top_3_accuracy: 0.9559 - acc: 0.8396
 662/9924 [=>............................] - ETA: 1:29:27 - loss: 0.5146 - top_3_accuracy: 0.9556 - acc: 0.8393
 663/9924 [=>............................] - ETA: 1:29:27 - loss: 0.5143 - top_3_accuracy: 0.9557 - acc: 0.8394
 664/9924 [=>............................] - ETA: 1:29:26 - loss: 0.5141 - top_3_accuracy: 0.9556 - acc: 0.8394
 665/9924 [=>............................] - ETA: 1:29:25 - loss: 0.5145 - top_3_accuracy: 0.9555 - acc: 0.8393
 666/9924 [=>............................] - ETA: 1:29:25 - loss: 0.5149 - top_3_accuracy: 0.9553 - acc: 0.8392
 667/9924 [=>............................] - ETA: 1:29:24 - loss: 0.5148 - top_3_accuracy: 0.9554 - acc: 0.8390
 668/9924 [=>............................] - ETA: 1:29:23 - loss: 0.5148 - top_3_accuracy: 0.9555 - acc: 0.8389
 669/9924 [=>............................] - ETA: 1:29:23 - loss: 0.5148 - top_3_accuracy: 0.9555 - acc: 0.8389
 670/9924 [=>............................] - ETA: 1:29:22 - loss: 0.5144 - top_3_accuracy: 0.9556 - acc: 0.8392
 671/9924 [=>............................] - ETA: 1:29:21 - loss: 0.5152 - top_3_accuracy: 0.9555 - acc: 0.8390
 672/9924 [=>............................] - ETA: 1:29:21 - loss: 0.5149 - top_3_accuracy: 0.9555 - acc: 0.8391
 673/9924 [=>............................] - ETA: 1:29:20 - loss: 0.5144 - top_3_accuracy: 0.9556 - acc: 0.8393
 674/9924 [=>............................] - ETA: 1:29:19 - loss: 0.5140 - top_3_accuracy: 0.9557 - acc: 0.8394
 675/9924 [=>............................] - ETA: 1:29:19 - loss: 0.5144 - top_3_accuracy: 0.9554 - acc: 0.8393
 676/9924 [=>............................] - ETA: 1:29:18 - loss: 0.5140 - top_3_accuracy: 0.9554 - acc: 0.8395
 677/9924 [=>............................] - ETA: 1:29:17 - loss: 0.5142 - top_3_accuracy: 0.9555 - acc: 0.8392
 678/9924 [=>............................] - ETA: 1:29:17 - loss: 0.5139 - top_3_accuracy: 0.9556 - acc: 0.8394
 679/9924 [=>............................] - ETA: 1:29:16 - loss: 0.5139 - top_3_accuracy: 0.9554 - acc: 0.8393
 680/9924 [=>............................] - ETA: 1:29:15 - loss: 0.5148 - top_3_accuracy: 0.9555 - acc: 0.8393
 681/9924 [=>............................] - ETA: 1:29:15 - loss: 0.5142 - top_3_accuracy: 0.9556 - acc: 0.8396
 682/9924 [=>............................] - ETA: 1:29:14 - loss: 0.5147 - top_3_accuracy: 0.9555 - acc: 0.8391
 683/9924 [=>............................] - ETA: 1:29:13 - loss: 0.5159 - top_3_accuracy: 0.9552 - acc: 0.8386
 684/9924 [=>............................] - ETA: 1:29:13 - loss: 0.5156 - top_3_accuracy: 0.9552 - acc: 0.8388
 685/9924 [=>............................] - ETA: 1:29:12 - loss: 0.5160 - top_3_accuracy: 0.9551 - acc: 0.8387
 686/9924 [=>............................] - ETA: 1:29:11 - loss: 0.5169 - top_3_accuracy: 0.9548 - acc: 0.8382
 687/9924 [=>............................] - ETA: 1:29:11 - loss: 0.5163 - top_3_accuracy: 0.9549 - acc: 0.8384
 688/9924 [=>............................] - ETA: 1:29:10 - loss: 0.5160 - top_3_accuracy: 0.9549 - acc: 0.8385
 689/9924 [=>............................] - ETA: 1:29:09 - loss: 0.5161 - top_3_accuracy: 0.9550 - acc: 0.8384
 690/9924 [=>............................] - ETA: 1:29:09 - loss: 0.5163 - top_3_accuracy: 0.9549 - acc: 0.8382
 691/9924 [=>............................] - ETA: 1:29:08 - loss: 0.5159 - top_3_accuracy: 0.9550 - acc: 0.8383
 692/9924 [=>............................] - ETA: 1:29:07 - loss: 0.5159 - top_3_accuracy: 0.9548 - acc: 0.8383
 693/9924 [=>............................] - ETA: 1:29:07 - loss: 0.5152 - top_3_accuracy: 0.9549 - acc: 0.8386
 694/9924 [=>............................] - ETA: 1:29:06 - loss: 0.5168 - top_3_accuracy: 0.9546 - acc: 0.8383
 695/9924 [=>............................] - ETA: 1:29:05 - loss: 0.5172 - top_3_accuracy: 0.9547 - acc: 0.8378
 696/9924 [=>............................] - ETA: 1:29:05 - loss: 0.5177 - top_3_accuracy: 0.9546 - acc: 0.8375
 697/9924 [=>............................] - ETA: 1:29:04 - loss: 0.5170 - top_3_accuracy: 0.9546 - acc: 0.8377
 698/9924 [=>............................] - ETA: 1:29:03 - loss: 0.5174 - top_3_accuracy: 0.9545 - acc: 0.8376
 699/9924 [=>............................] - ETA: 1:29:03 - loss: 0.5178 - top_3_accuracy: 0.9544 - acc: 0.8374
 700/9924 [=>............................] - ETA: 1:29:02 - loss: 0.5174 - top_3_accuracy: 0.9545 - acc: 0.8375
 701/9924 [=>............................] - ETA: 1:29:01 - loss: 0.5175 - top_3_accuracy: 0.9545 - acc: 0.8374
 702/9924 [=>............................] - ETA: 1:29:01 - loss: 0.5187 - top_3_accuracy: 0.9546 - acc: 0.8367
 703/9924 [=>............................] - ETA: 1:29:00 - loss: 0.5188 - top_3_accuracy: 0.9547 - acc: 0.8368
 704/9924 [=>............................] - ETA: 1:28:59 - loss: 0.5197 - top_3_accuracy: 0.9547 - acc: 0.8366
 705/9924 [=>............................] - ETA: 1:28:59 - loss: 0.5202 - top_3_accuracy: 0.9546 - acc: 0.8367
 706/9924 [=>............................] - ETA: 1:28:58 - loss: 0.5197 - top_3_accuracy: 0.9547 - acc: 0.8369
 707/9924 [=>............................] - ETA: 1:28:57 - loss: 0.5195 - top_3_accuracy: 0.9547 - acc: 0.8370
 708/9924 [=>............................] - ETA: 1:28:57 - loss: 0.5200 - top_3_accuracy: 0.9548 - acc: 0.8370
 709/9924 [=>............................] - ETA: 1:28:56 - loss: 0.5203 - top_3_accuracy: 0.9549 - acc: 0.8369
 710/9924 [=>............................] - ETA: 1:28:55 - loss: 0.5215 - top_3_accuracy: 0.9546 - acc: 0.8366
 711/9924 [=>............................] - ETA: 1:28:55 - loss: 0.5211 - top_3_accuracy: 0.9546 - acc: 0.8368
 712/9924 [=>............................] - ETA: 1:28:54 - loss: 0.5211 - top_3_accuracy: 0.9547 - acc: 0.8367
 713/9924 [=>............................] - ETA: 1:28:53 - loss: 0.5215 - top_3_accuracy: 0.9548 - acc: 0.8366
 714/9924 [=>............................] - ETA: 1:28:53 - loss: 0.5215 - top_3_accuracy: 0.9548 - acc: 0.8365
 715/9924 [=>............................] - ETA: 1:28:52 - loss: 0.5213 - top_3_accuracy: 0.9549 - acc: 0.8365
 716/9924 [=>............................] - ETA: 1:28:52 - loss: 0.5216 - top_3_accuracy: 0.9548 - acc: 0.8364
 717/9924 [=>............................] - ETA: 1:28:51 - loss: 0.5216 - top_3_accuracy: 0.9548 - acc: 0.8363
 718/9924 [=>............................] - ETA: 1:28:50 - loss: 0.5217 - top_3_accuracy: 0.9547 - acc: 0.8362
 719/9924 [=>............................] - ETA: 1:28:50 - loss: 0.5216 - top_3_accuracy: 0.9548 - acc: 0.8362
 720/9924 [=>............................] - ETA: 1:28:49 - loss: 0.5214 - top_3_accuracy: 0.9549 - acc: 0.8361
 721/9924 [=>............................] - ETA: 1:28:48 - loss: 0.5221 - top_3_accuracy: 0.9548 - acc: 0.8360
 722/9924 [=>............................] - ETA: 1:28:48 - loss: 0.5226 - top_3_accuracy: 0.9545 - acc: 0.8357
 723/9924 [=>............................] - ETA: 1:28:47 - loss: 0.5232 - top_3_accuracy: 0.9544 - acc: 0.8354
 724/9924 [=>............................] - ETA: 1:28:46 - loss: 0.5226 - top_3_accuracy: 0.9544 - acc: 0.8356
 725/9924 [=>............................] - ETA: 1:28:46 - loss: 0.5244 - top_3_accuracy: 0.9540 - acc: 0.8353
 726/9924 [=>............................] - ETA: 1:28:45 - loss: 0.5251 - top_3_accuracy: 0.9539 - acc: 0.8354
 727/9924 [=>............................] - ETA: 1:28:44 - loss: 0.5257 - top_3_accuracy: 0.9536 - acc: 0.8353
 728/9924 [=>............................] - ETA: 1:28:44 - loss: 0.5259 - top_3_accuracy: 0.9535 - acc: 0.8352
 729/9924 [=>............................] - ETA: 1:28:43 - loss: 0.5256 - top_3_accuracy: 0.9535 - acc: 0.8352
 730/9924 [=>............................] - ETA: 1:28:42 - loss: 0.5250 - top_3_accuracy: 0.9536 - acc: 0.8354
 731/9924 [=>............................] - ETA: 1:28:42 - loss: 0.5250 - top_3_accuracy: 0.9537 - acc: 0.8355
 732/9924 [=>............................] - ETA: 1:28:41 - loss: 0.5245 - top_3_accuracy: 0.9537 - acc: 0.8357
 733/9924 [=>............................] - ETA: 1:28:40 - loss: 0.5239 - top_3_accuracy: 0.9538 - acc: 0.8359
 734/9924 [=>............................] - ETA: 1:28:40 - loss: 0.5240 - top_3_accuracy: 0.9538 - acc: 0.8358
 735/9924 [=>............................] - ETA: 1:28:39 - loss: 0.5241 - top_3_accuracy: 0.9537 - acc: 0.8359
 736/9924 [=>............................] - ETA: 1:28:38 - loss: 0.5246 - top_3_accuracy: 0.9538 - acc: 0.8356
 737/9924 [=>............................] - ETA: 1:28:38 - loss: 0.5243 - top_3_accuracy: 0.9539 - acc: 0.8358
 738/9924 [=>............................] - ETA: 1:28:37 - loss: 0.5244 - top_3_accuracy: 0.9539 - acc: 0.8357
 739/9924 [=>............................] - ETA: 1:28:36 - loss: 0.5244 - top_3_accuracy: 0.9538 - acc: 0.8358
 740/9924 [=>............................] - ETA: 1:28:36 - loss: 0.5240 - top_3_accuracy: 0.9539 - acc: 0.8360
 741/9924 [=>............................] - ETA: 1:28:35 - loss: 0.5249 - top_3_accuracy: 0.9538 - acc: 0.8359
 742/9924 [=>............................] - ETA: 1:28:34 - loss: 0.5245 - top_3_accuracy: 0.9538 - acc: 0.8361
 743/9924 [=>............................] - ETA: 1:28:34 - loss: 0.5246 - top_3_accuracy: 0.9539 - acc: 0.8360
 744/9924 [=>............................] - ETA: 1:28:33 - loss: 0.5250 - top_3_accuracy: 0.9538 - acc: 0.8360
 745/9924 [=>............................] - ETA: 1:28:33 - loss: 0.5252 - top_3_accuracy: 0.9537 - acc: 0.8359
 746/9924 [=>............................] - ETA: 1:28:32 - loss: 0.5260 - top_3_accuracy: 0.9536 - acc: 0.8358
 747/9924 [=>............................] - ETA: 1:28:31 - loss: 0.5256 - top_3_accuracy: 0.9536 - acc: 0.8358
 748/9924 [=>............................] - ETA: 1:28:31 - loss: 0.5257 - top_3_accuracy: 0.9535 - acc: 0.8357
 749/9924 [=>............................] - ETA: 1:28:30 - loss: 0.5258 - top_3_accuracy: 0.9534 - acc: 0.8358
 750/9924 [=>............................] - ETA: 1:28:29 - loss: 0.5257 - top_3_accuracy: 0.9533 - acc: 0.8358
 751/9924 [=>............................] - ETA: 1:28:29 - loss: 0.5259 - top_3_accuracy: 0.9534 - acc: 0.8356
 752/9924 [=>............................] - ETA: 1:28:28 - loss: 0.5267 - top_3_accuracy: 0.9531 - acc: 0.8354
 753/9924 [=>............................] - ETA: 1:28:27 - loss: 0.5272 - top_3_accuracy: 0.9530 - acc: 0.8353
 754/9924 [=>............................] - ETA: 1:28:27 - loss: 0.5272 - top_3_accuracy: 0.9531 - acc: 0.8354
 755/9924 [=>............................] - ETA: 1:28:26 - loss: 0.5287 - top_3_accuracy: 0.9528 - acc: 0.8349
 756/9924 [=>............................] - ETA: 1:28:25 - loss: 0.5292 - top_3_accuracy: 0.9529 - acc: 0.8348
 757/9924 [=>............................] - ETA: 1:28:25 - loss: 0.5285 - top_3_accuracy: 0.9529 - acc: 0.8350
 758/9924 [=>............................] - ETA: 1:28:24 - loss: 0.5287 - top_3_accuracy: 0.9530 - acc: 0.8351
 759/9924 [=>............................] - ETA: 1:28:23 - loss: 0.5286 - top_3_accuracy: 0.9531 - acc: 0.8351
 760/9924 [=>............................] - ETA: 1:28:23 - loss: 0.5287 - top_3_accuracy: 0.9531 - acc: 0.8350
 761/9924 [=>............................] - ETA: 1:28:22 - loss: 0.5287 - top_3_accuracy: 0.9530 - acc: 0.8351
 762/9924 [=>............................] - ETA: 1:28:21 - loss: 0.5290 - top_3_accuracy: 0.9529 - acc: 0.8350
 763/9924 [=>............................] - ETA: 1:28:21 - loss: 0.5289 - top_3_accuracy: 0.9528 - acc: 0.8350
 764/9924 [=>............................] - ETA: 1:28:20 - loss: 0.5285 - top_3_accuracy: 0.9529 - acc: 0.8352
 765/9924 [=>............................] - ETA: 1:28:19 - loss: 0.5280 - top_3_accuracy: 0.9529 - acc: 0.8355
 766/9924 [=>............................] - ETA: 1:28:19 - loss: 0.5276 - top_3_accuracy: 0.9530 - acc: 0.8355
 767/9924 [=>............................] - ETA: 1:28:18 - loss: 0.5276 - top_3_accuracy: 0.9529 - acc: 0.8356
 768/9924 [=>............................] - ETA: 1:28:17 - loss: 0.5270 - top_3_accuracy: 0.9530 - acc: 0.8358
 769/9924 [=>............................] - ETA: 1:28:17 - loss: 0.5275 - top_3_accuracy: 0.9530 - acc: 0.8355
 770/9924 [=>............................] - ETA: 1:28:16 - loss: 0.5283 - top_3_accuracy: 0.9529 - acc: 0.8352
 771/9924 [=>............................] - ETA: 1:28:16 - loss: 0.5278 - top_3_accuracy: 0.9530 - acc: 0.8354
 772/9924 [=>............................] - ETA: 1:28:15 - loss: 0.5277 - top_3_accuracy: 0.9529 - acc: 0.8355
 773/9924 [=>............................] - ETA: 1:28:14 - loss: 0.5277 - top_3_accuracy: 0.9528 - acc: 0.8355
 774/9924 [=>............................] - ETA: 1:28:14 - loss: 0.5290 - top_3_accuracy: 0.9527 - acc: 0.8353
 775/9924 [=>............................] - ETA: 1:28:13 - loss: 0.5292 - top_3_accuracy: 0.9526 - acc: 0.8352
 776/9924 [=>............................] - ETA: 1:28:12 - loss: 0.5295 - top_3_accuracy: 0.9525 - acc: 0.8352
 777/9924 [=>............................] - ETA: 1:28:12 - loss: 0.5296 - top_3_accuracy: 0.9525 - acc: 0.8351
 778/9924 [=>............................] - ETA: 1:28:11 - loss: 0.5298 - top_3_accuracy: 0.9526 - acc: 0.8352
 779/9924 [=>............................] - ETA: 1:28:10 - loss: 0.5295 - top_3_accuracy: 0.9527 - acc: 0.8352
 780/9924 [=>............................] - ETA: 1:28:10 - loss: 0.5295 - top_3_accuracy: 0.9527 - acc: 0.8353
 781/9924 [=>............................] - ETA: 1:28:09 - loss: 0.5304 - top_3_accuracy: 0.9526 - acc: 0.8351
 782/9924 [=>............................] - ETA: 1:28:08 - loss: 0.5298 - top_3_accuracy: 0.9527 - acc: 0.8354
 783/9924 [=>............................] - ETA: 1:28:08 - loss: 0.5301 - top_3_accuracy: 0.9526 - acc: 0.8351
 784/9924 [=>............................] - ETA: 1:28:07 - loss: 0.5296 - top_3_accuracy: 0.9526 - acc: 0.8353
 785/9924 [=>............................] - ETA: 1:28:07 - loss: 0.5296 - top_3_accuracy: 0.9527 - acc: 0.8352
 786/9924 [=>............................] - ETA: 1:28:06 - loss: 0.5292 - top_3_accuracy: 0.9528 - acc: 0.8354
 787/9924 [=>............................] - ETA: 1:28:05 - loss: 0.5291 - top_3_accuracy: 0.9528 - acc: 0.8353
 788/9924 [=>............................] - ETA: 1:28:05 - loss: 0.5309 - top_3_accuracy: 0.9526 - acc: 0.8349
 789/9924 [=>............................] - ETA: 1:28:04 - loss: 0.5314 - top_3_accuracy: 0.9526 - acc: 0.8346
 790/9924 [=>............................] - ETA: 1:28:03 - loss: 0.5315 - top_3_accuracy: 0.9527 - acc: 0.8345
 791/9924 [=>............................] - ETA: 1:28:03 - loss: 0.5319 - top_3_accuracy: 0.9527 - acc: 0.8342
 792/9924 [=>............................] - ETA: 1:28:02 - loss: 0.5315 - top_3_accuracy: 0.9528 - acc: 0.8343
 793/9924 [=>............................] - ETA: 1:28:01 - loss: 0.5318 - top_3_accuracy: 0.9529 - acc: 0.8342
 794/9924 [=>............................] - ETA: 1:28:01 - loss: 0.5329 - top_3_accuracy: 0.9529 - acc: 0.8339
 795/9924 [=>............................] - ETA: 1:28:00 - loss: 0.5335 - top_3_accuracy: 0.9527 - acc: 0.8338
 796/9924 [=>............................] - ETA: 1:27:59 - loss: 0.5333 - top_3_accuracy: 0.9527 - acc: 0.8339
 797/9924 [=>............................] - ETA: 1:27:59 - loss: 0.5333 - top_3_accuracy: 0.9528 - acc: 0.8338
 798/9924 [=>............................] - ETA: 1:27:58 - loss: 0.5330 - top_3_accuracy: 0.9529 - acc: 0.8340
 799/9924 [=>............................] - ETA: 1:27:57 - loss: 0.5324 - top_3_accuracy: 0.9529 - acc: 0.8342
 800/9924 [=>............................] - ETA: 1:27:57 - loss: 0.5324 - top_3_accuracy: 0.9530 - acc: 0.8341
 801/9924 [=>............................] - ETA: 1:27:56 - loss: 0.5329 - top_3_accuracy: 0.9529 - acc: 0.8340
 802/9924 [=>............................] - ETA: 1:27:56 - loss: 0.5327 - top_3_accuracy: 0.9529 - acc: 0.8340
 803/9924 [=>............................] - ETA: 1:27:55 - loss: 0.5329 - top_3_accuracy: 0.9528 - acc: 0.8339
 804/9924 [=>............................] - ETA: 1:27:54 - loss: 0.5328 - top_3_accuracy: 0.9527 - acc: 0.8340
 805/9924 [=>............................] - ETA: 1:27:54 - loss: 0.5328 - top_3_accuracy: 0.9528 - acc: 0.8340
 806/9924 [=>............................] - ETA: 1:27:53 - loss: 0.5333 - top_3_accuracy: 0.9529 - acc: 0.8337
 807/9924 [=>............................] - ETA: 1:27:52 - loss: 0.5349 - top_3_accuracy: 0.9528 - acc: 0.8333
 808/9924 [=>............................] - ETA: 1:27:52 - loss: 0.5348 - top_3_accuracy: 0.9528 - acc: 0.8334
 809/9924 [=>............................] - ETA: 1:27:51 - loss: 0.5351 - top_3_accuracy: 0.9527 - acc: 0.8334
 810/9924 [=>............................] - ETA: 1:27:50 - loss: 0.5346 - top_3_accuracy: 0.9528 - acc: 0.8336
 811/9924 [=>............................] - ETA: 1:27:50 - loss: 0.5342 - top_3_accuracy: 0.9528 - acc: 0.8337
 812/9924 [=>............................] - ETA: 1:27:49 - loss: 0.5350 - top_3_accuracy: 0.9526 - acc: 0.8334
 813/9924 [=>............................] - ETA: 1:27:49 - loss: 0.5346 - top_3_accuracy: 0.9526 - acc: 0.8336
 814/9924 [=>............................] - ETA: 1:27:48 - loss: 0.5350 - top_3_accuracy: 0.9527 - acc: 0.8334
 815/9924 [=>............................] - ETA: 1:27:47 - loss: 0.5353 - top_3_accuracy: 0.9526 - acc: 0.8333
 816/9924 [=>............................] - ETA: 1:27:47 - loss: 0.5350 - top_3_accuracy: 0.9527 - acc: 0.8333
 817/9924 [=>............................] - ETA: 1:27:46 - loss: 0.5351 - top_3_accuracy: 0.9527 - acc: 0.8334
 818/9924 [=>............................] - ETA: 1:27:45 - loss: 0.5349 - top_3_accuracy: 0.9528 - acc: 0.8334
 819/9924 [=>............................] - ETA: 1:27:45 - loss: 0.5362 - top_3_accuracy: 0.9527 - acc: 0.8329
 820/9924 [=>............................] - ETA: 1:27:44 - loss: 0.5360 - top_3_accuracy: 0.9527 - acc: 0.8331
 821/9924 [=>............................] - ETA: 1:27:43 - loss: 0.5360 - top_3_accuracy: 0.9526 - acc: 0.8331
 822/9924 [=>............................] - ETA: 1:27:43 - loss: 0.5367 - top_3_accuracy: 0.9526 - acc: 0.8330
 823/9924 [=>............................] - ETA: 1:27:42 - loss: 0.5365 - top_3_accuracy: 0.9526 - acc: 0.8332
 824/9924 [=>............................] - ETA: 1:27:41 - loss: 0.5365 - top_3_accuracy: 0.9527 - acc: 0.8333
 825/9924 [=>............................] - ETA: 1:27:41 - loss: 0.5370 - top_3_accuracy: 0.9526 - acc: 0.8332
 826/9924 [=>............................] - ETA: 1:27:40 - loss: 0.5370 - top_3_accuracy: 0.9526 - acc: 0.8331
 827/9924 [=>............................] - ETA: 1:27:40 - loss: 0.5372 - top_3_accuracy: 0.9525 - acc: 0.8330
 828/9924 [=>............................] - ETA: 1:27:39 - loss: 0.5367 - top_3_accuracy: 0.9526 - acc: 0.8332
 829/9924 [=>............................] - ETA: 1:27:38 - loss: 0.5368 - top_3_accuracy: 0.9525 - acc: 0.8331
 830/9924 [=>............................] - ETA: 1:27:38 - loss: 0.5368 - top_3_accuracy: 0.9524 - acc: 0.8331
 831/9924 [=>............................] - ETA: 1:27:37 - loss: 0.5366 - top_3_accuracy: 0.9525 - acc: 0.8332
 832/9924 [=>............................] - ETA: 1:27:36 - loss: 0.5369 - top_3_accuracy: 0.9524 - acc: 0.8331
 833/9924 [=>............................] - ETA: 1:27:36 - loss: 0.5365 - top_3_accuracy: 0.9524 - acc: 0.8331
 834/9924 [=>............................] - ETA: 1:27:35 - loss: 0.5376 - top_3_accuracy: 0.9522 - acc: 0.8327
 835/9924 [=>............................] - ETA: 1:27:34 - loss: 0.5375 - top_3_accuracy: 0.9522 - acc: 0.8326
 836/9924 [=>............................] - ETA: 1:27:34 - loss: 0.5383 - top_3_accuracy: 0.9520 - acc: 0.8325
 837/9924 [=>............................] - ETA: 1:27:33 - loss: 0.5390 - top_3_accuracy: 0.9519 - acc: 0.8324
 838/9924 [=>............................] - ETA: 1:27:33 - loss: 0.5388 - top_3_accuracy: 0.9520 - acc: 0.8323
 839/9924 [=>............................] - ETA: 1:27:32 - loss: 0.5392 - top_3_accuracy: 0.9519 - acc: 0.8322
 840/9924 [=>............................] - ETA: 1:27:31 - loss: 0.5389 - top_3_accuracy: 0.9519 - acc: 0.8323
 841/9924 [=>............................] - ETA: 1:27:31 - loss: 0.5392 - top_3_accuracy: 0.9520 - acc: 0.8322
 842/9924 [=>............................] - ETA: 1:27:30 - loss: 0.5388 - top_3_accuracy: 0.9520 - acc: 0.8324
 843/9924 [=>............................] - ETA: 1:27:29 - loss: 0.5383 - top_3_accuracy: 0.9521 - acc: 0.8326
 844/9924 [=>............................] - ETA: 1:27:29 - loss: 0.5382 - top_3_accuracy: 0.9522 - acc: 0.8326
 845/9924 [=>............................] - ETA: 1:27:28 - loss: 0.5383 - top_3_accuracy: 0.9521 - acc: 0.8327
 846/9924 [=>............................] - ETA: 1:27:27 - loss: 0.5377 - top_3_accuracy: 0.9521 - acc: 0.8329
 847/9924 [=>............................] - ETA: 1:27:27 - loss: 0.5373 - top_3_accuracy: 0.9522 - acc: 0.8331
 848/9924 [=>............................] - ETA: 1:27:26 - loss: 0.5373 - top_3_accuracy: 0.9521 - acc: 0.8331
 849/9924 [=>............................] - ETA: 1:27:26 - loss: 0.5373 - top_3_accuracy: 0.9520 - acc: 0.8332
 850/9924 [=>............................] - ETA: 1:27:25 - loss: 0.5376 - top_3_accuracy: 0.9521 - acc: 0.8332
 851/9924 [=>............................] - ETA: 1:27:24 - loss: 0.5385 - top_3_accuracy: 0.9518 - acc: 0.8331
 852/9924 [=>............................] - ETA: 1:27:24 - loss: 0.5380 - top_3_accuracy: 0.9519 - acc: 0.8333
 853/9924 [=>............................] - ETA: 1:27:23 - loss: 0.5380 - top_3_accuracy: 0.9519 - acc: 0.8332
 854/9924 [=>............................] - ETA: 1:27:22 - loss: 0.5390 - top_3_accuracy: 0.9518 - acc: 0.8330
 855/9924 [=>............................] - ETA: 1:27:22 - loss: 0.5397 - top_3_accuracy: 0.9516 - acc: 0.8329
 856/9924 [=>............................] - ETA: 1:27:21 - loss: 0.5393 - top_3_accuracy: 0.9517 - acc: 0.8331
 857/9924 [=>............................] - ETA: 1:27:20 - loss: 0.5388 - top_3_accuracy: 0.9517 - acc: 0.8333
 858/9924 [=>............................] - ETA: 1:27:20 - loss: 0.5385 - top_3_accuracy: 0.9518 - acc: 0.8333
 859/9924 [=>............................] - ETA: 1:27:19 - loss: 0.5380 - top_3_accuracy: 0.9518 - acc: 0.8335
 860/9924 [=>............................] - ETA: 1:27:19 - loss: 0.5375 - top_3_accuracy: 0.9519 - acc: 0.8337
 861/9924 [=>............................] - ETA: 1:27:18 - loss: 0.5392 - top_3_accuracy: 0.9517 - acc: 0.8335
 862/9924 [=>............................] - ETA: 1:27:17 - loss: 0.5394 - top_3_accuracy: 0.9517 - acc: 0.8331
 863/9924 [=>............................] - ETA: 1:27:17 - loss: 0.5395 - top_3_accuracy: 0.9518 - acc: 0.8331
 864/9924 [=>............................] - ETA: 1:27:16 - loss: 0.5400 - top_3_accuracy: 0.9518 - acc: 0.8330
 865/9924 [=>............................] - ETA: 1:27:15 - loss: 0.5397 - top_3_accuracy: 0.9519 - acc: 0.8332
 866/9924 [=>............................] - ETA: 1:27:15 - loss: 0.5398 - top_3_accuracy: 0.9518 - acc: 0.8333
 867/9924 [=>............................] - ETA: 1:27:14 - loss: 0.5403 - top_3_accuracy: 0.9517 - acc: 0.8333
 868/9924 [=>............................] - ETA: 1:27:13 - loss: 0.5399 - top_3_accuracy: 0.9518 - acc: 0.8335
 869/9924 [=>............................] - ETA: 1:27:13 - loss: 0.5396 - top_3_accuracy: 0.9518 - acc: 0.8336
 870/9924 [=>............................] - ETA: 1:27:12 - loss: 0.5398 - top_3_accuracy: 0.9517 - acc: 0.8336
 871/9924 [=>............................] - ETA: 1:27:12 - loss: 0.5395 - top_3_accuracy: 0.9518 - acc: 0.8338
 872/9924 [=>............................] - ETA: 1:27:11 - loss: 0.5390 - top_3_accuracy: 0.9518 - acc: 0.8340
 873/9924 [=>............................] - ETA: 1:27:10 - loss: 0.5393 - top_3_accuracy: 0.9517 - acc: 0.8340
 874/9924 [=>............................] - ETA: 1:27:10 - loss: 0.5393 - top_3_accuracy: 0.9517 - acc: 0.8341
 875/9924 [=>............................] - ETA: 1:27:09 - loss: 0.5396 - top_3_accuracy: 0.9517 - acc: 0.8339
 876/9924 [=>............................] - ETA: 1:27:08 - loss: 0.5394 - top_3_accuracy: 0.9518 - acc: 0.8339
 877/9924 [=>............................] - ETA: 1:27:08 - loss: 0.5405 - top_3_accuracy: 0.9515 - acc: 0.8337
 878/9924 [=>............................] - ETA: 1:27:07 - loss: 0.5401 - top_3_accuracy: 0.9516 - acc: 0.8337
 879/9924 [=>............................] - ETA: 1:27:07 - loss: 0.5409 - top_3_accuracy: 0.9515 - acc: 0.8336
 880/9924 [=>............................] - ETA: 1:27:06 - loss: 0.5417 - top_3_accuracy: 0.9514 - acc: 0.8335
 881/9924 [=>............................] - ETA: 1:27:05 - loss: 0.5414 - top_3_accuracy: 0.9515 - acc: 0.8336
 882/9924 [=>............................] - ETA: 1:27:05 - loss: 0.5412 - top_3_accuracy: 0.9515 - acc: 0.8335
 883/9924 [=>............................] - ETA: 1:27:04 - loss: 0.5410 - top_3_accuracy: 0.9514 - acc: 0.8335
 884/9924 [=>............................] - ETA: 1:27:03 - loss: 0.5409 - top_3_accuracy: 0.9514 - acc: 0.8336
 885/9924 [=>............................] - ETA: 1:27:03 - loss: 0.5410 - top_3_accuracy: 0.9514 - acc: 0.8335
 886/9924 [=>............................] - ETA: 1:27:02 - loss: 0.5409 - top_3_accuracy: 0.9515 - acc: 0.8335
 887/9924 [=>............................] - ETA: 1:27:02 - loss: 0.5411 - top_3_accuracy: 0.9515 - acc: 0.8334
 888/9924 [=>............................] - ETA: 1:27:01 - loss: 0.5405 - top_3_accuracy: 0.9516 - acc: 0.8336
 889/9924 [=>............................] - ETA: 1:27:00 - loss: 0.5405 - top_3_accuracy: 0.9515 - acc: 0.8337
 890/9924 [=>............................] - ETA: 1:27:00 - loss: 0.5401 - top_3_accuracy: 0.9515 - acc: 0.8337
 891/9924 [=>............................] - ETA: 1:26:59 - loss: 0.5399 - top_3_accuracy: 0.9516 - acc: 0.8338
 892/9924 [=>............................] - ETA: 1:26:58 - loss: 0.5398 - top_3_accuracy: 0.9515 - acc: 0.8338
 893/9924 [=>............................] - ETA: 1:26:58 - loss: 0.5403 - top_3_accuracy: 0.9514 - acc: 0.8334
 894/9924 [=>............................] - ETA: 1:26:57 - loss: 0.5398 - top_3_accuracy: 0.9515 - acc: 0.8336
 895/9924 [=>............................] - ETA: 1:26:57 - loss: 0.5398 - top_3_accuracy: 0.9515 - acc: 0.8337
 896/9924 [=>............................] - ETA: 1:26:56 - loss: 0.5400 - top_3_accuracy: 0.9515 - acc: 0.8336
 897/9924 [=>............................] - ETA: 1:26:55 - loss: 0.5401 - top_3_accuracy: 0.9515 - acc: 0.8335
 898/9924 [=>............................] - ETA: 1:26:55 - loss: 0.5403 - top_3_accuracy: 0.9513 - acc: 0.8334
 899/9924 [=>............................] - ETA: 1:26:54 - loss: 0.5405 - top_3_accuracy: 0.9513 - acc: 0.8331
 900/9924 [=>............................] - ETA: 1:26:53 - loss: 0.5408 - top_3_accuracy: 0.9513 - acc: 0.8331
 901/9924 [=>............................] - ETA: 1:26:53 - loss: 0.5406 - top_3_accuracy: 0.9513 - acc: 0.8331
 902/9924 [=>............................] - ETA: 1:26:52 - loss: 0.5407 - top_3_accuracy: 0.9512 - acc: 0.8331
 903/9924 [=>............................] - ETA: 1:26:52 - loss: 0.5402 - top_3_accuracy: 0.9513 - acc: 0.8333
 904/9924 [=>............................] - ETA: 1:26:51 - loss: 0.5407 - top_3_accuracy: 0.9511 - acc: 0.8332
 905/9924 [=>............................] - ETA: 1:26:50 - loss: 0.5408 - top_3_accuracy: 0.9510 - acc: 0.8331
 906/9924 [=>............................] - ETA: 1:26:50 - loss: 0.5408 - top_3_accuracy: 0.9510 - acc: 0.8331
 907/9924 [=>............................] - ETA: 1:26:49 - loss: 0.5413 - top_3_accuracy: 0.9509 - acc: 0.8330
 908/9924 [=>............................] - ETA: 1:26:48 - loss: 0.5415 - top_3_accuracy: 0.9509 - acc: 0.8329
 909/9924 [=>............................] - ETA: 1:26:48 - loss: 0.5415 - top_3_accuracy: 0.9509 - acc: 0.8329
 910/9924 [=>............................] - ETA: 1:26:47 - loss: 0.5414 - top_3_accuracy: 0.9510 - acc: 0.8328
 911/9924 [=>............................] - ETA: 1:26:47 - loss: 0.5415 - top_3_accuracy: 0.9509 - acc: 0.8327
 912/9924 [=>............................] - ETA: 1:26:46 - loss: 0.5417 - top_3_accuracy: 0.9508 - acc: 0.8328
 913/9924 [=>............................] - ETA: 1:26:45 - loss: 0.5419 - top_3_accuracy: 0.9508 - acc: 0.8327
 914/9924 [=>............................] - ETA: 1:26:45 - loss: 0.5421 - top_3_accuracy: 0.9509 - acc: 0.8325
 915/9924 [=>............................] - ETA: 1:26:44 - loss: 0.5423 - top_3_accuracy: 0.9510 - acc: 0.8322
 916/9924 [=>............................] - ETA: 1:26:43 - loss: 0.5420 - top_3_accuracy: 0.9510 - acc: 0.8324
 917/9924 [=>............................] - ETA: 1:26:43 - loss: 0.5427 - top_3_accuracy: 0.9509 - acc: 0.8323
 918/9924 [=>............................] - ETA: 1:26:42 - loss: 0.5425 - top_3_accuracy: 0.9510 - acc: 0.8324
 919/9924 [=>............................] - ETA: 1:26:42 - loss: 0.5431 - top_3_accuracy: 0.9509 - acc: 0.8322
 920/9924 [=>............................] - ETA: 1:26:41 - loss: 0.5429 - top_3_accuracy: 0.9510 - acc: 0.8321
 921/9924 [=>............................] - ETA: 1:26:40 - loss: 0.5428 - top_3_accuracy: 0.9510 - acc: 0.8321
 922/9924 [=>............................] - ETA: 1:26:40 - loss: 0.5430 - top_3_accuracy: 0.9511 - acc: 0.8319
 923/9924 [=>............................] - ETA: 1:26:39 - loss: 0.5436 - top_3_accuracy: 0.9508 - acc: 0.8318
 924/9924 [=>............................] - ETA: 1:26:38 - loss: 0.5438 - top_3_accuracy: 0.9509 - acc: 0.8318
 925/9924 [=>............................] - ETA: 1:26:38 - loss: 0.5435 - top_3_accuracy: 0.9509 - acc: 0.8319
 926/9924 [=>............................] - ETA: 1:26:37 - loss: 0.5439 - top_3_accuracy: 0.9509 - acc: 0.8318
 927/9924 [=>............................] - ETA: 1:26:36 - loss: 0.5450 - top_3_accuracy: 0.9508 - acc: 0.8317
 928/9924 [=>............................] - ETA: 1:26:36 - loss: 0.5456 - top_3_accuracy: 0.9508 - acc: 0.8315
 929/9924 [=>............................] - ETA: 1:26:35 - loss: 0.5457 - top_3_accuracy: 0.9509 - acc: 0.8314
 930/9924 [=>............................] - ETA: 1:26:35 - loss: 0.5452 - top_3_accuracy: 0.9509 - acc: 0.8316
 931/9924 [=>............................] - ETA: 1:26:34 - loss: 0.5454 - top_3_accuracy: 0.9509 - acc: 0.8315
 932/9924 [=>............................] - ETA: 1:26:33 - loss: 0.5463 - top_3_accuracy: 0.9508 - acc: 0.8313
 933/9924 [=>............................] - ETA: 1:26:33 - loss: 0.5462 - top_3_accuracy: 0.9508 - acc: 0.8313
 934/9924 [=>............................] - ETA: 1:26:32 - loss: 0.5464 - top_3_accuracy: 0.9509 - acc: 0.8312
 935/9924 [=>............................] - ETA: 1:26:32 - loss: 0.5469 - top_3_accuracy: 0.9509 - acc: 0.8310
 936/9924 [=>............................] - ETA: 1:26:31 - loss: 0.5469 - top_3_accuracy: 0.9509 - acc: 0.8311
 937/9924 [=>............................] - ETA: 1:26:30 - loss: 0.5466 - top_3_accuracy: 0.9509 - acc: 0.8311
 938/9924 [=>............................] - ETA: 1:26:30 - loss: 0.5464 - top_3_accuracy: 0.9510 - acc: 0.8312
 939/9924 [=>............................] - ETA: 1:26:29 - loss: 0.5459 - top_3_accuracy: 0.9510 - acc: 0.8313
 940/9924 [=>............................] - ETA: 1:26:28 - loss: 0.5459 - top_3_accuracy: 0.9509 - acc: 0.8314
 941/9924 [=>............................] - ETA: 1:26:28 - loss: 0.5461 - top_3_accuracy: 0.9510 - acc: 0.8314
 942/9924 [=>............................] - ETA: 1:26:27 - loss: 0.5468 - top_3_accuracy: 0.9508 - acc: 0.8313
 943/9924 [=>............................] - ETA: 1:26:27 - loss: 0.5472 - top_3_accuracy: 0.9507 - acc: 0.8313
 944/9924 [=>............................] - ETA: 1:26:26 - loss: 0.5469 - top_3_accuracy: 0.9507 - acc: 0.8313
 945/9924 [=>............................] - ETA: 1:26:25 - loss: 0.5469 - top_3_accuracy: 0.9508 - acc: 0.8313
 946/9924 [=>............................] - ETA: 1:26:25 - loss: 0.5470 - top_3_accuracy: 0.9507 - acc: 0.8313
 947/9924 [=>............................] - ETA: 1:26:24 - loss: 0.5475 - top_3_accuracy: 0.9506 - acc: 0.8312
 948/9924 [=>............................] - ETA: 1:26:23 - loss: 0.5481 - top_3_accuracy: 0.9506 - acc: 0.8311
 949/9924 [=>............................] - ETA: 1:26:23 - loss: 0.5482 - top_3_accuracy: 0.9506 - acc: 0.8310
 950/9924 [=>............................] - ETA: 1:26:22 - loss: 0.5483 - top_3_accuracy: 0.9505 - acc: 0.8309
 951/9924 [=>............................] - ETA: 1:26:22 - loss: 0.5484 - top_3_accuracy: 0.9506 - acc: 0.8308
 952/9924 [=>............................] - ETA: 1:26:21 - loss: 0.5480 - top_3_accuracy: 0.9506 - acc: 0.8310
 953/9924 [=>............................] - ETA: 1:26:20 - loss: 0.5482 - top_3_accuracy: 0.9507 - acc: 0.8308
 954/9924 [=>............................] - ETA: 1:26:20 - loss: 0.5484 - top_3_accuracy: 0.9506 - acc: 0.8307
 955/9924 [=>............................] - ETA: 1:26:19 - loss: 0.5483 - top_3_accuracy: 0.9507 - acc: 0.8306
 956/9924 [=>............................] - ETA: 1:26:18 - loss: 0.5488 - top_3_accuracy: 0.9507 - acc: 0.8305
 957/9924 [=>............................] - ETA: 1:26:18 - loss: 0.5489 - top_3_accuracy: 0.9508 - acc: 0.8303
 958/9924 [=>............................] - ETA: 1:26:17 - loss: 0.5488 - top_3_accuracy: 0.9507 - acc: 0.8304
 959/9924 [=>............................] - ETA: 1:26:17 - loss: 0.5484 - top_3_accuracy: 0.9507 - acc: 0.8306
 960/9924 [=>............................] - ETA: 1:26:16 - loss: 0.5481 - top_3_accuracy: 0.9508 - acc: 0.8305
 961/9924 [=>............................] - ETA: 1:26:15 - loss: 0.5479 - top_3_accuracy: 0.9508 - acc: 0.8305
 962/9924 [=>............................] - ETA: 1:26:15 - loss: 0.5476 - top_3_accuracy: 0.9509 - acc: 0.8306
 963/9924 [=>............................] - ETA: 1:26:14 - loss: 0.5486 - top_3_accuracy: 0.9507 - acc: 0.8302
 964/9924 [=>............................] - ETA: 1:26:14 - loss: 0.5483 - top_3_accuracy: 0.9507 - acc: 0.8304
 965/9924 [=>............................] - ETA: 1:26:13 - loss: 0.5479 - top_3_accuracy: 0.9508 - acc: 0.8304
 966/9924 [=>............................] - ETA: 1:26:12 - loss: 0.5481 - top_3_accuracy: 0.9508 - acc: 0.8304
 967/9924 [=>............................] - ETA: 1:26:12 - loss: 0.5479 - top_3_accuracy: 0.9509 - acc: 0.8303
 968/9924 [=>............................] - ETA: 1:26:11 - loss: 0.5475 - top_3_accuracy: 0.9509 - acc: 0.8304
 969/9924 [=>............................] - ETA: 1:26:10 - loss: 0.5472 - top_3_accuracy: 0.9510 - acc: 0.8306
 970/9924 [=>............................] - ETA: 1:26:10 - loss: 0.5472 - top_3_accuracy: 0.9510 - acc: 0.8307
 971/9924 [=>............................] - ETA: 1:26:09 - loss: 0.5477 - top_3_accuracy: 0.9510 - acc: 0.8307
 972/9924 [=>............................] - ETA: 1:26:09 - loss: 0.5473 - top_3_accuracy: 0.9510 - acc: 0.8309
 973/9924 [=>............................] - ETA: 1:26:08 - loss: 0.5470 - top_3_accuracy: 0.9511 - acc: 0.8311
 974/9924 [=>............................] - ETA: 1:26:07 - loss: 0.5473 - top_3_accuracy: 0.9511 - acc: 0.8310
 975/9924 [=>............................] - ETA: 1:26:07 - loss: 0.5473 - top_3_accuracy: 0.9510 - acc: 0.8310
 976/9924 [=>............................] - ETA: 1:26:06 - loss: 0.5473 - top_3_accuracy: 0.9509 - acc: 0.8311
 977/9924 [=>............................] - ETA: 1:26:05 - loss: 0.5470 - top_3_accuracy: 0.9510 - acc: 0.8312
 978/9924 [=>............................] - ETA: 1:26:05 - loss: 0.5475 - top_3_accuracy: 0.9509 - acc: 0.8312
 979/9924 [=>............................] - ETA: 1:26:04 - loss: 0.5474 - top_3_accuracy: 0.9510 - acc: 0.8311
 980/9924 [=>............................] - ETA: 1:26:04 - loss: 0.5482 - top_3_accuracy: 0.9509 - acc: 0.8309
 981/9924 [=>............................] - ETA: 1:26:03 - loss: 0.5485 - top_3_accuracy: 0.9508 - acc: 0.8308
 982/9924 [=>............................] - ETA: 1:26:02 - loss: 0.5484 - top_3_accuracy: 0.9509 - acc: 0.8308
 983/9924 [=>............................] - ETA: 1:26:02 - loss: 0.5484 - top_3_accuracy: 0.9508 - acc: 0.8307
 984/9924 [=>............................] - ETA: 1:26:01 - loss: 0.5487 - top_3_accuracy: 0.9507 - acc: 0.8308
 985/9924 [=>............................] - ETA: 1:26:01 - loss: 0.5486 - top_3_accuracy: 0.9508 - acc: 0.8307
 986/9924 [=>............................] - ETA: 1:26:00 - loss: 0.5482 - top_3_accuracy: 0.9508 - acc: 0.8309
 987/9924 [=>............................] - ETA: 1:25:59 - loss: 0.5477 - top_3_accuracy: 0.9509 - acc: 0.8311
 988/9924 [=>............................] - ETA: 1:25:59 - loss: 0.5477 - top_3_accuracy: 0.9508 - acc: 0.8311
 989/9924 [=>............................] - ETA: 1:25:58 - loss: 0.5477 - top_3_accuracy: 0.9508 - acc: 0.8311
 990/9924 [=>............................] - ETA: 1:25:57 - loss: 0.5479 - top_3_accuracy: 0.9506 - acc: 0.8311
 991/9924 [=>............................] - ETA: 1:25:57 - loss: 0.5481 - top_3_accuracy: 0.9504 - acc: 0.8310
 992/9924 [=>............................] - ETA: 1:25:56 - loss: 0.5479 - top_3_accuracy: 0.9505 - acc: 0.8311
 993/9924 [==>...........................] - ETA: 1:25:56 - loss: 0.5479 - top_3_accuracy: 0.9505 - acc: 0.8312
 994/9924 [==>...........................] - ETA: 1:25:55 - loss: 0.5476 - top_3_accuracy: 0.9506 - acc: 0.8312
 995/9924 [==>...........................] - ETA: 1:25:54 - loss: 0.5482 - top_3_accuracy: 0.9506 - acc: 0.8310
 996/9924 [==>...........................] - ETA: 1:25:54 - loss: 0.5486 - top_3_accuracy: 0.9506 - acc: 0.8308
 997/9924 [==>...........................] - ETA: 1:25:53 - loss: 0.5496 - top_3_accuracy: 0.9505 - acc: 0.8305
 998/9924 [==>...........................] - ETA: 1:25:53 - loss: 0.5495 - top_3_accuracy: 0.9505 - acc: 0.8305
 999/9924 [==>...........................] - ETA: 1:25:52 - loss: 0.5497 - top_3_accuracy: 0.9506 - acc: 0.8303
1000/9924 [==>...........................] - ETA: 1:25:51 - loss: 0.5504 - top_3_accuracy: 0.9504 - acc: 0.8303
1001/9924 [==>...........................] - ETA: 1:25:51 - loss: 0.5499 - top_3_accuracy: 0.9504 - acc: 0.8304
1002/9924 [==>...........................] - ETA: 1:25:50 - loss: 0.5504 - top_3_accuracy: 0.9505 - acc: 0.8303
1003/9924 [==>...........................] - ETA: 1:25:49 - loss: 0.5501 - top_3_accuracy: 0.9505 - acc: 0.8305
1004/9924 [==>...........................] - ETA: 1:25:49 - loss: 0.5501 - top_3_accuracy: 0.9506 - acc: 0.8306
1005/9924 [==>...........................] - ETA: 1:25:48 - loss: 0.5498 - top_3_accuracy: 0.9506 - acc: 0.8307
1006/9924 [==>...........................] - ETA: 1:25:48 - loss: 0.5497 - top_3_accuracy: 0.9507 - acc: 0.8308
1007/9924 [==>...........................] - ETA: 1:25:47 - loss: 0.5494 - top_3_accuracy: 0.9507 - acc: 0.8308
1008/9924 [==>...........................] - ETA: 1:25:46 - loss: 0.5499 - top_3_accuracy: 0.9508 - acc: 0.8305
1009/9924 [==>...........................] - ETA: 1:25:46 - loss: 0.5501 - top_3_accuracy: 0.9507 - acc: 0.8303
1010/9924 [==>...........................] - ETA: 1:25:45 - loss: 0.5508 - top_3_accuracy: 0.9506 - acc: 0.8298
1011/9924 [==>...........................] - ETA: 1:25:45 - loss: 0.5514 - top_3_accuracy: 0.9504 - acc: 0.8296
1012/9924 [==>...........................] - ETA: 1:25:44 - loss: 0.5513 - top_3_accuracy: 0.9505 - acc: 0.8297
1013/9924 [==>...........................] - ETA: 1:25:43 - loss: 0.5513 - top_3_accuracy: 0.9505 - acc: 0.8296
1014/9924 [==>...........................] - ETA: 1:25:43 - loss: 0.5515 - top_3_accuracy: 0.9504 - acc: 0.8295
1015/9924 [==>...........................] - ETA: 1:25:42 - loss: 0.5512 - top_3_accuracy: 0.9505 - acc: 0.8296
1016/9924 [==>...........................] - ETA: 1:25:41 - loss: 0.5514 - top_3_accuracy: 0.9504 - acc: 0.8295
1017/9924 [==>...........................] - ETA: 1:25:41 - loss: 0.5513 - top_3_accuracy: 0.9505 - acc: 0.8295
1018/9924 [==>...........................] - ETA: 1:25:40 - loss: 0.5512 - top_3_accuracy: 0.9504 - acc: 0.8296
1019/9924 [==>...........................] - ETA: 1:25:40 - loss: 0.5516 - top_3_accuracy: 0.9503 - acc: 0.8292
1020/9924 [==>...........................] - ETA: 1:25:39 - loss: 0.5516 - top_3_accuracy: 0.9504 - acc: 0.8292
1021/9924 [==>...........................] - ETA: 1:25:38 - loss: 0.5514 - top_3_accuracy: 0.9504 - acc: 0.8292
1022/9924 [==>...........................] - ETA: 1:25:38 - loss: 0.5512 - top_3_accuracy: 0.9505 - acc: 0.8293
1023/9924 [==>...........................] - ETA: 1:25:37 - loss: 0.5512 - top_3_accuracy: 0.9505 - acc: 0.8293
1024/9924 [==>...........................] - ETA: 1:25:37 - loss: 0.5513 - top_3_accuracy: 0.9504 - acc: 0.8292
1025/9924 [==>...........................] - ETA: 1:25:36 - loss: 0.5514 - top_3_accuracy: 0.9504 - acc: 0.8290
1026/9924 [==>...........................] - ETA: 1:25:35 - loss: 0.5512 - top_3_accuracy: 0.9504 - acc: 0.8289
1027/9924 [==>...........................] - ETA: 1:25:35 - loss: 0.5514 - top_3_accuracy: 0.9503 - acc: 0.8289
1028/9924 [==>...........................] - ETA: 1:25:34 - loss: 0.5515 - top_3_accuracy: 0.9504 - acc: 0.8288
1029/9924 [==>...........................] - ETA: 1:25:33 - loss: 0.5516 - top_3_accuracy: 0.9504 - acc: 0.8286
1030/9924 [==>...........................] - ETA: 1:25:33 - loss: 0.5514 - top_3_accuracy: 0.9505 - acc: 0.8286
1031/9924 [==>...........................] - ETA: 1:25:32 - loss: 0.5514 - top_3_accuracy: 0.9505 - acc: 0.8286
1032/9924 [==>...........................] - ETA: 1:25:32 - loss: 0.5515 - top_3_accuracy: 0.9506 - acc: 0.8285
1033/9924 [==>...........................] - ETA: 1:25:31 - loss: 0.5513 - top_3_accuracy: 0.9506 - acc: 0.8285
1034/9924 [==>...........................] - ETA: 1:25:30 - loss: 0.5517 - top_3_accuracy: 0.9504 - acc: 0.8283
1035/9924 [==>...........................] - ETA: 1:25:30 - loss: 0.5525 - top_3_accuracy: 0.9504 - acc: 0.8281
1036/9924 [==>...........................] - ETA: 1:25:29 - loss: 0.5523 - top_3_accuracy: 0.9504 - acc: 0.8282
1037/9924 [==>...........................] - ETA: 1:25:29 - loss: 0.5524 - top_3_accuracy: 0.9503 - acc: 0.8281
1038/9924 [==>...........................] - ETA: 1:25:28 - loss: 0.5524 - top_3_accuracy: 0.9504 - acc: 0.8280
1039/9924 [==>...........................] - ETA: 1:25:27 - loss: 0.5525 - top_3_accuracy: 0.9504 - acc: 0.8278
1040/9924 [==>...........................] - ETA: 1:25:27 - loss: 0.5531 - top_3_accuracy: 0.9504 - acc: 0.8278
1041/9924 [==>...........................] - ETA: 1:25:26 - loss: 0.5528 - top_3_accuracy: 0.9504 - acc: 0.8278
1042/9924 [==>...........................] - ETA: 1:25:26 - loss: 0.5523 - top_3_accuracy: 0.9505 - acc: 0.8280
1043/9924 [==>...........................] - ETA: 1:25:25 - loss: 0.5520 - top_3_accuracy: 0.9505 - acc: 0.8280
1044/9924 [==>...........................] - ETA: 1:25:24 - loss: 0.5519 - top_3_accuracy: 0.9506 - acc: 0.8279
1045/9924 [==>...........................] - ETA: 1:25:24 - loss: 0.5520 - top_3_accuracy: 0.9505 - acc: 0.8280
1046/9924 [==>...........................] - ETA: 1:25:23 - loss: 0.5515 - top_3_accuracy: 0.9505 - acc: 0.8282
1047/9924 [==>...........................] - ETA: 1:25:22 - loss: 0.5515 - top_3_accuracy: 0.9506 - acc: 0.8282
1048/9924 [==>...........................] - ETA: 1:25:22 - loss: 0.5512 - top_3_accuracy: 0.9506 - acc: 0.8284
1049/9924 [==>...........................] - ETA: 1:25:21 - loss: 0.5510 - top_3_accuracy: 0.9505 - acc: 0.8284
1050/9924 [==>...........................] - ETA: 1:25:21 - loss: 0.5510 - top_3_accuracy: 0.9505 - acc: 0.8285
1051/9924 [==>...........................] - ETA: 1:25:20 - loss: 0.5509 - top_3_accuracy: 0.9505 - acc: 0.8284
1052/9924 [==>...........................] - ETA: 1:25:19 - loss: 0.5506 - top_3_accuracy: 0.9506 - acc: 0.8285
1053/9924 [==>...........................] - ETA: 1:25:19 - loss: 0.5506 - top_3_accuracy: 0.9506 - acc: 0.8286
1054/9924 [==>...........................] - ETA: 1:25:18 - loss: 0.5512 - top_3_accuracy: 0.9507 - acc: 0.8283
1055/9924 [==>...........................] - ETA: 1:25:18 - loss: 0.5516 - top_3_accuracy: 0.9506 - acc: 0.8281
1056/9924 [==>...........................] - ETA: 1:25:17 - loss: 0.5528 - top_3_accuracy: 0.9505 - acc: 0.8278
1057/9924 [==>...........................] - ETA: 1:25:16 - loss: 0.5529 - top_3_accuracy: 0.9506 - acc: 0.8277
1058/9924 [==>...........................] - ETA: 1:25:16 - loss: 0.5526 - top_3_accuracy: 0.9506 - acc: 0.8277
1059/9924 [==>...........................] - ETA: 1:25:15 - loss: 0.5526 - top_3_accuracy: 0.9507 - acc: 0.8277
1060/9924 [==>...........................] - ETA: 1:25:15 - loss: 0.5529 - top_3_accuracy: 0.9506 - acc: 0.8276
1061/9924 [==>...........................] - ETA: 1:25:14 - loss: 0.5529 - top_3_accuracy: 0.9505 - acc: 0.8276
1062/9924 [==>...........................] - ETA: 1:25:13 - loss: 0.5533 - top_3_accuracy: 0.9503 - acc: 0.8276
1063/9924 [==>...........................] - ETA: 1:25:13 - loss: 0.5533 - top_3_accuracy: 0.9503 - acc: 0.8275
1064/9924 [==>...........................] - ETA: 1:25:12 - loss: 0.5530 - top_3_accuracy: 0.9503 - acc: 0.8277
1065/9924 [==>...........................] - ETA: 1:25:11 - loss: 0.5534 - top_3_accuracy: 0.9502 - acc: 0.8277
1066/9924 [==>...........................] - ETA: 1:25:11 - loss: 0.5537 - top_3_accuracy: 0.9503 - acc: 0.8276
1067/9924 [==>...........................] - ETA: 1:25:10 - loss: 0.5535 - top_3_accuracy: 0.9503 - acc: 0.8277
1068/9924 [==>...........................] - ETA: 1:25:10 - loss: 0.5531 - top_3_accuracy: 0.9504 - acc: 0.8278
1069/9924 [==>...........................] - ETA: 1:25:09 - loss: 0.5526 - top_3_accuracy: 0.9504 - acc: 0.8280
1070/9924 [==>...........................] - ETA: 1:25:08 - loss: 0.5525 - top_3_accuracy: 0.9505 - acc: 0.8280
1071/9924 [==>...........................] - ETA: 1:25:08 - loss: 0.5522 - top_3_accuracy: 0.9505 - acc: 0.8281
1072/9924 [==>...........................] - ETA: 1:25:07 - loss: 0.5520 - top_3_accuracy: 0.9506 - acc: 0.8281
1073/9924 [==>...........................] - ETA: 1:25:07 - loss: 0.5525 - top_3_accuracy: 0.9506 - acc: 0.8281
1074/9924 [==>...........................] - ETA: 1:25:06 - loss: 0.5525 - top_3_accuracy: 0.9507 - acc: 0.8281
1075/9924 [==>...........................] - ETA: 1:25:05 - loss: 0.5524 - top_3_accuracy: 0.9507 - acc: 0.8281
1076/9924 [==>...........................] - ETA: 1:25:05 - loss: 0.5536 - top_3_accuracy: 0.9506 - acc: 0.8277
1077/9924 [==>...........................] - ETA: 1:25:04 - loss: 0.5551 - top_3_accuracy: 0.9504 - acc: 0.8272
1078/9924 [==>...........................] - ETA: 1:25:03 - loss: 0.5560 - top_3_accuracy: 0.9504 - acc: 0.8270
1079/9924 [==>...........................] - ETA: 1:25:03 - loss: 0.5558 - top_3_accuracy: 0.9504 - acc: 0.8270
1080/9924 [==>...........................] - ETA: 1:25:02 - loss: 0.5558 - top_3_accuracy: 0.9505 - acc: 0.8271
1081/9924 [==>...........................] - ETA: 1:25:02 - loss: 0.5562 - top_3_accuracy: 0.9504 - acc: 0.8270
1082/9924 [==>...........................] - ETA: 1:25:01 - loss: 0.5560 - top_3_accuracy: 0.9504 - acc: 0.8269
1083/9924 [==>...........................] - ETA: 1:25:00 - loss: 0.5559 - top_3_accuracy: 0.9505 - acc: 0.8269
1084/9924 [==>...........................] - ETA: 1:25:00 - loss: 0.5558 - top_3_accuracy: 0.9504 - acc: 0.8269
1085/9924 [==>...........................] - ETA: 1:24:59 - loss: 0.5557 - top_3_accuracy: 0.9505 - acc: 0.8270
1086/9924 [==>...........................] - ETA: 1:24:59 - loss: 0.5559 - top_3_accuracy: 0.9505 - acc: 0.8268
1087/9924 [==>...........................] - ETA: 1:24:58 - loss: 0.5556 - top_3_accuracy: 0.9506 - acc: 0.8269
1088/9924 [==>...........................] - ETA: 1:24:57 - loss: 0.5557 - top_3_accuracy: 0.9506 - acc: 0.8269
1089/9924 [==>...........................] - ETA: 1:24:57 - loss: 0.5556 - top_3_accuracy: 0.9506 - acc: 0.8270
1090/9924 [==>...........................] - ETA: 1:24:56 - loss: 0.5558 - top_3_accuracy: 0.9506 - acc: 0.8267
1091/9924 [==>...........................] - ETA: 1:24:56 - loss: 0.5554 - top_3_accuracy: 0.9506 - acc: 0.8269
1092/9924 [==>...........................] - ETA: 1:24:55 - loss: 0.5558 - top_3_accuracy: 0.9505 - acc: 0.8269
1093/9924 [==>...........................] - ETA: 1:24:54 - loss: 0.5554 - top_3_accuracy: 0.9506 - acc: 0.8271
1094/9924 [==>...........................] - ETA: 1:24:54 - loss: 0.5559 - top_3_accuracy: 0.9505 - acc: 0.8268
1095/9924 [==>...........................] - ETA: 1:24:53 - loss: 0.5557 - top_3_accuracy: 0.9506 - acc: 0.8268
1096/9924 [==>...........................] - ETA: 1:24:52 - loss: 0.5562 - top_3_accuracy: 0.9504 - acc: 0.8268
1097/9924 [==>...........................] - ETA: 1:24:52 - loss: 0.5560 - top_3_accuracy: 0.9504 - acc: 0.8268
1098/9924 [==>...........................] - ETA: 1:24:51 - loss: 0.5565 - top_3_accuracy: 0.9504 - acc: 0.8267
1099/9924 [==>...........................] - ETA: 1:24:51 - loss: 0.5566 - top_3_accuracy: 0.9503 - acc: 0.8268
1100/9924 [==>...........................] - ETA: 1:24:50 - loss: 0.5566 - top_3_accuracy: 0.9502 - acc: 0.8267
1101/9924 [==>...........................] - ETA: 1:24:49 - loss: 0.5570 - top_3_accuracy: 0.9503 - acc: 0.8266
1102/9924 [==>...........................] - ETA: 1:24:49 - loss: 0.5570 - top_3_accuracy: 0.9503 - acc: 0.8266
1103/9924 [==>...........................] - ETA: 1:24:48 - loss: 0.5568 - top_3_accuracy: 0.9504 - acc: 0.8266
1104/9924 [==>...........................] - ETA: 1:24:48 - loss: 0.5571 - top_3_accuracy: 0.9502 - acc: 0.8265
1105/9924 [==>...........................] - ETA: 1:24:47 - loss: 0.5574 - top_3_accuracy: 0.9501 - acc: 0.8264
1106/9924 [==>...........................] - ETA: 1:24:46 - loss: 0.5569 - top_3_accuracy: 0.9502 - acc: 0.8265
1107/9924 [==>...........................] - ETA: 1:24:46 - loss: 0.5568 - top_3_accuracy: 0.9501 - acc: 0.8266
1108/9924 [==>...........................] - ETA: 1:24:45 - loss: 0.5566 - top_3_accuracy: 0.9501 - acc: 0.8266
1109/9924 [==>...........................] - ETA: 1:24:45 - loss: 0.5564 - top_3_accuracy: 0.9502 - acc: 0.8266
1110/9924 [==>...........................] - ETA: 1:24:44 - loss: 0.5579 - top_3_accuracy: 0.9500 - acc: 0.8264
1111/9924 [==>...........................] - ETA: 1:24:43 - loss: 0.5580 - top_3_accuracy: 0.9499 - acc: 0.8262
1112/9924 [==>...........................] - ETA: 1:24:43 - loss: 0.5580 - top_3_accuracy: 0.9499 - acc: 0.8262
1113/9924 [==>...........................] - ETA: 1:24:42 - loss: 0.5580 - top_3_accuracy: 0.9498 - acc: 0.8263
1114/9924 [==>...........................] - ETA: 1:24:42 - loss: 0.5578 - top_3_accuracy: 0.9498 - acc: 0.8263
1115/9924 [==>...........................] - ETA: 1:24:41 - loss: 0.5585 - top_3_accuracy: 0.9498 - acc: 0.8260
1116/9924 [==>...........................] - ETA: 1:24:40 - loss: 0.5586 - top_3_accuracy: 0.9498 - acc: 0.8259
1117/9924 [==>...........................] - ETA: 1:24:40 - loss: 0.5585 - top_3_accuracy: 0.9499 - acc: 0.8260
1118/9924 [==>...........................] - ETA: 1:24:39 - loss: 0.5585 - top_3_accuracy: 0.9498 - acc: 0.8260
1119/9924 [==>...........................] - ETA: 1:24:39 - loss: 0.5590 - top_3_accuracy: 0.9497 - acc: 0.8258
1120/9924 [==>...........................] - ETA: 1:24:38 - loss: 0.5588 - top_3_accuracy: 0.9498 - acc: 0.8259
1121/9924 [==>...........................] - ETA: 1:24:37 - loss: 0.5588 - top_3_accuracy: 0.9498 - acc: 0.8259
1122/9924 [==>...........................] - ETA: 1:24:37 - loss: 0.5590 - top_3_accuracy: 0.9498 - acc: 0.8259
1123/9924 [==>...........................] - ETA: 1:24:36 - loss: 0.5593 - top_3_accuracy: 0.9497 - acc: 0.8259
1124/9924 [==>...........................] - ETA: 1:24:36 - loss: 0.5595 - top_3_accuracy: 0.9497 - acc: 0.8257
1125/9924 [==>...........................] - ETA: 1:24:35 - loss: 0.5594 - top_3_accuracy: 0.9498 - acc: 0.8258
1126/9924 [==>...........................] - ETA: 1:24:34 - loss: 0.5592 - top_3_accuracy: 0.9498 - acc: 0.8257
1127/9924 [==>...........................] - ETA: 1:24:34 - loss: 0.5590 - top_3_accuracy: 0.9499 - acc: 0.8258
1128/9924 [==>...........................] - ETA: 1:24:33 - loss: 0.5587 - top_3_accuracy: 0.9499 - acc: 0.8258
1129/9924 [==>...........................] - ETA: 1:24:32 - loss: 0.5587 - top_3_accuracy: 0.9500 - acc: 0.8256
1130/9924 [==>...........................] - ETA: 1:24:32 - loss: 0.5587 - top_3_accuracy: 0.9499 - acc: 0.8257
1131/9924 [==>...........................] - ETA: 1:24:31 - loss: 0.5587 - top_3_accuracy: 0.9498 - acc: 0.8257
1132/9924 [==>...........................] - ETA: 1:24:31 - loss: 0.5591 - top_3_accuracy: 0.9496 - acc: 0.8255
1133/9924 [==>...........................] - ETA: 1:24:30 - loss: 0.5595 - top_3_accuracy: 0.9495 - acc: 0.8255
1134/9924 [==>...........................] - ETA: 1:24:29 - loss: 0.5596 - top_3_accuracy: 0.9495 - acc: 0.8254
1135/9924 [==>...........................] - ETA: 1:24:29 - loss: 0.5593 - top_3_accuracy: 0.9496 - acc: 0.8254
1136/9924 [==>...........................] - ETA: 1:24:28 - loss: 0.5596 - top_3_accuracy: 0.9495 - acc: 0.8254
1137/9924 [==>...........................] - ETA: 1:24:28 - loss: 0.5593 - top_3_accuracy: 0.9495 - acc: 0.8255
1138/9924 [==>...........................] - ETA: 1:24:27 - loss: 0.5599 - top_3_accuracy: 0.9496 - acc: 0.8252
1139/9924 [==>...........................] - ETA: 1:24:26 - loss: 0.5599 - top_3_accuracy: 0.9496 - acc: 0.8252
1140/9924 [==>...........................] - ETA: 1:24:26 - loss: 0.5597 - top_3_accuracy: 0.9497 - acc: 0.8253
1141/9924 [==>...........................] - ETA: 1:24:25 - loss: 0.5596 - top_3_accuracy: 0.9497 - acc: 0.8255
1142/9924 [==>...........................] - ETA: 1:24:25 - loss: 0.5599 - top_3_accuracy: 0.9496 - acc: 0.8255
1143/9924 [==>...........................] - ETA: 1:24:24 - loss: 0.5596 - top_3_accuracy: 0.9497 - acc: 0.8257
1144/9924 [==>...........................] - ETA: 1:24:23 - loss: 0.5597 - top_3_accuracy: 0.9497 - acc: 0.8256
1145/9924 [==>...........................] - ETA: 1:24:23 - loss: 0.5606 - top_3_accuracy: 0.9496 - acc: 0.8254
1146/9924 [==>...........................] - ETA: 1:24:22 - loss: 0.5605 - top_3_accuracy: 0.9496 - acc: 0.8255
1147/9924 [==>...........................] - ETA: 1:24:22 - loss: 0.5608 - top_3_accuracy: 0.9495 - acc: 0.8254
1148/9924 [==>...........................] - ETA: 1:24:21 - loss: 0.5605 - top_3_accuracy: 0.9496 - acc: 0.8255
1149/9924 [==>...........................] - ETA: 1:24:20 - loss: 0.5606 - top_3_accuracy: 0.9495 - acc: 0.8254
1150/9924 [==>...........................] - ETA: 1:24:20 - loss: 0.5606 - top_3_accuracy: 0.9496 - acc: 0.8253
1151/9924 [==>...........................] - ETA: 1:24:19 - loss: 0.5605 - top_3_accuracy: 0.9495 - acc: 0.8254
1152/9924 [==>...........................] - ETA: 1:24:19 - loss: 0.5603 - top_3_accuracy: 0.9495 - acc: 0.8255
1153/9924 [==>...........................] - ETA: 1:24:18 - loss: 0.5611 - top_3_accuracy: 0.9495 - acc: 0.8253
1154/9924 [==>...........................] - ETA: 1:24:17 - loss: 0.5616 - top_3_accuracy: 0.9493 - acc: 0.8252
1155/9924 [==>...........................] - ETA: 1:24:17 - loss: 0.5617 - top_3_accuracy: 0.9492 - acc: 0.8251
1156/9924 [==>...........................] - ETA: 1:24:16 - loss: 0.5621 - top_3_accuracy: 0.9492 - acc: 0.8249
1157/9924 [==>...........................] - ETA: 1:24:16 - loss: 0.5619 - top_3_accuracy: 0.9492 - acc: 0.8250
1158/9924 [==>...........................] - ETA: 1:24:15 - loss: 0.5625 - top_3_accuracy: 0.9491 - acc: 0.8248
1159/9924 [==>...........................] - ETA: 1:24:14 - loss: 0.5630 - top_3_accuracy: 0.9491 - acc: 0.8245
1160/9924 [==>...........................] - ETA: 1:24:14 - loss: 0.5631 - top_3_accuracy: 0.9491 - acc: 0.8244
1161/9924 [==>...........................] - ETA: 1:24:13 - loss: 0.5631 - top_3_accuracy: 0.9492 - acc: 0.8242
1162/9924 [==>...........................] - ETA: 1:24:13 - loss: 0.5629 - top_3_accuracy: 0.9492 - acc: 0.8243
1163/9924 [==>...........................] - ETA: 1:24:12 - loss: 0.5625 - top_3_accuracy: 0.9493 - acc: 0.8245
1164/9924 [==>...........................] - ETA: 1:24:11 - loss: 0.5623 - top_3_accuracy: 0.9493 - acc: 0.8245
1165/9924 [==>...........................] - ETA: 1:24:11 - loss: 0.5628 - top_3_accuracy: 0.9494 - acc: 0.8242
1166/9924 [==>...........................] - ETA: 1:24:10 - loss: 0.5628 - top_3_accuracy: 0.9494 - acc: 0.8242
1167/9924 [==>...........................] - ETA: 1:24:10 - loss: 0.5626 - top_3_accuracy: 0.9494 - acc: 0.8241
1168/9924 [==>...........................] - ETA: 1:24:09 - loss: 0.5622 - top_3_accuracy: 0.9495 - acc: 0.8243
1169/9924 [==>...........................] - ETA: 1:24:08 - loss: 0.5618 - top_3_accuracy: 0.9495 - acc: 0.8244
1170/9924 [==>...........................] - ETA: 1:24:08 - loss: 0.5615 - top_3_accuracy: 0.9496 - acc: 0.8245
1171/9924 [==>...........................] - ETA: 1:24:07 - loss: 0.5612 - top_3_accuracy: 0.9496 - acc: 0.8246
1172/9924 [==>...........................] - ETA: 1:24:06 - loss: 0.5610 - top_3_accuracy: 0.9497 - acc: 0.8247
1173/9924 [==>...........................] - ETA: 1:24:06 - loss: 0.5609 - top_3_accuracy: 0.9497 - acc: 0.8248
1174/9924 [==>...........................] - ETA: 1:24:05 - loss: 0.5607 - top_3_accuracy: 0.9497 - acc: 0.8249
1175/9924 [==>...........................] - ETA: 1:24:05 - loss: 0.5610 - top_3_accuracy: 0.9497 - acc: 0.8249
1176/9924 [==>...........................] - ETA: 1:24:04 - loss: 0.5612 - top_3_accuracy: 0.9497 - acc: 0.8248
1177/9924 [==>...........................] - ETA: 1:24:03 - loss: 0.5610 - top_3_accuracy: 0.9498 - acc: 0.8250
1178/9924 [==>...........................] - ETA: 1:24:03 - loss: 0.5610 - top_3_accuracy: 0.9498 - acc: 0.8249
1179/9924 [==>...........................] - ETA: 1:24:02 - loss: 0.5617 - top_3_accuracy: 0.9497 - acc: 0.8247
1180/9924 [==>...........................] - ETA: 1:24:02 - loss: 0.5616 - top_3_accuracy: 0.9498 - acc: 0.8247
1181/9924 [==>...........................] - ETA: 1:24:01 - loss: 0.5619 - top_3_accuracy: 0.9496 - acc: 0.8246
1182/9924 [==>...........................] - ETA: 1:24:00 - loss: 0.5619 - top_3_accuracy: 0.9496 - acc: 0.8246
1183/9924 [==>...........................] - ETA: 1:24:00 - loss: 0.5619 - top_3_accuracy: 0.9496 - acc: 0.8244
1184/9924 [==>...........................] - ETA: 1:23:59 - loss: 0.5621 - top_3_accuracy: 0.9495 - acc: 0.8244
1185/9924 [==>...........................] - ETA: 1:23:59 - loss: 0.5618 - top_3_accuracy: 0.9496 - acc: 0.8245
1186/9924 [==>...........................] - ETA: 1:23:58 - loss: 0.5617 - top_3_accuracy: 0.9496 - acc: 0.8245
1187/9924 [==>...........................] - ETA: 1:23:57 - loss: 0.5618 - top_3_accuracy: 0.9496 - acc: 0.8245
1188/9924 [==>...........................] - ETA: 1:23:57 - loss: 0.5616 - top_3_accuracy: 0.9496 - acc: 0.8245
1189/9924 [==>...........................] - ETA: 1:23:56 - loss: 0.5615 - top_3_accuracy: 0.9496 - acc: 0.8245
1190/9924 [==>...........................] - ETA: 1:23:56 - loss: 0.5618 - top_3_accuracy: 0.9496 - acc: 0.8244
1191/9924 [==>...........................] - ETA: 1:23:55 - loss: 0.5622 - top_3_accuracy: 0.9494 - acc: 0.8243
1192/9924 [==>...........................] - ETA: 1:23:54 - loss: 0.5621 - top_3_accuracy: 0.9495 - acc: 0.8242
1193/9924 [==>...........................] - ETA: 1:23:54 - loss: 0.5620 - top_3_accuracy: 0.9495 - acc: 0.8242
1194/9924 [==>...........................] - ETA: 1:23:53 - loss: 0.5620 - top_3_accuracy: 0.9495 - acc: 0.8242
1195/9924 [==>...........................] - ETA: 1:23:53 - loss: 0.5624 - top_3_accuracy: 0.9495 - acc: 0.8242
1196/9924 [==>...........................] - ETA: 1:23:52 - loss: 0.5625 - top_3_accuracy: 0.9495 - acc: 0.8242
1197/9924 [==>...........................] - ETA: 1:23:51 - loss: 0.5627 - top_3_accuracy: 0.9495 - acc: 0.8242
1198/9924 [==>...........................] - ETA: 1:23:51 - loss: 0.5625 - top_3_accuracy: 0.9495 - acc: 0.8243